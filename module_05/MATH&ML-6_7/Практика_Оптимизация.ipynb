{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyHIGVhfa_Wf"
      },
      "source": [
        "# Стохастический градиентный и координатный спуски"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn6lluIADUKa"
      },
      "source": [
        "Для каждого задания указано количество баллов (если они оцениваются отдельно) + 1 балл за аккуратное и полное выполнение всего задания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txCccYvha_Wv"
      },
      "source": [
        "## Загрузка и подготовка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbyOzeZ6a_Wx"
      },
      "source": [
        "**Загрузите уже знакомый вам файл *Advertising.csv* как объект DataFrame.** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E1L4_xeDa_Wz"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>TV</th>\n",
              "      <th>radio</th>\n",
              "      <th>newspaper</th>\n",
              "      <th>sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>230.1</td>\n",
              "      <td>37.8</td>\n",
              "      <td>69.2</td>\n",
              "      <td>22.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>44.5</td>\n",
              "      <td>39.3</td>\n",
              "      <td>45.1</td>\n",
              "      <td>10.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>17.2</td>\n",
              "      <td>45.9</td>\n",
              "      <td>69.3</td>\n",
              "      <td>9.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>151.5</td>\n",
              "      <td>41.3</td>\n",
              "      <td>58.5</td>\n",
              "      <td>18.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>180.8</td>\n",
              "      <td>10.8</td>\n",
              "      <td>58.4</td>\n",
              "      <td>12.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0     TV  radio  newspaper  sales\n",
              "0           1  230.1   37.8       69.2   22.1\n",
              "1           2   44.5   39.3       45.1   10.4\n",
              "2           3   17.2   45.9       69.3    9.3\n",
              "3           4  151.5   41.3       58.5   18.5\n",
              "4           5  180.8   10.8       58.4   12.9"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<u>Shape:</u> (200, 5)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "data = pd.read_csv('Advertising.csv')\n",
        "display(data.head())\n",
        "display(HTML(f\"<u>Shape:</u> {data.shape}\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf4aVFndDUKf"
      },
      "source": [
        "**Проверьте, есть ли в данных пропуски и, если они есть - удалите их**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tiVeFnR5DUKg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Unnamed: 0    0\n",
              "TV            0\n",
              "radio         0\n",
              "newspaper     0\n",
              "sales         0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isna().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTkiqPr_DUKh"
      },
      "source": [
        "**Преобразуйте ваши признаки в массивы NumPy и разделите их на переменные X (предикторы) и y(целевая переменная)** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R9OHIRB3a_Xa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X: type=<class 'numpy.ndarray'>, shape=(200, 3)\n",
            "y: type=<class 'numpy.ndarray'>, shape=(200,)\n"
          ]
        }
      ],
      "source": [
        "data.drop(['Unnamed: 0'], inplace=True, axis=1)\n",
        "\n",
        "target_column = 'sales'\n",
        "data_features = data.drop([target_column], axis=1)\n",
        "data_target = data[target_column]\n",
        "\n",
        "X = data_features.to_numpy(copy=True)\n",
        "y = data_target.to_numpy(copy=True)\n",
        "print(f\"X: type={type(X)}, shape={X.shape}\")\n",
        "print(f\"y: type={type(y)}, shape={y.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCvjSoHEDUKo"
      },
      "source": [
        "## Координатный спуск (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjNm8dATDUKq"
      },
      "source": [
        "**Добавим единичный столбец для того, чтобы у нас был свободный коэффициент в уравнении регрессии:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LMgq0fmKDUKr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X: type=<class 'numpy.ndarray'>, shape=(200, 4)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[  1. , 230.1,  37.8,  69.2],\n",
              "       [  1. ,  44.5,  39.3,  45.1],\n",
              "       [  1. ,  17.2,  45.9,  69.3],\n",
              "       [  1. , 151.5,  41.3,  58.5]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.hstack([np.ones(X.shape[0]).reshape(-1, 1), X])\n",
        "print(f\"X: type={type(X)}, shape={X.shape}\")\n",
        "X[0:4, :]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R008OQwcDUKt"
      },
      "source": [
        "**Нормализуем данные: обычно это необходимо для корректной работы алгоритма**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2Sk7Wx-SDUKt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.07071068, 0.09561706, 0.09692057, 0.13052034],\n",
              "       [0.07071068, 0.01849178, 0.10076663, 0.08506456],\n",
              "       [0.07071068, 0.00714739, 0.11768927, 0.13070895],\n",
              "       [0.07071068, 0.06295517, 0.1058947 , 0.11033873]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = X / np.sqrt(np.sum(np.square(X), axis=0))\n",
        "X[0:4, :]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_pHHbAdDUKu"
      },
      "source": [
        "**Реализуйте алгоритм координатного спуска:** (3 балла)\n",
        "\n",
        "Ниже приведен алгоритм:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBQ8vT5UDUKu"
      },
      "source": [
        "<a href=\"https://ibb.co/Th3BQFn\"><img src=\"https://i.ibb.co/DK2DBS6/zascas.jpg\" alt=\"zascas\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ce_yM20DUKv"
      },
      "source": [
        "Примечание: 1000 итераций здесь указаны для этого задания, на самом деле их может быть намного больше, нет детерменированного значения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3IdiHm9DUKv"
      },
      "source": [
        "Вам необходимо реализовать координатный спуск, и вывести веса в модели линейной регрессии."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Vsi3d9OfDUKw"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<u>Results of the <b><i>generic</i></b> coordinate descent method:</u>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<ul>\n",
              "    <li>Linear regression coefficients <b>w = {41.55119820717775, 110.12980736209727, 73.53409950393593, -0.5402867694709074}</b></li>\n",
              "    <li>RSS function minimum: <b>556.825</b></li>\n",
              "    <li>Reached tolerance: <b>7.551099e-09</b></li>\n",
              "    <li>Coordinate descent iterations: <b>1000</b></li>\n",
              "    <li>Total 1D iterations: <b>136118</b></li>\n",
              "</ul>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<u>Results of the <b><i>LLS</i></b>-optimized coordinate descent method:</u>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<ul>\n",
              "    <li>Linear regression coefficients <b>w = {41.562172046036125, 110.13144155326066, 73.52860637603473, -0.5500638414306833}</b></li>\n",
              "    <li>RSS function minimum: <b>556.825</b></li>\n",
              "    <li>Reached tolerance: <b>6.661338e-16</b></li>\n",
              "    <li>Coordinate descent iterations: <b>1000</b></li>\n",
              "</ul>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from typing import Callable\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "RATIO_GOLDEN = (1 + 5 ** 0.5) / 2\n",
        "INV_RATIO_GOLDEN = 1 / RATIO_GOLDEN\n",
        "INV_RATIO_GOLDEN_SQUARED = 1 - 1 / RATIO_GOLDEN  # == 1 / RATIO_GOLDEN**2\n",
        "LOG_INV_RATIO_GOLDEN = np.log(INV_RATIO_GOLDEN)\n",
        "\n",
        "\n",
        "def array_put(x: np.ndarray, i: int, xi: float):\n",
        "    x[i] = xi\n",
        "    return x\n",
        "\n",
        "\n",
        "def optimize_golden_section(f: Callable, a: float, b: float, tol: float = 1e-5):\n",
        "    assert a < b\n",
        "    assert tol > 0\n",
        "    assert tol < 1\n",
        "\n",
        "    h = b - a\n",
        "    x_left = a + INV_RATIO_GOLDEN_SQUARED * h\n",
        "    x_right = a + INV_RATIO_GOLDEN * h\n",
        "    f_left = f(x_left)\n",
        "    f_right = f(x_right)\n",
        "    number_of_iterations = int(\n",
        "        np.ceil((np.log(tol) - np.log(h)) / LOG_INV_RATIO_GOLDEN))\n",
        "\n",
        "    for i in range(number_of_iterations - 1):\n",
        "        h = INV_RATIO_GOLDEN * h\n",
        "        if f_left >= f_right:\n",
        "            a = x_left  # ; b = b\n",
        "            x_left = x_right\n",
        "            f_left = f_right\n",
        "            x_right = a + INV_RATIO_GOLDEN * h\n",
        "            f_right = f(x_right)\n",
        "        else:\n",
        "            b = x_right  # ; a = a\n",
        "            x_right = x_left\n",
        "            f_right = f_left\n",
        "            x_left = a + INV_RATIO_GOLDEN_SQUARED * h\n",
        "            f_left = f(x_left)\n",
        "\n",
        "    if f_left >= f_right:\n",
        "        return {\n",
        "            'point': (x_left + b) / 2,\n",
        "            'uncertainty': (x_left, b),\n",
        "            'tol': b - x_left,\n",
        "            'iterations': number_of_iterations\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            'point': (a + x_right) / 2,\n",
        "            'uncertainty': (a, x_right),\n",
        "            'tol': x_right - a,\n",
        "            'iterations': number_of_iterations\n",
        "        }\n",
        "\n",
        "\n",
        "def interval_1d(f: Callable, x0, dx):\n",
        "    assert dx > 0\n",
        "    x = x0\n",
        "    a = x\n",
        "    f_a = f(a)\n",
        "\n",
        "    f_x_dx = f(x - dx)\n",
        "    if f_x_dx < f_a:\n",
        "        dx = -dx\n",
        "\n",
        "    b = x + dx\n",
        "    f_b = f(b)\n",
        "\n",
        "    temp_a = a\n",
        "    while f_b < f_a:\n",
        "        temp_a = a\n",
        "        a = b\n",
        "        f_a = f_b\n",
        "        b = b + dx\n",
        "        f_b = f(b)\n",
        "\n",
        "    a = temp_a\n",
        "\n",
        "    if dx < 0:\n",
        "        temp_b = b\n",
        "        b = a\n",
        "        a = temp_b\n",
        "\n",
        "    return (a, b)\n",
        "\n",
        "\n",
        "def optimize_coordinate_descent(f: Callable, x0: np.ndarray,\n",
        "                                tol: float = 1e-5,\n",
        "                                iterations=1000, iterations_over_tolerance: bool = False,\n",
        "                                sliding_window_1d: float = 0.01,\n",
        "                                norm_order: int = 2):\n",
        "    assert isinstance(x0, np.ndarray)\n",
        "    assert len(np.shape(x0)) == 1\n",
        "    assert tol > 0\n",
        "    assert tol < 1\n",
        "\n",
        "    p = np.size(x0)\n",
        "    x_last = np.copy(x0, order='C')\n",
        "    x = np.copy(x0, order='C')\n",
        "    counter_iterations = 1\n",
        "    counter_1d_iterations = 0\n",
        "    while True:\n",
        "        x = np.copy(x_last, order='C')\n",
        "\n",
        "        for i in range(p):\n",
        "            def f_xi(xi): return f(array_put(x, i, xi))\n",
        "            a_i, b_i = interval_1d(f_xi, x[i], dx=sliding_window_1d)\n",
        "            result_i = optimize_golden_section(f_xi, a_i, b_i, tol=tol/10)\n",
        "            xi_new = result_i['point']\n",
        "            counter_1d_iterations += result_i['iterations']\n",
        "            x[i] = xi_new\n",
        "\n",
        "        if iterations_over_tolerance:\n",
        "            if counter_iterations >= iterations:\n",
        "                break\n",
        "        else:\n",
        "            if np.linalg.norm(x - x_last, ord=norm_order) < tol or counter_iterations >= iterations:\n",
        "                break\n",
        "\n",
        "        x_last = x\n",
        "        counter_iterations += 1\n",
        "\n",
        "    return {\n",
        "        'point': x,\n",
        "        'f': f(x),\n",
        "        'tol': np.linalg.norm(x - x_last, ord=norm_order),\n",
        "        'iterations': counter_iterations,\n",
        "        '1D-iterations': counter_1d_iterations\n",
        "    }\n",
        "\n",
        "\n",
        "def optimize_lls_coordinate_descent(X: np.ndarray, y: np.ndarray, w0: np.ndarray,\n",
        "                                    tol: float = 1e-5,\n",
        "                                    iterations=1000, iterations_over_tolerance: bool = False,\n",
        "                                    norm_order: int = 2):\n",
        "    assert isinstance(w0, np.ndarray)\n",
        "    assert len(np.shape(w0)) == 1\n",
        "    assert tol > 0\n",
        "    assert tol < 1\n",
        "\n",
        "    p = np.size(w0)\n",
        "    w_last = np.copy(w0, order='C')\n",
        "    w = np.copy(w0, order='C')\n",
        "    counter_iterations = 1\n",
        "    r = np.zeros(np.size(y))\n",
        "    while True:\n",
        "        r = y - X @ w\n",
        "\n",
        "        for j in range(p):\n",
        "            r_j = r + w[j] * X[:, j]\n",
        "            w[j] = r_j @ X[:, j]\n",
        "            r = r_j - w[j] * X[:, j]\n",
        "\n",
        "        if iterations_over_tolerance:\n",
        "            if counter_iterations >= iterations:\n",
        "                break\n",
        "        else:\n",
        "            if np.linalg.norm(w - w_last, ord=norm_order) < tol or counter_iterations >= iterations:\n",
        "                break\n",
        "\n",
        "        w_last = np.copy(w, order='C')\n",
        "        counter_iterations += 1\n",
        "\n",
        "    return {\n",
        "        'weights': w,\n",
        "        'residue': np.dot(r, r),\n",
        "        'tol': np.linalg.norm(w - w_last, ord=norm_order),\n",
        "        'iterations': counter_iterations\n",
        "    }\n",
        "\n",
        "\n",
        "# /----- Целевая функция -----\\\n",
        "def rss_function(X, y, w):\n",
        "    delta_y = y - X @ w\n",
        "    return np.dot(delta_y, delta_y)\n",
        "# \\----- Целевая функция -----/\n",
        "\n",
        "\n",
        "# /----- Тестовые функции -----\\\n",
        "# X0 = np.array([5.0, 5.0])\n",
        "def func(X):\n",
        "    return (X[0] - 1)**2 + (X[1] + 2)**2 + 3\n",
        "\n",
        "\n",
        "# Для функции Исома метод покоординатного спуска работает плохо.\n",
        "# X0 = np.array([2.0, 2.0]) # подобранная начальная точка\n",
        "def easom_function(X):\n",
        "    return - np.cos(X[0]) * np.cos(X[1]) * np.exp(- (X[0] - np.pi)**2 - (X[1] - np.pi)**2)\n",
        "\n",
        "# a, b = interval_1d(lambda xi: func(array_put(X0, 0, xi)), X0[0], 0.01)\n",
        "# print(a, b)\n",
        "# optimize_golden_section(lambda xi: func(array_put(X0, 0, xi)), a, b, tol=1e-4)\n",
        "# \\----- Тестовые функции -----/\n",
        "\n",
        "# ==========\n",
        "w0 = np.zeros(np.size(X, axis=1))\n",
        "generic_method_results = optimize_coordinate_descent(\n",
        "    lambda w: rss_function(X, y, w), w0,\n",
        "    tol=1e-8,\n",
        "    iterations=1000, iterations_over_tolerance=True,\n",
        "    sliding_window_1d=0.01, norm_order=2\n",
        ")\n",
        "display(HTML(f\"<u>Results of the <b><i>generic</i></b> coordinate descent method:</u>\"))\n",
        "display(HTML(f\"\"\"<ul>\n",
        "    <li>Linear regression coefficients <b>w = {{{', '.join(map(str, generic_method_results['point']))}}}</b></li>\n",
        "    <li>RSS function minimum: <b>{generic_method_results['f']:.3f}</b></li>\n",
        "    <li>Reached tolerance: <b>{generic_method_results['tol']:e}</b></li>\n",
        "    <li>Coordinate descent iterations: <b>{generic_method_results['iterations']}</b></li>\n",
        "    <li>Total 1D iterations: <b>{generic_method_results['1D-iterations']}</b></li>\n",
        "</ul>\"\"\"))\n",
        "# ==========\n",
        "\n",
        "# ==========\n",
        "w0 = np.zeros(np.size(X, axis=1))\n",
        "lls_method_results = optimize_lls_coordinate_descent(\n",
        "    X, y, w0, tol=1e-8,\n",
        "    iterations=1000, iterations_over_tolerance=True,\n",
        "    norm_order=2\n",
        ")\n",
        "display(HTML(f\"<u>Results of the <b><i>LLS</i></b>-optimized coordinate descent method:</u>\"))\n",
        "display(HTML(f\"\"\"<ul>\n",
        "    <li>Linear regression coefficients <b>w = {{{', '.join(map(str, lls_method_results['weights']))}}}</b></li>\n",
        "    <li>RSS function minimum: <b>{lls_method_results['residue']:.3f}</b></li>\n",
        "    <li>Reached tolerance: <b>{lls_method_results['tol']:e}</b></li>\n",
        "    <li>Coordinate descent iterations: <b>{lls_method_results['iterations']}</b></li>\n",
        "</ul>\"\"\"))\n",
        "# =========="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3jG-7UADUKx"
      },
      "source": [
        "Сравните результаты с реализацией линейной регрессии из библиотеки sklearn:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SBl-1Yb5DUKy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 41.56217205 110.13144155  73.52860638  -0.55006384]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<u>Results of the <b><i>scikit-learn LinearRegression</i></b> model:</u>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<ul>\n",
              "    <li>Linear regression coefficients <b>w = {41.56217204603611, 110.13144155326069, 73.52860637603477, -0.550063841430628}</b></li>\n",
              "</ul>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression(fit_intercept=False)\n",
        "model.fit(X, y)\n",
        "\n",
        "print(model.coef_)\n",
        "\n",
        "display(HTML(f\"<u>Results of the <b><i>scikit-learn LinearRegression</i></b> model:</u>\"))\n",
        "display(HTML(f\"\"\"<ul>\n",
        "    <li>Linear regression coefficients <b>w = {{{', '.join(map(str, model.coef_))}}}</b></li>\n",
        "</ul>\"\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIl0AGLyDUKy"
      },
      "source": [
        "Если вы все сделали верно, они должны практически совпасть!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCGwFnPdDUKz"
      },
      "source": [
        "## Стохастический градиентный спуск (6 баллов)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u7Q2YJla_Xk"
      },
      "source": [
        "**Отмасштабируйте столбцы исходной матрицы *X* (которую мы не нормализовали еще!). Для того, чтобы это сделать, надо вычесть из каждого значения среднее и разделить на стандартное отклонение** (0.5 баллов)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9cEpV_5La_Xo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X[shape=(200, 3)] =\n",
            "[[ 0.96985227  0.98152247  1.77894547]\n",
            " [-1.19737623  1.08280781  0.66957876]\n",
            " [-1.51615499  1.52846331  1.78354865]\n",
            " [ 0.05204968  1.21785493  1.28640506]\n",
            " [ 0.3941822  -0.84161366  1.28180188]]\n",
            "...\n",
            "[[ 0.34981006 -0.942899   -1.11185242]\n",
            " [ 1.59456522  1.26512143  1.64085003]]\n",
            "\n",
            "y[shape=(200,)] =\n",
            "[22.1 10.4  9.3 18.5 12.9]... [12.8 25.5]\n"
          ]
        }
      ],
      "source": [
        "X = data_features.to_numpy(copy=True)\n",
        "y = data_target.to_numpy(copy=True)\n",
        "\n",
        "X = ( (X.T - np.mean(X, axis=0)[:, None]) / np.std(X[:, None], axis=0).T ).T\n",
        "\n",
        "\n",
        "print(f\"X[shape={X.shape}] =\\n{X[0:5, :]}\\n...\\n{X[-3:-1, :]}\")\n",
        "print('')\n",
        "print(f\"y[shape={y.shape}] =\\n{y[0:5]}... {y[-3:-1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WkNYILHDUK1"
      },
      "source": [
        "**Добавим единичный столбец**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EVl5tEGtDUK1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X[shape=(200, 4)] =\n",
            "[[ 1.          0.96985227  0.98152247  1.77894547]\n",
            " [ 1.         -1.19737623  1.08280781  0.66957876]\n",
            " [ 1.         -1.51615499  1.52846331  1.78354865]\n",
            " [ 1.          0.05204968  1.21785493  1.28640506]\n",
            " [ 1.          0.3941822  -0.84161366  1.28180188]]\n",
            "...\n",
            "[[ 1.          0.34981006 -0.942899   -1.11185242]\n",
            " [ 1.          1.59456522  1.26512143  1.64085003]]\n"
          ]
        }
      ],
      "source": [
        "X = np.hstack([np.ones(X.shape[0]).reshape(-1, 1), X])\n",
        "\n",
        "print(f\"X[shape={X.shape}] =\\n{X[0:5, :]}\\n...\\n{X[-3:-1, :]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m53tZA5fDUK1"
      },
      "source": [
        "**Создайте функцию mse_error для вычисления среднеквадратичной ошибки, принимающую два аргумента: реальные значения и предсказывающие, и возвращающую значение mse** (0.5 балла)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0cvtC08Aa_YK"
      },
      "outputs": [],
      "source": [
        "def mse_error(y_test: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "    assert np.size(y_test) == np.size(y_pred)\n",
        "    return (1 / np.size(y_test)) * np.sum( (y_test - y_pred)**2 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpOLhdvBDUK2"
      },
      "source": [
        "**Сделайте наивный прогноз: предскажите продажи средним значением. После этого рассчитайте среднеквадратичную ошибку для этого прогноза** (0.5 балла)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kLV_XljVa_YZ"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span style='color: red'><b>MSE</b> of mean value: <b>27.086</b></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_mean = np.mean(y)\n",
        "y_means = np.full(np.size(y), y_mean)\n",
        "\n",
        "display(HTML(f\"<span style='color: red'><b>MSE</b> of mean value: <b>{mse_error(y_means, y):.3f}</b></span>\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbybL2ola_ZM"
      },
      "source": [
        "**Создайте функцию *lin_pred*, которая может по матрице предикторов *X* и вектору весов линейной модели *w* получить вектор прогнозов** (0.5 балла)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1Cyz-Luaa_ZO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1.          0.96985227  0.98152247  1.77894547]\n",
            " [ 1.         -1.19737623  1.08280781  0.66957876]\n",
            " [ 1.         -1.51615499  1.52846331  1.78354865]\n",
            " [ 1.          0.05204968  1.21785493  1.28640506]\n",
            " [ 1.          0.3941822  -0.84161366  1.28180188]]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<u>Results of the <b><i>generic</i></b> coordinate descent method:</u>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<ul>\n",
              "    <li>Linear regression coefficients <b>w = {14.023, 3.92, 2.793, -0.023}</b></li>\n",
              "    <li>RSS function minimum: <b>556.826</b></li>\n",
              "    <li>Reached tolerance: <b>1.109010e-09</b></li>\n",
              "    <li>Coordinate descent iterations: <b>1000</b></li>\n",
              "    <li>Total 1D iterations: <b>136006</b></li>\n",
              "    <li><span style='color: red'><b>MSE</b> of LLS coordinate descent: <b>2.784</b></span></li>\n",
              "</ul>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ваш код\n",
        "def lin_pred(X: np.ndarray, w: np.ndarray) -> np.ndarray:\n",
        "    assert X.ndim == 2\n",
        "    assert w.ndim == 1\n",
        "    assert np.size(X, axis=1) == np.size(w, axis=0)\n",
        "    print(X[0:5, :])\n",
        "    return X @ w\n",
        "\n",
        "# ==========\n",
        "# Сделаем градиентный спуск generic методом для функции RSS\n",
        "# для самопроверки, что величина MSE будет меньше\n",
        "# по сравнению с MSE, подсчитаной по среднему значению продаж.\n",
        "# ==========\n",
        "w0 = np.zeros(np.size(X, axis=1))\n",
        "generic_method_results = optimize_coordinate_descent(\n",
        "    lambda w: rss_function(X, y, w), w0,\n",
        "    tol=1e-8,\n",
        "    iterations=1000, iterations_over_tolerance=True,\n",
        "    sliding_window_1d=0.01, norm_order=2\n",
        ")\n",
        "y_pred = lin_pred(X, generic_method_results['point'])\n",
        "display(HTML(f\"<u>Results of the <b><i>generic</i></b> coordinate descent method:</u>\"))\n",
        "display(HTML(f\"\"\"<ul>\n",
        "    <li>Linear regression coefficients <b>w = {{{', '.join(map(str, np.round(generic_method_results['point'], 3)))}}}</b></li>\n",
        "    <li>RSS function minimum: <b>{generic_method_results['f']:.3f}</b></li>\n",
        "    <li>Reached tolerance: <b>{generic_method_results['tol']:e}</b></li>\n",
        "    <li>Coordinate descent iterations: <b>{generic_method_results['iterations']}</b></li>\n",
        "    <li>Total 1D iterations: <b>{generic_method_results['1D-iterations']}</b></li>\n",
        "    <li><span style='color: red'><b>MSE</b> of LLS coordinate descent: <b>{mse_error(y_pred, y):.3f}</b></span></li>\n",
        "</ul>\"\"\"))\n",
        "# =========="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU4adBrya_Zm"
      },
      "source": [
        "**Создайте функцию *stoch_grad_step* для реализации шага стохастического градиентного спуска. (1.5 балла) \n",
        "Функция должна принимать на вход следующие аргументы:**\n",
        "* матрицу *X*\n",
        "* вектора *y* и *w*\n",
        "* число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов\n",
        "* число *$\\eta$* (eta) - шаг градиентного спуска\n",
        "\n",
        "Результатом будет вектор обновленных весов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyLY-P02DUK5"
      },
      "source": [
        "Шаг для стохастического градиентного спуска выглядит следующим образом:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORsAyIKNDUK5"
      },
      "source": [
        "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQl2FrpuDUK6"
      },
      "source": [
        "Для того, чтобы написать функцию, нужно сделать следующее:\n",
        "    \n",
        "*  посчитать направление изменения: умножить объект обучающей выборки на 2 и на разницу между предсказанным значением и реальным, а потом поделить на количество элементов в выборке.\n",
        "* вернуть разницу между вектором весов и направлением изменения, умноженным на шаг градиентного спуска"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YUhVQGsja_Zn"
      },
      "outputs": [],
      "source": [
        "def stoch_grad_step(X: np.ndarray, y: np.ndarray, w: np.ndarray, train_ind: int, eta: float) -> np.ndarray:\n",
        "    return w - (2 * eta) * X[train_ind, :] * (X[train_ind, :] @ w - y[train_ind])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXwIFd0Ma_Zx"
      },
      "source": [
        "**Создайте функцию *stochastic_gradient_descent*, для реализации стохастического градиентного спуска (2.5 балла)**\n",
        "\n",
        "**Функция принимает на вход следующие аргументы:**\n",
        "- Матрицу признаков X\n",
        "- Целевую переменнную\n",
        "- Изначальную точку (веса модели)\n",
        "- Параметр, определяющий темп обучения\n",
        "- Максимальное число итераций\n",
        "- Евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,при котором алгоритм прекращает работу \n",
        "\n",
        "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVeoNF1JDUK7"
      },
      "source": [
        "Алгоритм следующий:\n",
        "    \n",
        "* Инициализируйте расстояние между векторами весов на соседних итерациях большим числом (можно бесконечностью)\n",
        "* Создайте пустой список для фиксации ошибок\n",
        "* Создайте счетчик итераций\n",
        "* Реализуйте оновной цикл обучения пока расстояние между векторами весов больше того, при котором надо прекратить работу (когда расстояния станут слишком маленькими - значит, мы застряли в одном месте) и количество итераций меньше максимально разрешенного: сгенерируйте случайный индекс, запишите текущую ошибку в вектор ошибок, запишите в переменную текущий шаг стохастического спуска с использованием функции, написанной ранее. Далее рассчитайте текущее расстояние между векторами весов и прибавьте к счетчику итераций 1.\n",
        "* Верните вектор весов и вектор ошибок"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CD_xcFNfa_Zy"
      },
      "outputs": [],
      "source": [
        "def stochastic_gradient_descent(\n",
        "    X: np.ndarray, y: np.ndarray, w0: np.ndarray,\n",
        "    eta_rate: float = 0.05,\n",
        "    iterations: int = 1000, iterations_over_tolerance: bool = False,\n",
        "    tol: float = 1e-5) -> np.ndarray:\n",
        "    assert X.ndim == 2\n",
        "    assert y.ndim == 1\n",
        "    assert w0.ndim == 1\n",
        "    assert np.size(X, axis=0) == np.size(y, axis=0)\n",
        "    assert np.size(X, axis=1) == np.size(w0, axis=0)\n",
        "    assert eta_rate > 0\n",
        "    assert iterations > 0\n",
        "    assert tol > 0\n",
        "\n",
        "    # =====\n",
        "    w = np.copy(w0)\n",
        "    w_last = np.copy(w0 + 1000)\n",
        "    N = np.size(X, axis=0)\n",
        "    counter_iterations = 1\n",
        "    # -----\n",
        "    error_list = list()\n",
        "    # -----\n",
        "    while True:\n",
        "        train_ind = np.random.randint(low=0, high=N)\n",
        "        w = stoch_grad_step(X, y, w, train_ind=train_ind, eta=eta_rate)\n",
        "\n",
        "        error = mse_error(y_test=y, y_pred=X @ w)\n",
        "        error_list.append(error)\n",
        "\n",
        "        if iterations_over_tolerance:\n",
        "            if counter_iterations >= iterations:\n",
        "                break\n",
        "        else:\n",
        "            if np.linalg.norm(w - w_last, ord=2) < tol or counter_iterations >= iterations:\n",
        "                break\n",
        "\n",
        "        w_last = np.copy(w)\n",
        "        counter_iterations += 1\n",
        "    # =====\n",
        "    \n",
        "    return {\n",
        "        'weights': w,\n",
        "        'errors': np.array(error_list),\n",
        "        'last_error': error_list[-1],\n",
        "        'tol': np.linalg.norm(w - w_last, ord=2),\n",
        "        'iterations': counter_iterations\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OqHO1Rta_Z7"
      },
      "source": [
        " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов, состоящий из нулей. Можете поэкспериментировать с параметром, отвечающим за темп обучения.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6fHHT6vDUK8"
      },
      "source": [
        "**Постройте график зависимости ошибки от номера итерации**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zsSfHDzLDUK9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set_theme(style='whitegrid')\n",
        "\n",
        "\n",
        "w0 = np.zeros(np.size(X, axis=1))\n",
        "sgd_results = stochastic_gradient_descent(X, y, w0,\n",
        "    eta_rate=0.0001,\n",
        "    iterations=int(1e5), iterations_over_tolerance=True,\n",
        "    tol=1e-5\n",
        ")\n",
        "\n",
        "mse_errors = sgd_results['errors']\n",
        "mse_errors_plot = sns.lineplot(x=np.arange(1, np.size(mse_errors) + 1), y=mse_errors)\n",
        "mse_errors_plot.set(xscale='log')\n",
        "mse_errors_plot.set_xlabel(\"Number of iterations\", fontsize = 10)\n",
        "mse_errors_plot.set_ylabel(\"Mean Squared Error (MSE)\", fontsize = 10)\n",
        "mse_errors_plot.set_title(\"SGD MSE\", fontsize = 12)\n",
        "plt.show(mse_errors_plot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-MVOcJ6a_aY"
      },
      "source": [
        "**Выведите вектор весов, к которому сошелся метод.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MPjVkXe4DUK9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<u>Results of the <b><i>Stochatic Gradient Descent</i></b> method:</u>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<ul>\n",
              "    <li><span style='color: blue'>Linear regression coefficients <b>w = {14.032, 3.932, 2.786, 0.006}</b></span></li>\n",
              "    <li>MSE errors: <b>[223.53069, 223.51519, 223.37002, 223.32484, 223.22726... 2.78518, 2.78518, 2.78518]</b></li>\n",
              "    <li>Reached tolerance: <b>8.354070e-04</b></li>\n",
              "    <li>SGD iterations: <b>100000</b></li>\n",
              "    <li><span style='color: red'><b>MSE</b> of Stochatic Gradient Descent: <b>2.785</b></span></li>\n",
              "</ul>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(HTML(f\"<u>Results of the <b><i>Stochatic Gradient Descent</i></b> method:</u>\"))\n",
        "display(HTML(f\"\"\"<ul>\n",
        "    <li><span style='color: blue'>Linear regression coefficients <b>w = {{{', '.join(map(str, np.round(sgd_results['weights'], 3)))}}}</b></span></li>\n",
        "    <li>MSE errors: <b>[{', '.join(map(str, np.round(sgd_results['errors'][0:5], 5)))}... {', '.join(map(str, np.round(sgd_results['errors'][-4:-1], 5)))}]</b></li>\n",
        "    <li>Reached tolerance: <b>{sgd_results['tol']:e}</b></li>\n",
        "    <li>SGD iterations: <b>{sgd_results['iterations']}</b></li>\n",
        "    <li><span style='color: red'><b>MSE</b> of Stochatic Gradient Descent: <b>{sgd_results['last_error']:.3f}</b></span></li>\n",
        "</ul>\"\"\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qabzMc3Qa_a5"
      },
      "source": [
        "**Выведите среднеквадратичную ошибку на последней итерации.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7tPWleMIa_a7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span style='color: darkred'>Last <b>MSE</b> of Stochatic Gradient Descent: <b>2.785</b></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(HTML(f\"<span style='color: darkred'>Last <b>MSE</b> of Stochatic Gradient Descent: <b>{sgd_results['last_error']:.3f}</b></span>\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Практика_Оптимизация.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "510017f941ecd040108aa6155b7d7920a30c358be25c6738528295864459697b"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('data-science')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
