{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Базовые библиотеки и настройки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install termcolor\n",
    "# !conda install -c conda-forge termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Глобальные переменные и типы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Verbosity(Enum):\n",
    "    NONE = 1\n",
    "    BASIC_TIME = 2\n",
    "    ADVANCED_TIME_SCORE = 3\n",
    "    EXTREME_TIME_SCORE_PARAMETERS = 3\n",
    "\n",
    "\n",
    "ML_SEED = 42\n",
    "ML_JOBS = 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Логирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "from termcolor import colored\n",
    "\n",
    "\n",
    "DEFAULT_LOGGER_NAME = \"Hyper-Parameters\"\n",
    "\n",
    "\n",
    "def setup_applevel_logger(logger_name=DEFAULT_LOGGER_NAME, file_name=None):\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    formatter = logging.Formatter(\n",
    "        \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "    sh = logging.StreamHandler(sys.stdout)\n",
    "    sh.setFormatter(formatter)\n",
    "\n",
    "    logger.handlers.clear()\n",
    "    logger.addHandler(sh)\n",
    "\n",
    "    if file_name:\n",
    "        fh = logging.FileHandler(file_name)\n",
    "        fh.setFormatter(formatter)\n",
    "        logger.addHandler(fh)\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "# def get_logger(module_name):\n",
    "#    return logging.getLogger(DEFAULT_LOGGER_NAME).getChild(module_name)\n",
    "\n",
    "\n",
    "LOG = setup_applevel_logger(file_name=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "\n",
       "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
       "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
       "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
       "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1777 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('_train_sem09.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Activity', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=data, x=\"Activity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Базовые модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from typing import Type\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def make_holdout_sample_sklearn(X: pd.DataFrame, Y: pd.Series,\n",
    "                                holdout_sample_size: float = 0.2, seed: int = None,\n",
    "                                shuffle: bool = True, stratify: Any | None = None):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                        test_size=holdout_sample_size,\n",
    "                                                        random_state=seed,\n",
    "                                                        shuffle=shuffle, stratify=stratify)\n",
    "    LOG.info(\n",
    "        f\"A holdout sample is selected. Train sample size - {len(Y_train)} ({1 - holdout_sample_size}), test sample size {len(Y_test)} ({holdout_sample_size}).\")\n",
    "\n",
    "    return {\n",
    "        \"X_train\": X_train,\n",
    "        \"Y_train\": Y_train,\n",
    "        \"X_test\": X_test,\n",
    "        \"Y_test\": Y_test\n",
    "    }\n",
    "\n",
    "\n",
    "def log_f1_scores(samples, optimization_algorithm_instance, log_precision_recall_accuracy=True):\n",
    "    Y_predicted_train = optimization_algorithm_instance.predict(samples[\"X_train\"])\n",
    "    LOG.info(f\"{colored('F1-score', 'red')}, train dataset: {metrics.f1_score(samples['Y_train'], Y_predicted_train)}\")\n",
    "    if log_precision_recall_accuracy:\n",
    "        LOG.info(f\"{colored('Precision', 'magenta')}, train dataset: {metrics.precision_score(samples['Y_train'], Y_predicted_train)}\")\n",
    "        LOG.info(f\"{colored('Recall', 'blue')}, train dataset: {metrics.recall_score(samples['Y_train'], Y_predicted_train)}\")\n",
    "        LOG.info(f\"{colored('Accuracy', 'green')}, train dataset: {metrics.accuracy_score(samples['Y_train'], Y_predicted_train)}\")\n",
    "    LOG.info(\"-----\")\n",
    "    Y_predicted_test = optimization_algorithm_instance.predict(samples[\"X_test\"])\n",
    "    LOG.info(f\"{colored('F1-score', 'red')}, test dataset: {metrics.f1_score(samples['Y_test'], Y_predicted_test)}\")\n",
    "    if log_precision_recall_accuracy:\n",
    "        LOG.info(f\"{colored('Precision', 'magenta')}, test dataset: {metrics.precision_score(samples['Y_test'], Y_predicted_test)}\")\n",
    "        LOG.info(f\"{colored('Recall', 'blue')}, test dataset: {metrics.recall_score(samples['Y_test'], Y_predicted_test)}\")\n",
    "        LOG.info(f\"{colored('Accuracy', 'green')}, test dataset: {metrics.accuracy_score(samples['Y_test'], Y_predicted_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-14 21:27:02,423 - Hyper-Parameters - INFO - A holdout sample is selected. Train sample size - 3000 (0.8), test sample size 751 (0.2).\n",
      "2022-07-14 21:27:04,018 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, train dataset: 0.850828729281768\n",
      "2022-07-14 21:27:04,019 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, train dataset: 0.8497854077253219\n",
      "2022-07-14 21:27:04,020 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, train dataset: 0.8518746158574063\n",
      "2022-07-14 21:27:04,020 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, train dataset: 0.838\n",
      "2022-07-14 21:27:04,021 - Hyper-Parameters - INFO - -----\n",
      "2022-07-14 21:27:04,031 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, test dataset: 0.7853658536585365\n",
      "2022-07-14 21:27:04,032 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, test dataset: 0.7796610169491526\n",
      "2022-07-14 21:27:04,034 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, test dataset: 0.7911547911547911\n",
      "2022-07-14 21:27:04,034 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, test dataset: 0.7656458055925432\n"
     ]
    }
   ],
   "source": [
    "target_feature_name = 'Activity'\n",
    "X = data.drop([target_feature_name], axis=1)\n",
    "Y = data[target_feature_name]\n",
    "samples = make_holdout_sample_sklearn(\n",
    "    X, Y,\n",
    "    holdout_sample_size=0.2,\n",
    "    seed=ML_SEED,\n",
    "    shuffle=True,\n",
    "    stratify=Y\n",
    ")\n",
    "\n",
    "model = linear_model.LogisticRegression(\n",
    "    C=0.1,\n",
    "    penalty='l2',\n",
    "    solver='sag',\n",
    "    class_weight='balanced',\n",
    "    max_iter=50,\n",
    "    n_jobs=ML_JOBS,\n",
    "    random_state=ML_SEED\n",
    ")\n",
    "model.fit(samples[\"X_train\"], samples['Y_train'])\n",
    "\n",
    "\n",
    "log_f1_scores(samples, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-14 21:30:53,615 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, train dataset: 0.8470732454796199\n",
      "2022-07-14 21:30:53,617 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, train dataset: 0.8447432762836186\n",
      "2022-07-14 21:30:53,618 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, train dataset: 0.8494161032575291\n",
      "2022-07-14 21:30:53,619 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, train dataset: 0.8336666666666667\n",
      "2022-07-14 21:30:53,619 - Hyper-Parameters - INFO - -----\n",
      "2022-07-14 21:30:53,662 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, test dataset: 0.7852028639618138\n",
      "2022-07-14 21:30:53,664 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, test dataset: 0.7633410672853829\n",
      "2022-07-14 21:30:53,665 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, test dataset: 0.8083538083538083\n",
      "2022-07-14 21:30:53,665 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, test dataset: 0.7603195739014648\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    criterion='entropy',\n",
    "    max_depth=6,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=0.5,\n",
    "    bootstrap=True,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=ML_JOBS,\n",
    "    random_state=ML_SEED\n",
    ")\n",
    "model.fit(samples[\"X_train\"], samples['Y_train'])\n",
    "\n",
    "log_f1_scores(samples, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Базовая оптимизация моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from typing import Type\n",
    "from sklearn.model_selection._search import BaseSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "from sklearn import exceptions\n",
    "\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=exceptions.ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=exceptions.ConvergenceWarning)\n",
    "\n",
    "\n",
    "def make_holdout_sample_sklearn(X: pd.DataFrame, Y: pd.Series,\n",
    "                                holdout_sample_size: float = 0.2, seed: int = None,\n",
    "                                shuffle: bool = True, stratify: Any | None = None):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                        test_size=holdout_sample_size,\n",
    "                                                        random_state=seed,\n",
    "                                                        shuffle=shuffle, stratify=stratify)\n",
    "    LOG.info(\n",
    "        f\"A holdout sample is selected. Train sample size - {len(Y_train)} ({1 - holdout_sample_size}), test sample size {len(Y_test)} ({holdout_sample_size}).\")\n",
    "\n",
    "    return {\n",
    "        \"X_train\": X_train,\n",
    "        \"Y_train\": Y_train,\n",
    "        \"X_test\": X_test,\n",
    "        \"Y_test\": Y_test\n",
    "    }\n",
    "\n",
    "\n",
    "def optimize_model_sklearn(data: pd.DataFrame, target_feature_name: str,\n",
    "                           base_model_instance,\n",
    "                           Type_optimization_algorithm: Type[BaseSearchCV], scoring_type: str,\n",
    "                           hyper_parameters, cross_validation_parameter,\n",
    "                           holdout_sample_size: float = 0.2, holdout_shuffle: bool = True,\n",
    "                           max_iterations: int = 50,\n",
    "                           verbosity: Verbosity = Verbosity.BASIC_TIME,\n",
    "                           seed: int = None,\n",
    "                           n_jobs: int = -1):\n",
    "    assert Type_optimization_algorithm in [\n",
    "        GridSearchCV, RandomizedSearchCV], \"Supported optimizator types: GridSearchCV, RandomizedSearchCV.\"\n",
    "\n",
    "    LOG.info(\"Optimization begins...\")\n",
    "\n",
    "    X = data.drop([target_feature_name], axis=1)\n",
    "    Y = data[target_feature_name]\n",
    "    XY_samples = make_holdout_sample_sklearn(\n",
    "        X, Y,\n",
    "        holdout_sample_size=holdout_sample_size,\n",
    "        seed=seed,\n",
    "        shuffle=holdout_shuffle,\n",
    "        stratify=Y\n",
    "    )\n",
    "\n",
    "    optimization_algorithm_instance: BaseSearchCV = None\n",
    "\n",
    "    if GridSearchCV == Type_optimization_algorithm:\n",
    "        optimization_algorithm_instance = GridSearchCV(\n",
    "            estimator=base_model_instance,\n",
    "            param_grid=hyper_parameters,\n",
    "            scoring=scoring_type,\n",
    "            n_jobs=n_jobs,\n",
    "            cv=cross_validation_parameter,\n",
    "            verbose=verbosity.value\n",
    "        )\n",
    "    elif RandomizedSearchCV == Type_optimization_algorithm:\n",
    "        optimization_algorithm_instance = RandomizedSearchCV(\n",
    "            estimator=base_model_instance,\n",
    "            param_distributions=hyper_parameters,\n",
    "            n_iter=max_iterations,\n",
    "            scoring=scoring_type,\n",
    "            n_jobs=n_jobs,\n",
    "            cv=cross_validation_parameter,\n",
    "            verbose=verbosity.value\n",
    "        )\n",
    "    else:\n",
    "        raise AssertionError(\n",
    "            \"Supported optimizator types: GridSearchCV, RandomizedSearchCV.\")\n",
    "\n",
    "    LOG.info(f\"Selected optimizator algorithm - {type(optimization_algorithm_instance)}.\")\n",
    "\n",
    "    X_train = XY_samples[\"X_train\"]\n",
    "    Y_train = XY_samples[\"Y_train\"]\n",
    "    LOG.info(\"Hyperparameters fitting...\")\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=exceptions.ConvergenceWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category=exceptions.ConvergenceWarning)\n",
    "        %time optimization_algorithm_instance.fit(X_train, Y_train)\n",
    "    LOG.info(\"Hyperparameters fitting... done.\")\n",
    "\n",
    "    X_test = XY_samples[\"X_test\"]\n",
    "    Y_test = XY_samples[\"Y_test\"]\n",
    "    score_value = optimization_algorithm_instance.score(X_test, Y_test)\n",
    "    LOG.info(f\"Best '{scoring_type}' value - {score_value}\")\n",
    "    LOG.info(f\"Best hyper-parameters found:\\n{optimization_algorithm_instance.best_params_}\")\n",
    "\n",
    "    return optimization_algorithm_instance, XY_samples\n",
    "\n",
    "\n",
    "def log_f1_scores(samples, optimization_algorithm_instance, log_precision_recall_accuracy=True):\n",
    "    Y_predicted_train = optimization_algorithm_instance.predict(samples[\"X_train\"])\n",
    "    LOG.info(f\"{colored('F1-score', 'red')}, train dataset: {metrics.f1_score(samples['Y_train'], Y_predicted_train)}\")\n",
    "    if log_precision_recall_accuracy:\n",
    "        LOG.info(f\"{colored('Precision', 'magenta')}, train dataset: {metrics.precision_score(samples['Y_train'], Y_predicted_train)}\")\n",
    "        LOG.info(f\"{colored('Recall', 'blue')}, train dataset: {metrics.recall_score(samples['Y_train'], Y_predicted_train)}\")\n",
    "        LOG.info(f\"{colored('Accuracy', 'green')}, train dataset: {metrics.accuracy_score(samples['Y_train'], Y_predicted_train)}\")\n",
    "    LOG.info(\"-----\")\n",
    "    Y_predicted_test = optimization_algorithm_instance.predict(samples[\"X_test\"])\n",
    "    LOG.info(f\"{colored('F1-score', 'red')}, test dataset: {metrics.f1_score(samples['Y_test'], Y_predicted_test)}\")\n",
    "    if log_precision_recall_accuracy:\n",
    "        LOG.info(f\"{colored('Precision', 'magenta')}, test dataset: {metrics.precision_score(samples['Y_test'], Y_predicted_test)}\")\n",
    "        LOG.info(f\"{colored('Recall', 'blue')}, test dataset: {metrics.recall_score(samples['Y_test'], Y_predicted_test)}\")\n",
    "        LOG.info(f\"{colored('Accuracy', 'green')}, test dataset: {metrics.accuracy_score(samples['Y_test'], Y_predicted_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 `GridSearchCV` + `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-14 18:39:11,307 - Hyper-Parameters - INFO - Optimization begins...\n",
      "2022-07-14 18:39:11,380 - Hyper-Parameters - INFO - A holdout sample is selected. Train sample size - 3000 (0.8), test sample size 751 (0.2).\n",
      "2022-07-14 18:39:11,381 - Hyper-Parameters - INFO - Selected optimizator algorithm - <class 'sklearn.model_selection._search.GridSearchCV'>.\n",
      "2022-07-14 18:39:11,382 - Hyper-Parameters - INFO - Hyperparameters fitting...\n",
      "Fitting 5 folds for each of 528 candidates, totalling 2640 fits\n",
      "CPU times: user 15.9 s, sys: 1.66 s, total: 17.5 s\n",
      "Wall time: 3min 36s\n",
      "2022-07-14 18:42:48,299 - Hyper-Parameters - INFO - Hyperparameters fitting... done.\n",
      "2022-07-14 18:42:48,350 - Hyper-Parameters - INFO - Best 'f1' value - 0.7834319526627218\n",
      "2022-07-14 18:42:48,351 - Hyper-Parameters - INFO - Best hyper-parameters found:\n",
      "{'C': 0.055, 'class_weight': None, 'max_iter': 40, 'n_jobs': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "2022-07-14 18:42:48,432 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, train dataset: 0.8439271859146522\n",
      "2022-07-14 18:42:48,434 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, train dataset: 0.820185614849188\n",
      "2022-07-14 18:42:48,435 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, train dataset: 0.8690842040565457\n",
      "2022-07-14 18:42:48,438 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, train dataset: 0.8256666666666667\n",
      "2022-07-14 18:42:48,438 - Hyper-Parameters - INFO - -----\n",
      "2022-07-14 18:42:48,448 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, test dataset: 0.7834319526627218\n",
      "2022-07-14 18:42:48,449 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, test dataset: 0.7557077625570776\n",
      "2022-07-14 18:42:48,450 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, test dataset: 0.8132678132678133\n",
      "2022-07-14 18:42:48,451 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, test dataset: 0.7563249001331558\n"
     ]
    }
   ],
   "source": [
    "hyper_parameters = [\n",
    "    # {\n",
    "    #     'penalty': ['l2'], # 'none' не сходится ни при каком числе итераций\n",
    "    #     'solver': ['lbfgs'],\n",
    "    #     'C': np.arange(0.014, 0.02+0.001, 0.001),\n",
    "    #     'class_weight': ['balanced', None],\n",
    "    #     'max_iter': np.arange(400, 900+100, 100),\n",
    "    #     'n_jobs' : [ML_JOBS]\n",
    "    # },\n",
    "    # {\n",
    "    #     'penalty': ['l2'], # 'none' не сходится ни при каком числе итераций\n",
    "    #     'solver': ['sag'],\n",
    "    #     'C': np.arange(0.016, 0.024+0.001, 0.001),\n",
    "    #     'class_weight': ['balanced', None],\n",
    "    #     'max_iter': np.arange(400, 900+100, 100),\n",
    "    #     'n_jobs' : [ML_JOBS]\n",
    "    # },\n",
    "    # {\n",
    "    #     'penalty': ['l1'],  # С 'none' не сходится ни при каком числе итераций.\n",
    "    #     'solver': ['saga'],\n",
    "    #     'C': np.arange(0.001, 0.01+0.001, 0.001),\n",
    "    #     'class_weight': ['balanced', None],\n",
    "    #     'max_iter': np.arange(400, 900+100, 100),\n",
    "    #     'n_jobs' : [ML_JOBS]\n",
    "    # },\n",
    "    # {\n",
    "    #     'penalty': ['l2'],\n",
    "    #     'solver': ['saga'],\n",
    "    #     'C': np.arange(0.015, 0.03+0.001, 0.001),\n",
    "    #     'class_weight': ['balanced', None],\n",
    "    #     'max_iter': np.arange(400, 900+100, 100),\n",
    "    #     'n_jobs' : [ML_JOBS]\n",
    "    # },\n",
    "    # {\n",
    "    #     'penalty': ['elasticnet'],\n",
    "    #     'solver': ['saga'],\n",
    "    #     'C': np.arange(0.018, 0.027+0.001, 0.001),\n",
    "    #     'class_weight': ['balanced', None],\n",
    "    #     'max_iter': np.arange(400, 900+100, 100),\n",
    "    #     'l1_ratio': np.arange(0.006, 0.012+0.001, 0.001),\n",
    "    #     'n_jobs' : [ML_JOBS]\n",
    "    # },\n",
    "    {\n",
    "        'penalty': ['l1', 'l2'], # С 'elasticnet' не сходится в принципе.\n",
    "        'solver': ['liblinear'],\n",
    "        'C': np.arange(0.05, 0.1+0.005, 0.005),\n",
    "        'class_weight': ['balanced', None],\n",
    "        'max_iter': np.arange(40, 60+2, 2),\n",
    "        'n_jobs' : [1]\n",
    "    },\n",
    "    # {\n",
    "    #     'penalty': ['l2'], # 'none' при увеличении числа итераций не даёт сходимости.\n",
    "    #     'solver': ['newton-cg'],\n",
    "    #     'C': np.arange(0.05, 0.1+0.005, 0.005),\n",
    "    #     'class_weight': ['balanced', None],\n",
    "    #     'max_iter': np.arange(40, 60+2, 2),\n",
    "    #     'n_jobs' : [ML_JOBS]\n",
    "    # }\n",
    "]\n",
    "\n",
    "base_model = linear_model.LogisticRegression(random_state=ML_SEED, n_jobs=ML_JOBS)\n",
    "optimization_algorithm_instance, samples = optimize_model_sklearn(data, \"Activity\",\n",
    "                                                                  base_model,\n",
    "                                                                  GridSearchCV, scoring_type='f1',\n",
    "                                                                  hyper_parameters=hyper_parameters, cross_validation_parameter=5,\n",
    "                                                                  holdout_sample_size=0.2, holdout_shuffle=True,\n",
    "                                                                  verbosity=Verbosity.NONE,\n",
    "                                                                  seed=ML_SEED,\n",
    "                                                                  n_jobs=ML_JOBS)\n",
    "\n",
    "\n",
    "log_f1_scores(samples, optimization_algorithm_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 `RandomizedSearchCV` + `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-14 18:43:21,829 - Hyper-Parameters - INFO - Optimization begins...\n",
      "2022-07-14 18:43:21,924 - Hyper-Parameters - INFO - A holdout sample is selected. Train sample size - 3000 (0.8), test sample size 751 (0.2).\n",
      "2022-07-14 18:43:21,924 - Hyper-Parameters - INFO - Selected optimizator algorithm - <class 'sklearn.model_selection._search.RandomizedSearchCV'>.\n",
      "2022-07-14 18:43:21,925 - Hyper-Parameters - INFO - Hyperparameters fitting...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "CPU times: user 11.4 s, sys: 159 ms, total: 11.6 s\n",
      "Wall time: 5min 43s\n",
      "2022-07-14 18:49:05,368 - Hyper-Parameters - INFO - Hyperparameters fitting... done.\n",
      "2022-07-14 18:49:05,394 - Hyper-Parameters - INFO - Best 'f1' value - 0.7796208530805686\n",
      "2022-07-14 18:49:05,396 - Hyper-Parameters - INFO - Best hyper-parameters found:\n",
      "{'solver': 'saga', 'penalty': 'elasticnet', 'n_jobs': 12, 'max_iter': 400, 'l1_ratio': 0.011, 'class_weight': None, 'C': 0.021}\n",
      "2022-07-14 18:49:05,427 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, train dataset: 0.829487563679952\n",
      "2022-07-14 18:49:05,429 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, train dataset: 0.8093567251461988\n",
      "2022-07-14 18:49:05,430 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, train dataset: 0.8506453595574678\n",
      "2022-07-14 18:49:05,431 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, train dataset: 0.8103333333333333\n",
      "2022-07-14 18:49:05,431 - Hyper-Parameters - INFO - -----\n",
      "2022-07-14 18:49:05,445 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, test dataset: 0.7796208530805686\n",
      "2022-07-14 18:49:05,446 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, test dataset: 0.7528604118993135\n",
      "2022-07-14 18:49:05,447 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, test dataset: 0.8083538083538083\n",
      "2022-07-14 18:49:05,447 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, test dataset: 0.7523302263648469\n"
     ]
    }
   ],
   "source": [
    "hyper_parameters = [\n",
    "    {\n",
    "        'penalty': ['l2'], # 'none' не сходится ни при каком числе итераций\n",
    "        'solver': ['lbfgs'],\n",
    "        'C': np.arange(0.014, 0.02+0.001, 0.001),\n",
    "        'class_weight': ['balanced', None],\n",
    "        'max_iter': np.arange(400, 900+100, 100),\n",
    "        'n_jobs' : [ML_JOBS]\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['l2'], # 'none' не сходится ни при каком числе итераций\n",
    "        'solver': ['sag'],\n",
    "        'C': np.arange(0.016, 0.024+0.001, 0.001),\n",
    "        'class_weight': ['balanced', None],\n",
    "        'max_iter': np.arange(400, 900+100, 100),\n",
    "        'n_jobs' : [ML_JOBS]\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['l1'],  # С 'none' не сходится ни при каком числе итераций.\n",
    "        'solver': ['saga'],\n",
    "        'C': np.arange(0.001, 0.01+0.001, 0.001),\n",
    "        'class_weight': ['balanced', None],\n",
    "        'max_iter': np.arange(400, 900+100, 100),\n",
    "        'n_jobs' : [ML_JOBS]\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['saga'],\n",
    "        'C': np.arange(0.015, 0.03+0.001, 0.001),\n",
    "        'class_weight': ['balanced', None],\n",
    "        'max_iter': np.arange(400, 900+100, 100),\n",
    "        'n_jobs' : [ML_JOBS]\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['elasticnet'],\n",
    "        'solver': ['saga'],\n",
    "        'C': np.arange(0.018, 0.027+0.001, 0.001),\n",
    "        'class_weight': ['balanced', None],\n",
    "        'max_iter': np.arange(400, 900+100, 100),\n",
    "        'l1_ratio': np.arange(0.006, 0.012+0.001, 0.001),\n",
    "        'n_jobs' : [ML_JOBS]\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['l1', 'l2'], # С 'elasticnet' не сходится в принципе.\n",
    "        'solver': ['liblinear'],\n",
    "        'C': np.arange(0.05, 0.1+0.005, 0.005),\n",
    "        'class_weight': ['balanced', None],\n",
    "        'max_iter': np.arange(40, 60+2, 2),\n",
    "        'n_jobs' : [1]\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['l2'], # 'none' при увеличении числа итераций не даёт сходимости.\n",
    "        'solver': ['newton-cg'],\n",
    "        'C': np.arange(0.05, 0.1+0.005, 0.005),\n",
    "        'class_weight': ['balanced', None],\n",
    "        'max_iter': np.arange(40, 60+2, 2),\n",
    "        'n_jobs' : [ML_JOBS]\n",
    "    }\n",
    "]\n",
    "\n",
    "base_model = linear_model.LogisticRegression(random_state=ML_SEED)\n",
    "optimization_algorithm_instance, samples = optimize_model_sklearn(data, \"Activity\",\n",
    "                                                                  base_model,\n",
    "                                                                  RandomizedSearchCV, scoring_type='f1',\n",
    "                                                                  hyper_parameters=hyper_parameters, cross_validation_parameter=5,\n",
    "                                                                  holdout_sample_size=0.2, holdout_shuffle=True,\n",
    "                                                                  max_iterations=100,\n",
    "                                                                  verbosity=Verbosity.NONE,\n",
    "                                                                  seed=ML_SEED,\n",
    "                                                                  n_jobs=ML_JOBS)\n",
    "\n",
    "log_f1_scores(samples, optimization_algorithm_instance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 `RandomizedSearchCV` + `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-14 18:49:38,988 - Hyper-Parameters - INFO - Optimization begins...\n",
      "2022-07-14 18:49:39,071 - Hyper-Parameters - INFO - A holdout sample is selected. Train sample size - 3000 (0.8), test sample size 751 (0.2).\n",
      "2022-07-14 18:49:39,072 - Hyper-Parameters - INFO - Selected optimizator algorithm - <class 'sklearn.model_selection._search.RandomizedSearchCV'>.\n",
      "2022-07-14 18:49:39,073 - Hyper-Parameters - INFO - Hyperparameters fitting...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "CPU times: user 45 s, sys: 108 ms, total: 45.1 s\n",
      "Wall time: 2min 37s\n",
      "2022-07-14 18:52:16,269 - Hyper-Parameters - INFO - Hyperparameters fitting... done.\n",
      "2022-07-14 18:52:16,339 - Hyper-Parameters - INFO - Best 'f1' value - 0.795266272189349\n",
      "2022-07-14 18:52:16,340 - Hyper-Parameters - INFO - Best hyper-parameters found:\n",
      "{'n_jobs': 12, 'n_estimators': 350, 'min_samples_leaf': 4, 'max_features': 0.34500000000000003, 'max_depth': 8, 'criterion': 'log_loss', 'class_weight': None, 'bootstrap': True}\n",
      "2022-07-14 18:52:16,439 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, train dataset: 0.884627092846271\n",
      "2022-07-14 18:52:16,441 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, train dataset: 0.876357056694813\n",
      "2022-07-14 18:52:16,443 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, train dataset: 0.8930547019053473\n",
      "2022-07-14 18:52:16,444 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, train dataset: 0.8736666666666667\n",
      "2022-07-14 18:52:16,444 - Hyper-Parameters - INFO - -----\n",
      "2022-07-14 18:52:16,516 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, test dataset: 0.795266272189349\n",
      "2022-07-14 18:52:16,517 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, test dataset: 0.7671232876712328\n",
      "2022-07-14 18:52:16,518 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, test dataset: 0.8255528255528255\n",
      "2022-07-14 18:52:16,519 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, test dataset: 0.7696404793608522\n"
     ]
    }
   ],
   "source": [
    "hyper_parameters = [\n",
    "    {\n",
    "        'n_estimators': [250, 300, 350], # Увеличение числа деревьев не сильно даёт улучшение здесь: 200, 300 или 500 - разница невелика.\n",
    "        'criterion': [\"entropy\", \"log_loss\"], # Эти параметры могут выигрывать попеременно, вероятно в зависимости от max_features.\n",
    "        'max_depth': [7, 8], # Какой диапазон, ни ставь, в целом выбираются более переобученные модели с большей глубиной.\n",
    "        'min_samples_leaf': [3, 4], # Аналогично, но в сторону уменьшения числа примеров в листе.\n",
    "        'max_features' : np.arange(0.33, 0.39, 0.005), # Примерно в интервале от 0.29 до 0.4 могут получаться приличные пары значений f1-score на выборках train и test.\n",
    "        'bootstrap': [True], # Всегда выигрывало значение True.\n",
    "        'class_weight' : [\"balanced\", None], # Всегда выигрывало значение \"balanced\".\n",
    "        'n_jobs' : [ML_JOBS] # Иногда помогает уменьшать затраченное машинное время при одновременном параллельном вычислении в RandomizedSearchCV.\n",
    "    }\n",
    "]\n",
    "\n",
    "base_model = ensemble.RandomForestClassifier(random_state=ML_SEED)\n",
    "optimization_algorithm_instance, samples = optimize_model_sklearn(data, \"Activity\",\n",
    "                                                                  base_model,\n",
    "                                                                  RandomizedSearchCV, scoring_type='f1',\n",
    "                                                                  hyper_parameters=hyper_parameters, cross_validation_parameter=5,\n",
    "                                                                  holdout_sample_size=0.2, holdout_shuffle=True,\n",
    "                                                                  max_iterations=10,\n",
    "                                                                  verbosity=Verbosity.NONE,\n",
    "                                                                  seed=ML_SEED,\n",
    "                                                                  n_jobs=ML_JOBS + 2)\n",
    "\n",
    "\n",
    "log_f1_scores(samples, optimization_algorithm_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 `GridSearchCV` + `RandomForestClassifier`\n",
    "\n",
    "Приходится ограничивать наборы параметров, чтобы их полный перебор не занимал сутки и более."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-14 19:47:01,709 - Hyper-Parameters - INFO - Optimization begins...\n",
      "2022-07-14 19:47:01,776 - Hyper-Parameters - INFO - A holdout sample is selected. Train sample size - 3000 (0.8), test sample size 751 (0.2).\n",
      "2022-07-14 19:47:01,777 - Hyper-Parameters - INFO - Selected optimizator algorithm - <class 'sklearn.model_selection._search.GridSearchCV'>.\n",
      "2022-07-14 19:47:01,777 - Hyper-Parameters - INFO - Hyperparameters fitting...\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "CPU times: user 31.2 s, sys: 314 ms, total: 31.5 s\n",
      "Wall time: 23min 53s\n",
      "2022-07-14 20:10:55,783 - Hyper-Parameters - INFO - Hyperparameters fitting... done.\n",
      "2022-07-14 20:10:55,839 - Hyper-Parameters - INFO - Best 'f1' value - 0.7947805456702255\n",
      "2022-07-14 20:10:55,840 - Hyper-Parameters - INFO - Best hyper-parameters found:\n",
      "{'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 8, 'max_features': 0.35, 'min_samples_leaf': 4, 'n_estimators': 250, 'n_jobs': 12}\n",
      "2022-07-14 20:10:55,928 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, train dataset: 0.8869300911854103\n",
      "2022-07-14 20:10:55,930 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, train dataset: 0.8773301262778112\n",
      "2022-07-14 20:10:55,932 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, train dataset: 0.8967424708051629\n",
      "2022-07-14 20:10:55,933 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, train dataset: 0.876\n",
      "2022-07-14 20:10:55,934 - Hyper-Parameters - INFO - -----\n",
      "2022-07-14 20:10:55,987 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, test dataset: 0.7947805456702255\n",
      "2022-07-14 20:10:55,988 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, test dataset: 0.768348623853211\n",
      "2022-07-14 20:10:55,989 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, test dataset: 0.8230958230958231\n",
      "2022-07-14 20:10:55,990 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, test dataset: 0.7696404793608522\n"
     ]
    }
   ],
   "source": [
    "hyper_parameters = [\n",
    "    {\n",
    "        'n_estimators': [250, 300, 350], # Увеличение числа деревьев не сильно даёт улучшение здесь: 200, 300 или 500 - разница невелика.\n",
    "        'criterion': [\"entropy\", \"log_loss\"], # Эти параметры могут выигрывать попеременно, вероятно в зависимости от max_features.\n",
    "        'max_depth': [7, 8], # Какой диапазон, ни ставь, в целом выбираются более переобученные модели с большей глубиной.\n",
    "        'min_samples_leaf': [3, 4], # Аналогично, но в сторону уменьшения числа примеров в листе.\n",
    "        'max_features' : [0.35, 0.4],\n",
    "        'bootstrap': [True], # Всегда выигрывало значение True.\n",
    "        'class_weight' : [\"balanced\", None], # Всегда выигрывало значение \"balanced\".\n",
    "        'n_jobs' : [ML_JOBS] # Иногда помогает уменьшать затраченное машинное время при одновременном параллельном вычислении в RandomizedSearchCV.\n",
    "    }\n",
    "]\n",
    "\n",
    "base_model = ensemble.RandomForestClassifier(random_state=ML_SEED)\n",
    "optimization_algorithm_instance, samples = optimize_model_sklearn(data, \"Activity\",\n",
    "                                                                  base_model,\n",
    "                                                                  GridSearchCV, scoring_type='f1',\n",
    "                                                                  hyper_parameters=hyper_parameters, cross_validation_parameter=5,\n",
    "                                                                  holdout_sample_size=0.2, holdout_shuffle=True,\n",
    "                                                                  verbosity=Verbosity.NONE,\n",
    "                                                                  seed=ML_SEED,\n",
    "                                                                  n_jobs=14)\n",
    "\n",
    "log_f1_scores(samples, optimization_algorithm_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика recall довольно высока даже на тестовой выборке, а вот precision заметно падает. Возможно при достаточном количестве машинного времени удатся найти баланс между метриками, чтобы приходилось меньше тестировать препараты в реальных тестах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Продвинутая оптимизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 `hyperopt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 `hyperopt` + `LogisticRegressionCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-14 20:25:32,417 - Hyper-Parameters - INFO - Hyperopt Version: 0.2.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "\n",
    "\n",
    "LOG.info(f\"Hyperopt Version: {hyperopt.__version__}\")\n",
    "\n",
    "\n",
    "def objective(parameters, X=samples[\"X_train\"], y=samples[\"Y_train\"], cv=5, random_state=ML_SEED):\n",
    "    # LOG.info(f\"Case type: \\\"{colored(parameters['case-type'], 'green')}\\\"; Parameters: {parameters}.\")\n",
    "\n",
    "    model = linear_model.LogisticRegression(\n",
    "        C=parameters['C'],\n",
    "        penalty=parameters['penalty'],\n",
    "        solver=parameters['solver'],\n",
    "        class_weight=parameters['class_weight'],\n",
    "        max_iter=parameters['max_iter'],\n",
    "        l1_ratio=parameters['l1_ratio'] if 'l1_ratio' in parameters else None,\n",
    "        n_jobs=parameters['n_jobs'],\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"error\")\n",
    "        try:\n",
    "            score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "            # LOG.info(f\"Case \\\"{colored(parameters['case-type'], 'green')}\\\"; Score: {colored(score, 'red')}\\n----------\")\n",
    "            return -score\n",
    "        except Warning or exceptions.NotFittedError:\n",
    "            LOG.info(f\"Case \\\"{colored(parameters['case-type'], 'red')}\\\"; NOT FITTED; Parameters: {parameters}.\\n----------\")\n",
    "            return 10000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-14 20:28:09,214 - Hyper-Parameters - INFO - A holdout sample is selected. Train sample size - 3000 (0.8), test sample size 751 (0.2).\n",
      "2022-07-14 20:28:09,215 - Hyper-Parameters - INFO - Starting Hyperopt minimization.\n",
      "100%|██████████| 40/40 [02:10<00:00,  3.25s/trial, best loss: -0.794791603133382]\n",
      "2022-07-14 20:30:19,316 - Hyper-Parameters - INFO - Best hyper-parameters: {'C': 0.019, 'case-type': 'lbfgs+l2', 'class_weight': None, 'max_iter': 800, 'n_jobs': 12, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "2022-07-14 20:30:23,820 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, train dataset: 0.8305389221556886\n",
      "2022-07-14 20:30:23,822 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, train dataset: 0.8096906012842966\n",
      "2022-07-14 20:30:23,823 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, train dataset: 0.8524892440073756\n",
      "2022-07-14 20:30:23,823 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, train dataset: 0.8113333333333334\n",
      "2022-07-14 20:30:23,824 - Hyper-Parameters - INFO - -----\n",
      "2022-07-14 20:30:23,833 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, test dataset: 0.7796208530805686\n",
      "2022-07-14 20:30:23,835 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, test dataset: 0.7528604118993135\n",
      "2022-07-14 20:30:23,836 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, test dataset: 0.8083538083538083\n",
      "2022-07-14 20:30:23,836 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, test dataset: 0.7523302263648469\n"
     ]
    }
   ],
   "source": [
    "ML_JOBS = 12 # К сожалению только при числе \"потоков\" 1 удаётся скрыть ненужные ConvergenceWarning в scikit-learn...\n",
    "hyper_parameters = hp.choice('cases', [\n",
    "    {\n",
    "        'case-type': 'lbfgs+l2',\n",
    "        'solver': 'lbfgs',\n",
    "        'penalty': 'l2',\n",
    "        'C': hp.quniform('lbfgs+l2-C', 0.014, 0.02, 0.001),\n",
    "        'class_weight': hp.choice('lbfgs+l2-class_weight', ['balanced', None]),\n",
    "        'max_iter': hp.choice('lbfgs+l2-max_iter', np.arange(400, 900, 100, dtype=int)),\n",
    "        'n_jobs': ML_JOBS\n",
    "    },\n",
    "    {\n",
    "        'case-type': 'sag+l2',\n",
    "        'solver': 'sag',\n",
    "        'penalty': 'l2',\n",
    "        'C': hp.quniform('sag+l2-C', 0.016, 0.024, 0.001),\n",
    "        'class_weight': hp.choice('sag+l2-class_weight', ['balanced', None]),\n",
    "        'max_iter': hp.choice('sag+l2-max_iter', np.arange(400, 900, 100, dtype=int)),\n",
    "        'n_jobs': ML_JOBS\n",
    "    },\n",
    "    {\n",
    "        'case-type': 'saga+l1',\n",
    "        'penalty': 'l1',\n",
    "        'solver': 'saga',\n",
    "        'C': hp.quniform('saga+l1-C', 0.001, 0.01, 0.001),\n",
    "        'class_weight': hp.choice('saga+l1-class_weight', ['balanced', None]),\n",
    "        'max_iter': hp.choice('sag+l1-max_iter', np.arange(400, 900, 100, dtype=int)),\n",
    "        'n_jobs': ML_JOBS\n",
    "    },\n",
    "    {\n",
    "        'case-type': 'saga+l2',\n",
    "        'penalty': 'l2',\n",
    "        'solver': 'saga',\n",
    "        'C': hp.quniform('saga+l2-C', 0.015, 0.03, 0.001),\n",
    "        'class_weight': hp.choice('saga+l2-class_weight', ['balanced', None]),\n",
    "        'max_iter': hp.choice('saga+l2-max_iter', np.arange(400, 900, 100, dtype=int)),\n",
    "        'n_jobs' : ML_JOBS\n",
    "    },\n",
    "    {\n",
    "        'case-type': 'saga+elasticnet',\n",
    "        'penalty': 'elasticnet',\n",
    "        'solver': 'saga',\n",
    "        'C': hp.quniform('saga+elasticnet-C', 0.018, 0.027, 0.001),\n",
    "        'class_weight': hp.choice('saga+elasticnet-class_weight', ['balanced', None]),\n",
    "        'max_iter': hp.choice('saga+elasticnet-max_iter', np.arange(400, 900, 100, dtype=int)),\n",
    "        'l1_ratio': hp.quniform('saga+elasticnet-l1_ratio', 0.006, 0.012, 0.001),\n",
    "        'n_jobs': ML_JOBS\n",
    "    },\n",
    "    {\n",
    "        'case-type': 'liblinear+l1_l2',\n",
    "        'penalty': hp.choice('liblinear+l1_l2-penalty', ['l1', 'l2']),\n",
    "        'solver': 'liblinear',\n",
    "        'C': hp.quniform('liblinear+l1_l2-C', 0.05, 0.1, 0.005),\n",
    "        'class_weight': hp.choice('liblinear+l1_l2-class_weight', ['balanced', None]),\n",
    "        'max_iter': hp.choice('liblinear+l1_l2-max_iter', np.arange(40, 60, 2, dtype=int)),\n",
    "        'n_jobs' : 1\n",
    "    },\n",
    "    {\n",
    "        'case-type': 'newton-cg+l2',\n",
    "        'penalty': 'l2',\n",
    "        'solver': 'newton-cg',\n",
    "        'C': hp.quniform('newton-cg+l2-C', 0.05, 0.1, 0.005),\n",
    "        'class_weight': hp.choice('newton-cg+l2-class_weight', ['balanced', None]),\n",
    "        'max_iter': hp.choice('newton-cg+l2-max_iter', np.arange(40, 60, 2, dtype=int)),\n",
    "        'n_jobs' : ML_JOBS\n",
    "    }\n",
    "])\n",
    "\n",
    "\n",
    "target_feature_name = \"Activity\" \n",
    "X = data.drop([target_feature_name], axis=1)\n",
    "Y = data[target_feature_name]\n",
    "samples = make_holdout_sample_sklearn(\n",
    "    X, Y,\n",
    "    holdout_sample_size=0.2,\n",
    "    seed=ML_SEED,\n",
    "    shuffle=True,\n",
    "    stratify=Y\n",
    ")\n",
    "\n",
    "\n",
    "LOG.info(f\"Starting Hyperopt minimization.\")\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    objective,\n",
    "    space=hyper_parameters,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=40,\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(ML_SEED),\n",
    "    show_progressbar=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "best_parameters = hyperopt.space_eval(hyper_parameters, best)\n",
    "LOG.info(f\"Best hyper-parameters: {hyperopt.space_eval(hyper_parameters, best)}\")\n",
    "\n",
    "best_model = linear_model.LogisticRegression(\n",
    "    C=best_parameters['C'],\n",
    "    penalty=best_parameters['penalty'],\n",
    "    solver=best_parameters['solver'],\n",
    "    class_weight=best_parameters['class_weight'],\n",
    "    max_iter=best_parameters['max_iter'],\n",
    "    l1_ratio=best_parameters['l1_ratio'] if 'l1_ratio' in best_parameters else None,\n",
    "    n_jobs=best_parameters['n_jobs'],\n",
    "    random_state=ML_SEED,\n",
    ")\n",
    "best_model.fit(samples['X_train'], samples['Y_train'])\n",
    "\n",
    "log_f1_scores(samples, best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 `hyperopt` + `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "\n",
    "\n",
    "def objective(parameters, X=samples[\"X_train\"], y=samples[\"Y_train\"], cv=5, random_state=ML_SEED):\n",
    "    # LOG.info(f\"Parameters: {parameters}.\")\n",
    "\n",
    "    model = ensemble.RandomForestClassifier(\n",
    "        n_estimators=parameters['n_estimators'],\n",
    "        criterion=parameters['criterion'],\n",
    "        max_depth=parameters['max_depth'],\n",
    "        min_samples_leaf=parameters['min_samples_leaf'],\n",
    "        max_features=parameters['max_features'],\n",
    "        bootstrap=parameters['bootstrap'],\n",
    "        class_weight=parameters['class_weight'],\n",
    "        n_jobs=parameters['n_jobs'],\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"error\")\n",
    "        try:\n",
    "            # model.fit(X, y)\n",
    "            score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "            return -score\n",
    "        except Warning or exceptions.NotFittedError:\n",
    "            LOG.info(f\"NOT FITTED; Parameters: {parameters}.\\n----------\")\n",
    "            return 10000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-14 20:32:36,617 - Hyper-Parameters - INFO - A holdout sample is selected. Train sample size - 3000 (0.8), test sample size 751 (0.2).\n",
      "2022-07-14 20:32:36,617 - Hyper-Parameters - INFO - Starting Hyperopt minimization.\n",
      "100%|██████████| 40/40 [09:59<00:00, 14.99s/trial, best loss: -0.8119676180118495]\n",
      "2022-07-14 20:42:36,409 - Hyper-Parameters - INFO - Best hyper-parameters: {'bootstrap': True, 'class_weight': None, 'criterion': 'log_loss', 'max_depth': 8, 'max_features': 0.5, 'min_samples_leaf': 4, 'n_estimators': 300, 'n_jobs': 12}\n",
      "2022-07-14 20:42:37,026 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, train dataset: 0.8812519177661859\n",
      "2022-07-14 20:42:37,028 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, train dataset: 0.8799019607843137\n",
      "2022-07-14 20:42:37,029 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, train dataset: 0.8826060233558697\n",
      "2022-07-14 20:42:37,030 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, train dataset: 0.871\n",
      "2022-07-14 20:42:37,030 - Hyper-Parameters - INFO - -----\n",
      "2022-07-14 20:42:37,094 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, test dataset: 0.7815533980582523\n",
      "2022-07-14 20:42:37,095 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, test dataset: 0.7721822541966427\n",
      "2022-07-14 20:42:37,097 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, test dataset: 0.7911547911547911\n",
      "2022-07-14 20:42:37,097 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, test dataset: 0.7603195739014648\n"
     ]
    }
   ],
   "source": [
    "ML_JOBS = 12\n",
    "hyper_parameters = {\n",
    "    'n_estimators': hp.choice('n_estimators', [250, 300, 350]), # Увеличение числа деревьев не сильно даёт улучшение здесь: 200, 300 или 500 - разница невелика.\n",
    "    'criterion': hp.choice('criterion', [\"entropy\", \"log_loss\"]), # Эти параметры могут выигрывать попеременно, вероятно в зависимости от max_features.\n",
    "    'max_depth': hp.choice('max_depth', [7, 8]), # Какой диапазон, ни ставь, в целом выбираются более переобученные модели с большей глубиной.\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', [3, 4]), # Аналогично, но в сторону уменьшения числа примеров в листе.\n",
    "    'max_features' : hp.quniform('max_features', 0.2, 0.5, 0.02),\n",
    "    'bootstrap': True, # Всегда выигрывало значение True.\n",
    "    'class_weight' : hp.choice('class_weight', [\"balanced\", None]), # Всегда выигрывало значение \"balanced\".\n",
    "    'n_jobs' : ML_JOBS # Иногда помогает уменьшать затраченное машинное время при одновременном параллельном вычислении в RandomizedSearchCV.\n",
    "}\n",
    "\n",
    "\n",
    "target_feature_name = \"Activity\"\n",
    "X = data.drop([target_feature_name], axis=1)\n",
    "Y = data[target_feature_name]\n",
    "samples = make_holdout_sample_sklearn(\n",
    "    X, Y,\n",
    "    holdout_sample_size=0.2,\n",
    "    seed=ML_SEED,\n",
    "    shuffle=True,\n",
    "    stratify=Y\n",
    ")\n",
    "\n",
    "\n",
    "LOG.info(f\"Starting Hyperopt minimization.\")\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    objective,\n",
    "    space=hyper_parameters,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=40,\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(ML_SEED),\n",
    "    show_progressbar=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "best_parameters = hyperopt.space_eval(hyper_parameters, best)\n",
    "LOG.info(f\"Best hyper-parameters: {hyperopt.space_eval(hyper_parameters, best)}\")\n",
    "\n",
    "best_model = ensemble.RandomForestClassifier(\n",
    "    n_estimators=best_parameters['n_estimators'],\n",
    "    criterion=best_parameters['criterion'],\n",
    "    max_depth=best_parameters['max_depth'],\n",
    "    min_samples_leaf=best_parameters['min_samples_leaf'],\n",
    "    bootstrap=best_parameters['bootstrap'],\n",
    "    class_weight=best_parameters['class_weight'],\n",
    "    n_jobs=best_parameters['n_jobs'],\n",
    "    random_state=ML_SEED\n",
    ")\n",
    "\n",
    "\n",
    "best_model.fit(samples['X_train'], samples['Y_train'])\n",
    "\n",
    "log_f1_scores(samples, best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 `optuna`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-14 20:43:15,302 - Hyper-Parameters - INFO - Hyperopt Version: 0.2.7\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "LOG.info(f\"Hyperopt Version: {hyperopt.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 `optuna` + `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-14 20:44:11,532 - Hyper-Parameters - INFO - A holdout sample is selected. Train sample size - 3000 (0.8), test sample size 751 (0.2).\n",
      "2022-07-14 20:44:12,331 - Hyper-Parameters - INFO - TRIAL 31. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.1, 'max_iter': 46}; Score: 0.7849401308591\n",
      "2022-07-14 20:44:13,044 - Hyper-Parameters - INFO - TRIAL 32. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.1, 'max_iter': 46}; Score: 0.7849401308591\n",
      "2022-07-14 20:44:13,704 - Hyper-Parameters - INFO - TRIAL 38. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.1, 'max_iter': 46}; Score: 0.7849401308591\n",
      "2022-07-14 20:44:14,418 - Hyper-Parameters - INFO - TRIAL 41. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.1, 'max_iter': 46}; Score: 0.7849401308591\n",
      "2022-07-14 20:44:15,116 - Hyper-Parameters - INFO - TRIAL 44. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.1, 'max_iter': 46}; Score: 0.7849401308591\n",
      "2022-07-14 20:44:15,797 - Hyper-Parameters - INFO - TRIAL 45. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.1, 'max_iter': 46}; Score: 0.7849401308591\n",
      "2022-07-14 20:44:16,530 - Hyper-Parameters - INFO - TRIAL 46. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.1, 'max_iter': 46}; Score: 0.7849401308591\n",
      "2022-07-14 20:44:17,200 - Hyper-Parameters - INFO - TRIAL 47. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.1, 'max_iter': 46}; Score: 0.7849401308591\n",
      "2022-07-14 20:44:17,918 - Hyper-Parameters - INFO - TRIAL 48. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.1, 'max_iter': 46}; Score: 0.7849401308591\n",
      "2022-07-14 20:44:18,679 - Hyper-Parameters - INFO - TRIAL 51. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.1, 'max_iter': 46}; Score: 0.7849401308591\n",
      "2022-07-14 20:44:19,385 - Hyper-Parameters - INFO - TRIAL 52. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.1, 'max_iter': 46}; Score: 0.7849401308591\n",
      "2022-07-14 20:44:20,027 - Hyper-Parameters - INFO - TRIAL 53. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.1, 'max_iter': 46}; Score: 0.7849401308591\n",
      "2022-07-14 20:44:20,700 - Hyper-Parameters - INFO - TRIAL 55. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.095, 'max_iter': 54}; Score: 0.7850800530975821\n",
      "2022-07-14 20:44:21,108 - Hyper-Parameters - INFO - TRIAL 56. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.09, 'max_iter': 56}; Score: 0.7828272048898637\n",
      "2022-07-14 20:44:21,730 - Hyper-Parameters - INFO - TRIAL 57. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.085, 'max_iter': 52}; Score: 0.7873915552483234\n",
      "2022-07-14 20:44:22,374 - Hyper-Parameters - INFO - TRIAL 61. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.08, 'max_iter': 54}; Score: 0.7878594965430807\n",
      "2022-07-14 20:44:23,055 - Hyper-Parameters - INFO - TRIAL 62. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.08, 'max_iter': 54}; Score: 0.7878594965430807\n",
      "2022-07-14 20:44:23,685 - Hyper-Parameters - INFO - TRIAL 63. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.08, 'max_iter': 54}; Score: 0.7878594965430807\n",
      "2022-07-14 20:44:24,344 - Hyper-Parameters - INFO - TRIAL 64. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.08, 'max_iter': 54}; Score: 0.7878594965430807\n",
      "2022-07-14 20:44:24,983 - Hyper-Parameters - INFO - TRIAL 66. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.08, 'max_iter': 54}; Score: 0.7878594965430807\n",
      "2022-07-14 20:44:25,602 - Hyper-Parameters - INFO - TRIAL 69. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.08, 'max_iter': 54}; Score: 0.7878594965430807\n",
      "2022-07-14 20:44:26,270 - Hyper-Parameters - INFO - TRIAL 71. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.08, 'max_iter': 54}; Score: 0.7878594965430807\n",
      "2022-07-14 20:44:26,896 - Hyper-Parameters - INFO - TRIAL 72. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.08, 'max_iter': 52}; Score: 0.7878594965430807\n",
      "2022-07-14 20:44:27,524 - Hyper-Parameters - INFO - TRIAL 74. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07500000000000001, 'max_iter': 54}; Score: 0.788100402137102\n",
      "2022-07-14 20:44:28,223 - Hyper-Parameters - INFO - TRIAL 78. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07500000000000001, 'max_iter': 54}; Score: 0.788100402137102\n",
      "2022-07-14 20:44:28,868 - Hyper-Parameters - INFO - TRIAL 81. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07500000000000001, 'max_iter': 54}; Score: 0.788100402137102\n",
      "2022-07-14 20:44:29,454 - Hyper-Parameters - INFO - TRIAL 82. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07, 'max_iter': 54}; Score: 0.7881000053127035\n",
      "2022-07-14 20:44:30,068 - Hyper-Parameters - INFO - TRIAL 83. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07, 'max_iter': 52}; Score: 0.7881000053127035\n",
      "2022-07-14 20:44:30,684 - Hyper-Parameters - INFO - TRIAL 84. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07, 'max_iter': 50}; Score: 0.7881000053127035\n",
      "2022-07-14 20:44:31,300 - Hyper-Parameters - INFO - TRIAL 88. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.065, 'max_iter': 50}; Score: 0.7886045038906973\n",
      "2022-07-14 20:44:31,916 - Hyper-Parameters - INFO - TRIAL 91. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.065, 'max_iter': 50}; Score: 0.7886045038906973\n",
      "2022-07-14 20:44:32,469 - Hyper-Parameters - INFO - TRIAL 92. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.065, 'max_iter': 50}; Score: 0.7886045038906973\n",
      "2022-07-14 20:44:33,062 - Hyper-Parameters - INFO - TRIAL 93. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07, 'max_iter': 50}; Score: 0.7881000053127035\n",
      "2022-07-14 20:44:33,718 - Hyper-Parameters - INFO - TRIAL 94. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.065, 'max_iter': 50}; Score: 0.7886045038906973\n",
      "2022-07-14 20:44:34,292 - Hyper-Parameters - INFO - TRIAL 96. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 50}; Score: 0.789808217291193\n",
      "2022-07-14 20:44:34,851 - Hyper-Parameters - INFO - TRIAL 100. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 50}; Score: 0.789808217291193\n",
      "2022-07-14 20:44:35,432 - Hyper-Parameters - INFO - TRIAL 101. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 50}; Score: 0.789808217291193\n",
      "2022-07-14 20:44:36,016 - Hyper-Parameters - INFO - TRIAL 102. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 50}; Score: 0.789808217291193\n",
      "2022-07-14 20:44:36,563 - Hyper-Parameters - INFO - TRIAL 103. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 50}; Score: 0.789808217291193\n",
      "2022-07-14 20:44:37,153 - Hyper-Parameters - INFO - TRIAL 104. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 50}; Score: 0.789808217291193\n",
      "2022-07-14 20:44:37,747 - Hyper-Parameters - INFO - TRIAL 105. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 50}; Score: 0.789808217291193\n",
      "2022-07-14 20:44:38,300 - Hyper-Parameters - INFO - TRIAL 107. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 50}; Score: 0.789808217291193\n",
      "2022-07-14 20:44:38,902 - Hyper-Parameters - INFO - TRIAL 111. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 50}; Score: 0.789808217291193\n",
      "2022-07-14 20:44:39,516 - Hyper-Parameters - INFO - TRIAL 112. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:40,080 - Hyper-Parameters - INFO - TRIAL 113. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:40,679 - Hyper-Parameters - INFO - TRIAL 114. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:41,268 - Hyper-Parameters - INFO - TRIAL 115. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:41,817 - Hyper-Parameters - INFO - TRIAL 116. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:44:42,451 - Hyper-Parameters - INFO - TRIAL 120. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:43,019 - Hyper-Parameters - INFO - TRIAL 121. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:43,583 - Hyper-Parameters - INFO - TRIAL 122. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:44,198 - Hyper-Parameters - INFO - TRIAL 123. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:44,817 - Hyper-Parameters - INFO - TRIAL 124. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:45,374 - Hyper-Parameters - INFO - TRIAL 125. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:45,962 - Hyper-Parameters - INFO - TRIAL 126. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:46,565 - Hyper-Parameters - INFO - TRIAL 129. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:47,145 - Hyper-Parameters - INFO - TRIAL 130. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:47,817 - Hyper-Parameters - INFO - TRIAL 131. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:48,432 - Hyper-Parameters - INFO - TRIAL 132. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:48,991 - Hyper-Parameters - INFO - TRIAL 133. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:49,648 - Hyper-Parameters - INFO - TRIAL 134. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:50,243 - Hyper-Parameters - INFO - TRIAL 135. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:50,802 - Hyper-Parameters - INFO - TRIAL 136. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:44:51,389 - Hyper-Parameters - INFO - TRIAL 139. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:52,010 - Hyper-Parameters - INFO - TRIAL 140. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:52,563 - Hyper-Parameters - INFO - TRIAL 141. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:53,155 - Hyper-Parameters - INFO - TRIAL 142. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:53,732 - Hyper-Parameters - INFO - TRIAL 143. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 46}; Score: 0.7896620382423478\n",
      "2022-07-14 20:44:54,281 - Hyper-Parameters - INFO - TRIAL 144. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:54,897 - Hyper-Parameters - INFO - TRIAL 145. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:55,494 - Hyper-Parameters - INFO - TRIAL 148. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:44:56,064 - Hyper-Parameters - INFO - TRIAL 150. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:56,701 - Hyper-Parameters - INFO - TRIAL 151. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:57,288 - Hyper-Parameters - INFO - TRIAL 152. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:57,862 - Hyper-Parameters - INFO - TRIAL 153. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:58,482 - Hyper-Parameters - INFO - TRIAL 154. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:44:59,084 - Hyper-Parameters - INFO - TRIAL 157. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:44:59,636 - Hyper-Parameters - INFO - TRIAL 160. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:00,252 - Hyper-Parameters - INFO - TRIAL 161. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:00,868 - Hyper-Parameters - INFO - TRIAL 162. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:01,420 - Hyper-Parameters - INFO - TRIAL 163. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:02,001 - Hyper-Parameters - INFO - TRIAL 164. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:02,561 - Hyper-Parameters - INFO - TRIAL 165. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:45:03,117 - Hyper-Parameters - INFO - TRIAL 167. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:03,729 - Hyper-Parameters - INFO - TRIAL 168. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:04,308 - Hyper-Parameters - INFO - TRIAL 169. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:04,860 - Hyper-Parameters - INFO - TRIAL 171. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:05,453 - Hyper-Parameters - INFO - TRIAL 172. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:06,098 - Hyper-Parameters - INFO - TRIAL 173. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:06,683 - Hyper-Parameters - INFO - TRIAL 174. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 44}; Score: 0.7896620382423478\n",
      "2022-07-14 20:45:07,300 - Hyper-Parameters - INFO - TRIAL 178. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:07,679 - Hyper-Parameters - INFO - TRIAL 179. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7676539987218554\n",
      "2022-07-14 20:45:08,230 - Hyper-Parameters - INFO - TRIAL 181. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:08,841 - Hyper-Parameters - INFO - TRIAL 182. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:09,412 - Hyper-Parameters - INFO - TRIAL 183. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:09,965 - Hyper-Parameters - INFO - TRIAL 184. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:10,566 - Hyper-Parameters - INFO - TRIAL 186. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:45:11,195 - Hyper-Parameters - INFO - TRIAL 187. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:45:11,755 - Hyper-Parameters - INFO - TRIAL 188. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:12,327 - Hyper-Parameters - INFO - TRIAL 190. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:12,933 - Hyper-Parameters - INFO - TRIAL 191. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:13,484 - Hyper-Parameters - INFO - TRIAL 192. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:14,049 - Hyper-Parameters - INFO - TRIAL 193. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:14,631 - Hyper-Parameters - INFO - TRIAL 194. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 48}; Score: 0.789808217291193\n",
      "2022-07-14 20:45:15,193 - Hyper-Parameters - INFO - TRIAL 195. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:15,775 - Hyper-Parameters - INFO - TRIAL 196. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:16,439 - Hyper-Parameters - INFO - TRIAL 201. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:17,012 - Hyper-Parameters - INFO - TRIAL 202. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:17,592 - Hyper-Parameters - INFO - TRIAL 203. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:18,191 - Hyper-Parameters - INFO - TRIAL 204. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:18,736 - Hyper-Parameters - INFO - TRIAL 205. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:45:19,349 - Hyper-Parameters - INFO - TRIAL 206. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 48}; Score: 0.789808217291193\n",
      "2022-07-14 20:45:19,932 - Hyper-Parameters - INFO - TRIAL 207. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:20,496 - Hyper-Parameters - INFO - TRIAL 208. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:21,084 - Hyper-Parameters - INFO - TRIAL 211. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:21,734 - Hyper-Parameters - INFO - TRIAL 212. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:22,317 - Hyper-Parameters - INFO - TRIAL 213. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:22,882 - Hyper-Parameters - INFO - TRIAL 214. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:23,491 - Hyper-Parameters - INFO - TRIAL 216. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:23,864 - Hyper-Parameters - INFO - TRIAL 217. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7676539987218554\n",
      "2022-07-14 20:45:24,469 - Hyper-Parameters - INFO - TRIAL 218. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:25,048 - Hyper-Parameters - INFO - TRIAL 219. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:45:25,677 - Hyper-Parameters - INFO - TRIAL 220. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.09, 'max_iter': 42}; Score: 0.7858426086799593\n",
      "2022-07-14 20:45:26,257 - Hyper-Parameters - INFO - TRIAL 221. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:26,950 - Hyper-Parameters - INFO - TRIAL 222. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:27,501 - Hyper-Parameters - INFO - TRIAL 223. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:28,087 - Hyper-Parameters - INFO - TRIAL 225. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:28,686 - Hyper-Parameters - INFO - TRIAL 229. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:29,246 - Hyper-Parameters - INFO - TRIAL 230. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:45:29,816 - Hyper-Parameters - INFO - TRIAL 231. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:30,399 - Hyper-Parameters - INFO - TRIAL 232. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:30,959 - Hyper-Parameters - INFO - TRIAL 233. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:31,534 - Hyper-Parameters - INFO - TRIAL 235. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:32,164 - Hyper-Parameters - INFO - TRIAL 236. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:32,721 - Hyper-Parameters - INFO - TRIAL 237. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:33,301 - Hyper-Parameters - INFO - TRIAL 240. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:33,913 - Hyper-Parameters - INFO - TRIAL 241. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:34,502 - Hyper-Parameters - INFO - TRIAL 242. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:35,080 - Hyper-Parameters - INFO - TRIAL 243. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:35,666 - Hyper-Parameters - INFO - TRIAL 245. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:36,228 - Hyper-Parameters - INFO - TRIAL 246. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:36,800 - Hyper-Parameters - INFO - TRIAL 248. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:37,424 - Hyper-Parameters - INFO - TRIAL 249. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 48}; Score: 0.789808217291193\n",
      "2022-07-14 20:45:38,003 - Hyper-Parameters - INFO - TRIAL 251. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:38,615 - Hyper-Parameters - INFO - TRIAL 253. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:39,005 - Hyper-Parameters - INFO - TRIAL 254. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 40}; Score: 0.7653885569492547\n",
      "2022-07-14 20:45:39,565 - Hyper-Parameters - INFO - TRIAL 256. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:40,136 - Hyper-Parameters - INFO - TRIAL 257. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:40,718 - Hyper-Parameters - INFO - TRIAL 258. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:41,268 - Hyper-Parameters - INFO - TRIAL 259. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:45:41,839 - Hyper-Parameters - INFO - TRIAL 260. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:42,406 - Hyper-Parameters - INFO - TRIAL 261. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:43,025 - Hyper-Parameters - INFO - TRIAL 262. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 44}; Score: 0.7896620382423478\n",
      "2022-07-14 20:45:43,638 - Hyper-Parameters - INFO - TRIAL 268. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:44,215 - Hyper-Parameters - INFO - TRIAL 269. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:44,806 - Hyper-Parameters - INFO - TRIAL 270. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:45,386 - Hyper-Parameters - INFO - TRIAL 273. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:45,988 - Hyper-Parameters - INFO - TRIAL 275. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 42}; Score: 0.789808217291193\n",
      "2022-07-14 20:45:46,381 - Hyper-Parameters - INFO - TRIAL 276. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7676539987218554\n",
      "2022-07-14 20:45:46,957 - Hyper-Parameters - INFO - TRIAL 277. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:47,557 - Hyper-Parameters - INFO - TRIAL 279. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:48,152 - Hyper-Parameters - INFO - TRIAL 280. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 44}; Score: 0.7896620382423478\n",
      "2022-07-14 20:45:48,768 - Hyper-Parameters - INFO - TRIAL 281. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:49,374 - Hyper-Parameters - INFO - TRIAL 283. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:49,949 - Hyper-Parameters - INFO - TRIAL 285. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:50,521 - Hyper-Parameters - INFO - TRIAL 286. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:45:51,144 - Hyper-Parameters - INFO - TRIAL 287. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:51,701 - Hyper-Parameters - INFO - TRIAL 288. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:52,301 - Hyper-Parameters - INFO - TRIAL 290. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:52,884 - Hyper-Parameters - INFO - TRIAL 291. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:53,515 - Hyper-Parameters - INFO - TRIAL 294. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:54,176 - Hyper-Parameters - INFO - TRIAL 296. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 60}; Score: 0.7896620382423478\n",
      "2022-07-14 20:45:54,775 - Hyper-Parameters - INFO - TRIAL 298. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:55,163 - Hyper-Parameters - INFO - TRIAL 300. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7676539987218554\n",
      "2022-07-14 20:45:55,748 - Hyper-Parameters - INFO - TRIAL 302. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:56,386 - Hyper-Parameters - INFO - TRIAL 303. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.085, 'max_iter': 46}; Score: 0.7873915552483234\n",
      "2022-07-14 20:45:56,945 - Hyper-Parameters - INFO - TRIAL 305. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 48}; Score: 0.789808217291193\n",
      "2022-07-14 20:45:57,543 - Hyper-Parameters - INFO - TRIAL 306. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:58,117 - Hyper-Parameters - INFO - TRIAL 307. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:58,757 - Hyper-Parameters - INFO - TRIAL 309. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:45:59,368 - Hyper-Parameters - INFO - TRIAL 310. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:45:59,940 - Hyper-Parameters - INFO - TRIAL 311. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:00,500 - Hyper-Parameters - INFO - TRIAL 312. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:01,077 - Hyper-Parameters - INFO - TRIAL 313. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:01,682 - Hyper-Parameters - INFO - TRIAL 315. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 44}; Score: 0.789808217291193\n",
      "2022-07-14 20:46:02,242 - Hyper-Parameters - INFO - TRIAL 316. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:02,827 - Hyper-Parameters - INFO - TRIAL 317. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:03,413 - Hyper-Parameters - INFO - TRIAL 320. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:03,790 - Hyper-Parameters - INFO - TRIAL 323. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7653885569492547\n",
      "2022-07-14 20:46:04,447 - Hyper-Parameters - INFO - TRIAL 324. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:05,030 - Hyper-Parameters - INFO - TRIAL 327. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:05,581 - Hyper-Parameters - INFO - TRIAL 328. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:06,168 - Hyper-Parameters - INFO - TRIAL 329. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:46:06,772 - Hyper-Parameters - INFO - TRIAL 330. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:07,324 - Hyper-Parameters - INFO - TRIAL 331. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:07,913 - Hyper-Parameters - INFO - TRIAL 332. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:08,526 - Hyper-Parameters - INFO - TRIAL 334. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:09,167 - Hyper-Parameters - INFO - TRIAL 335. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.095, 'max_iter': 46}; Score: 0.7850800530975821\n",
      "2022-07-14 20:46:09,784 - Hyper-Parameters - INFO - TRIAL 337. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:46:10,398 - Hyper-Parameters - INFO - TRIAL 338. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:46:10,961 - Hyper-Parameters - INFO - TRIAL 339. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:11,549 - Hyper-Parameters - INFO - TRIAL 340. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:12,143 - Hyper-Parameters - INFO - TRIAL 344. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:12,730 - Hyper-Parameters - INFO - TRIAL 345. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:13,335 - Hyper-Parameters - INFO - TRIAL 346. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:13,899 - Hyper-Parameters - INFO - TRIAL 347. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:14,451 - Hyper-Parameters - INFO - TRIAL 349. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:15,070 - Hyper-Parameters - INFO - TRIAL 350. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:15,634 - Hyper-Parameters - INFO - TRIAL 352. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:46:16,199 - Hyper-Parameters - INFO - TRIAL 354. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:16,833 - Hyper-Parameters - INFO - TRIAL 355. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07500000000000001, 'max_iter': 48}; Score: 0.788100402137102\n",
      "2022-07-14 20:46:17,405 - Hyper-Parameters - INFO - TRIAL 356. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:18,000 - Hyper-Parameters - INFO - TRIAL 358. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 40}; Score: 0.789808217291193\n",
      "2022-07-14 20:46:18,608 - Hyper-Parameters - INFO - TRIAL 359. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:19,199 - Hyper-Parameters - INFO - TRIAL 363. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:19,781 - Hyper-Parameters - INFO - TRIAL 364. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:20,460 - Hyper-Parameters - INFO - TRIAL 365. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:21,049 - Hyper-Parameters - INFO - TRIAL 366. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:21,459 - Hyper-Parameters - INFO - TRIAL 367. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7676539987218554\n",
      "2022-07-14 20:46:22,037 - Hyper-Parameters - INFO - TRIAL 370. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.065, 'max_iter': 50}; Score: 0.7886045038906973\n",
      "2022-07-14 20:46:22,616 - Hyper-Parameters - INFO - TRIAL 371. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:23,171 - Hyper-Parameters - INFO - TRIAL 372. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 46}; Score: 0.7896620382423478\n",
      "2022-07-14 20:46:23,762 - Hyper-Parameters - INFO - TRIAL 374. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:24,352 - Hyper-Parameters - INFO - TRIAL 376. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 50}; Score: 0.789808217291193\n",
      "2022-07-14 20:46:24,906 - Hyper-Parameters - INFO - TRIAL 377. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:25,599 - Hyper-Parameters - INFO - TRIAL 381. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:26,202 - Hyper-Parameters - INFO - TRIAL 382. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:26,749 - Hyper-Parameters - INFO - TRIAL 383. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:27,330 - Hyper-Parameters - INFO - TRIAL 384. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:27,936 - Hyper-Parameters - INFO - TRIAL 388. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 44}; Score: 0.7896620382423478\n",
      "2022-07-14 20:46:28,509 - Hyper-Parameters - INFO - TRIAL 389. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:29,082 - Hyper-Parameters - INFO - TRIAL 390. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:29,472 - Hyper-Parameters - INFO - TRIAL 391. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7676539987218554\n",
      "2022-07-14 20:46:30,030 - Hyper-Parameters - INFO - TRIAL 392. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 48}; Score: 0.789808217291193\n",
      "2022-07-14 20:46:30,652 - Hyper-Parameters - INFO - TRIAL 394. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:31,232 - Hyper-Parameters - INFO - TRIAL 395. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:31,782 - Hyper-Parameters - INFO - TRIAL 397. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:32,419 - Hyper-Parameters - INFO - TRIAL 402. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 50}; Score: 0.789808217291193\n",
      "2022-07-14 20:46:32,987 - Hyper-Parameters - INFO - TRIAL 403. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:46:33,554 - Hyper-Parameters - INFO - TRIAL 404. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:34,160 - Hyper-Parameters - INFO - TRIAL 405. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:34,747 - Hyper-Parameters - INFO - TRIAL 407. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:35,310 - Hyper-Parameters - INFO - TRIAL 408. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:36,016 - Hyper-Parameters - INFO - TRIAL 409. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07, 'max_iter': 44}; Score: 0.7881000053127035\n",
      "2022-07-14 20:46:36,583 - Hyper-Parameters - INFO - TRIAL 410. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:46:36,971 - Hyper-Parameters - INFO - TRIAL 413. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7676539987218554\n",
      "2022-07-14 20:46:37,589 - Hyper-Parameters - INFO - TRIAL 414. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:38,168 - Hyper-Parameters - INFO - TRIAL 416. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:38,755 - Hyper-Parameters - INFO - TRIAL 418. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:46:39,418 - Hyper-Parameters - INFO - TRIAL 419. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:39,998 - Hyper-Parameters - INFO - TRIAL 421. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:40,561 - Hyper-Parameters - INFO - TRIAL 423. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:41,197 - Hyper-Parameters - INFO - TRIAL 424. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:41,781 - Hyper-Parameters - INFO - TRIAL 425. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:42,336 - Hyper-Parameters - INFO - TRIAL 426. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:42,931 - Hyper-Parameters - INFO - TRIAL 427. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:43,530 - Hyper-Parameters - INFO - TRIAL 430. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 46}; Score: 0.7896620382423478\n",
      "2022-07-14 20:46:44,132 - Hyper-Parameters - INFO - TRIAL 433. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:44,732 - Hyper-Parameters - INFO - TRIAL 434. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:45,131 - Hyper-Parameters - INFO - TRIAL 435. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 56}; Score: 0.7706817631464509\n",
      "2022-07-14 20:46:45,706 - Hyper-Parameters - INFO - TRIAL 437. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:46,312 - Hyper-Parameters - INFO - TRIAL 438. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:46,936 - Hyper-Parameters - INFO - TRIAL 441. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:46:47,529 - Hyper-Parameters - INFO - TRIAL 443. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:48,106 - Hyper-Parameters - INFO - TRIAL 444. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:48,702 - Hyper-Parameters - INFO - TRIAL 445. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:49,250 - Hyper-Parameters - INFO - TRIAL 446. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:49,873 - Hyper-Parameters - INFO - TRIAL 447. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:50,449 - Hyper-Parameters - INFO - TRIAL 448. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 44}; Score: 0.789808217291193\n",
      "2022-07-14 20:46:51,002 - Hyper-Parameters - INFO - TRIAL 449. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:51,666 - Hyper-Parameters - INFO - TRIAL 455. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:52,356 - Hyper-Parameters - INFO - TRIAL 456. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.085, 'max_iter': 42}; Score: 0.7873915552483234\n",
      "2022-07-14 20:46:52,906 - Hyper-Parameters - INFO - TRIAL 458. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:53,484 - Hyper-Parameters - INFO - TRIAL 459. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:54,082 - Hyper-Parameters - INFO - TRIAL 461. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:46:54,630 - Hyper-Parameters - INFO - TRIAL 463. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 46}; Score: 0.7896620382423478\n",
      "2022-07-14 20:46:55,213 - Hyper-Parameters - INFO - TRIAL 464. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:55,801 - Hyper-Parameters - INFO - TRIAL 465. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:56,364 - Hyper-Parameters - INFO - TRIAL 466. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:56,939 - Hyper-Parameters - INFO - TRIAL 467. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:57,558 - Hyper-Parameters - INFO - TRIAL 468. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:58,118 - Hyper-Parameters - INFO - TRIAL 470. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 60}; Score: 0.7896620382423478\n",
      "2022-07-14 20:46:58,763 - Hyper-Parameters - INFO - TRIAL 473. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:59,319 - Hyper-Parameters - INFO - TRIAL 474. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:46:59,867 - Hyper-Parameters - INFO - TRIAL 475. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:00,271 - Hyper-Parameters - INFO - TRIAL 478. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7676539987218554\n",
      "2022-07-14 20:47:00,899 - Hyper-Parameters - INFO - TRIAL 480. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:01,469 - Hyper-Parameters - INFO - TRIAL 482. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:47:02,065 - Hyper-Parameters - INFO - TRIAL 483. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:47:02,706 - Hyper-Parameters - INFO - TRIAL 485. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:03,286 - Hyper-Parameters - INFO - TRIAL 486. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:03,884 - Hyper-Parameters - INFO - TRIAL 487. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:04,449 - Hyper-Parameters - INFO - TRIAL 488. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:05,010 - Hyper-Parameters - INFO - TRIAL 490. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:05,599 - Hyper-Parameters - INFO - TRIAL 491. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 44}; Score: 0.789808217291193\n",
      "2022-07-14 20:47:06,218 - Hyper-Parameters - INFO - TRIAL 493. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:06,773 - Hyper-Parameters - INFO - TRIAL 494. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:07,462 - Hyper-Parameters - INFO - TRIAL 495. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07500000000000001, 'max_iter': 56}; Score: 0.788100402137102\n",
      "2022-07-14 20:47:08,108 - Hyper-Parameters - INFO - TRIAL 498. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:08,540 - Hyper-Parameters - INFO - TRIAL 499. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7653885569492547\n",
      "2022-07-14 20:47:09,133 - Hyper-Parameters - INFO - TRIAL 501. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:09,827 - Hyper-Parameters - INFO - TRIAL 503. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.095, 'max_iter': 44}; Score: 0.7850800530975821\n",
      "2022-07-14 20:47:10,396 - Hyper-Parameters - INFO - TRIAL 505. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:10,979 - Hyper-Parameters - INFO - TRIAL 506. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 48}; Score: 0.789808217291193\n",
      "2022-07-14 20:47:11,569 - Hyper-Parameters - INFO - TRIAL 507. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:12,132 - Hyper-Parameters - INFO - TRIAL 509. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:12,768 - Hyper-Parameters - INFO - TRIAL 510. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:13,468 - Hyper-Parameters - INFO - TRIAL 513. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:14,015 - Hyper-Parameters - INFO - TRIAL 514. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:14,624 - Hyper-Parameters - INFO - TRIAL 515. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:15,204 - Hyper-Parameters - INFO - TRIAL 518. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:15,785 - Hyper-Parameters - INFO - TRIAL 520. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:47:16,400 - Hyper-Parameters - INFO - TRIAL 521. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:47:17,004 - Hyper-Parameters - INFO - TRIAL 522. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.065, 'max_iter': 48}; Score: 0.7886045038906973\n",
      "2022-07-14 20:47:17,602 - Hyper-Parameters - INFO - TRIAL 524. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:18,206 - Hyper-Parameters - INFO - TRIAL 525. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:18,895 - Hyper-Parameters - INFO - TRIAL 526. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:19,635 - Hyper-Parameters - INFO - TRIAL 527. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:20,337 - Hyper-Parameters - INFO - TRIAL 529. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.09, 'max_iter': 44}; Score: 0.7858426086799593\n",
      "2022-07-14 20:47:20,950 - Hyper-Parameters - INFO - TRIAL 530. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:21,547 - Hyper-Parameters - INFO - TRIAL 532. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:22,167 - Hyper-Parameters - INFO - TRIAL 537. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:22,777 - Hyper-Parameters - INFO - TRIAL 539. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 46}; Score: 0.7896620382423478\n",
      "2022-07-14 20:47:23,333 - Hyper-Parameters - INFO - TRIAL 540. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:23,973 - Hyper-Parameters - INFO - TRIAL 541. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:24,565 - Hyper-Parameters - INFO - TRIAL 543. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:25,115 - Hyper-Parameters - INFO - TRIAL 544. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:25,699 - Hyper-Parameters - INFO - TRIAL 545. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:26,307 - Hyper-Parameters - INFO - TRIAL 546. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 44}; Score: 0.789808217291193\n",
      "2022-07-14 20:47:26,866 - Hyper-Parameters - INFO - TRIAL 549. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:27,429 - Hyper-Parameters - INFO - TRIAL 550. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 40}; Score: 0.7896620382423478\n",
      "2022-07-14 20:47:28,017 - Hyper-Parameters - INFO - TRIAL 552. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:28,589 - Hyper-Parameters - INFO - TRIAL 553. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 40}; Score: 0.789808217291193\n",
      "2022-07-14 20:47:29,204 - Hyper-Parameters - INFO - TRIAL 556. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:29,906 - Hyper-Parameters - INFO - TRIAL 558. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.08, 'max_iter': 44}; Score: 0.7878594965430807\n",
      "2022-07-14 20:47:30,476 - Hyper-Parameters - INFO - TRIAL 559. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:31,069 - Hyper-Parameters - INFO - TRIAL 561. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:31,662 - Hyper-Parameters - INFO - TRIAL 564. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:32,053 - Hyper-Parameters - INFO - TRIAL 566. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 54}; Score: 0.7676539987218554\n",
      "2022-07-14 20:47:32,617 - Hyper-Parameters - INFO - TRIAL 567. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 46}; Score: 0.7896620382423478\n",
      "2022-07-14 20:47:33,243 - Hyper-Parameters - INFO - TRIAL 568. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:33,831 - Hyper-Parameters - INFO - TRIAL 570. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07, 'max_iter': 42}; Score: 0.7881000053127035\n",
      "2022-07-14 20:47:34,502 - Hyper-Parameters - INFO - TRIAL 572. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:35,118 - Hyper-Parameters - INFO - TRIAL 574. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:35,683 - Hyper-Parameters - INFO - TRIAL 575. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 50}; Score: 0.789808217291193\n",
      "2022-07-14 20:47:36,293 - Hyper-Parameters - INFO - TRIAL 576. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:36,897 - Hyper-Parameters - INFO - TRIAL 577. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:37,493 - Hyper-Parameters - INFO - TRIAL 578. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:38,072 - Hyper-Parameters - INFO - TRIAL 579. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:38,739 - Hyper-Parameters - INFO - TRIAL 581. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 44}; Score: 0.7896620382423478\n",
      "2022-07-14 20:47:39,337 - Hyper-Parameters - INFO - TRIAL 583. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:39,979 - Hyper-Parameters - INFO - TRIAL 584. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:40,601 - Hyper-Parameters - INFO - TRIAL 585. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:41,163 - Hyper-Parameters - INFO - TRIAL 586. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:41,744 - Hyper-Parameters - INFO - TRIAL 587. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:42,381 - Hyper-Parameters - INFO - TRIAL 590. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:42,955 - Hyper-Parameters - INFO - TRIAL 592. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 60}; Score: 0.789808217291193\n",
      "2022-07-14 20:47:43,653 - Hyper-Parameters - INFO - TRIAL 595. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.1, 'max_iter': 40}; Score: 0.7849401308591\n",
      "2022-07-14 20:47:44,298 - Hyper-Parameters - INFO - TRIAL 596. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:44,867 - Hyper-Parameters - INFO - TRIAL 597. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:45,533 - Hyper-Parameters - INFO - TRIAL 598. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:46,116 - Hyper-Parameters - INFO - TRIAL 599. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:47:46,701 - Hyper-Parameters - INFO - TRIAL 601. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:47:47,298 - Hyper-Parameters - INFO - TRIAL 603. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:47,946 - Hyper-Parameters - INFO - TRIAL 604. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:48,594 - Hyper-Parameters - INFO - TRIAL 605. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:49,220 - Hyper-Parameters - INFO - TRIAL 606. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 54}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:49,868 - Hyper-Parameters - INFO - TRIAL 608. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:50,451 - Hyper-Parameters - INFO - TRIAL 610. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:47:51,115 - Hyper-Parameters - INFO - TRIAL 613. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:51,751 - Hyper-Parameters - INFO - TRIAL 615. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:52,360 - Hyper-Parameters - INFO - TRIAL 616. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:47:52,956 - Hyper-Parameters - INFO - TRIAL 617. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:53,591 - Hyper-Parameters - INFO - TRIAL 619. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:54,195 - Hyper-Parameters - INFO - TRIAL 621. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:54,826 - Hyper-Parameters - INFO - TRIAL 623. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:55,441 - Hyper-Parameters - INFO - TRIAL 624. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:56,086 - Hyper-Parameters - INFO - TRIAL 626. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:47:56,719 - Hyper-Parameters - INFO - TRIAL 628. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 50}; Score: 0.789808217291193\n",
      "2022-07-14 20:47:57,353 - Hyper-Parameters - INFO - TRIAL 629. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:57,930 - Hyper-Parameters - INFO - TRIAL 630. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:58,655 - Hyper-Parameters - INFO - TRIAL 632. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.085, 'max_iter': 48}; Score: 0.7873915552483234\n",
      "2022-07-14 20:47:59,272 - Hyper-Parameters - INFO - TRIAL 635. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:47:59,870 - Hyper-Parameters - INFO - TRIAL 637. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:00,473 - Hyper-Parameters - INFO - TRIAL 638. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:00,948 - Hyper-Parameters - INFO - TRIAL 639. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7676539987218554\n",
      "2022-07-14 20:48:01,573 - Hyper-Parameters - INFO - TRIAL 641. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:02,184 - Hyper-Parameters - INFO - TRIAL 642. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:02,792 - Hyper-Parameters - INFO - TRIAL 643. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 46}; Score: 0.7896620382423478\n",
      "2022-07-14 20:48:03,410 - Hyper-Parameters - INFO - TRIAL 644. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:04,048 - Hyper-Parameters - INFO - TRIAL 645. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:04,625 - Hyper-Parameters - INFO - TRIAL 646. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.065, 'max_iter': 48}; Score: 0.7886045038906973\n",
      "2022-07-14 20:48:05,219 - Hyper-Parameters - INFO - TRIAL 647. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 44}; Score: 0.789808217291193\n",
      "2022-07-14 20:48:05,844 - Hyper-Parameters - INFO - TRIAL 650. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:06,446 - Hyper-Parameters - INFO - TRIAL 651. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:07,037 - Hyper-Parameters - INFO - TRIAL 652. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:07,684 - Hyper-Parameters - INFO - TRIAL 653. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:08,303 - Hyper-Parameters - INFO - TRIAL 655. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:08,901 - Hyper-Parameters - INFO - TRIAL 658. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 46}; Score: 0.7896620382423478\n",
      "2022-07-14 20:48:09,352 - Hyper-Parameters - INFO - TRIAL 660. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 42}; Score: 0.7706817631464509\n",
      "2022-07-14 20:48:10,003 - Hyper-Parameters - INFO - TRIAL 661. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:10,569 - Hyper-Parameters - INFO - TRIAL 663. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:11,147 - Hyper-Parameters - INFO - TRIAL 664. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:11,836 - Hyper-Parameters - INFO - TRIAL 667. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:12,441 - Hyper-Parameters - INFO - TRIAL 668. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:13,067 - Hyper-Parameters - INFO - TRIAL 669. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:13,666 - Hyper-Parameters - INFO - TRIAL 671. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 46}; Score: 0.7896620382423478\n",
      "2022-07-14 20:48:14,269 - Hyper-Parameters - INFO - TRIAL 673. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:14,951 - Hyper-Parameters - INFO - TRIAL 675. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.08, 'max_iter': 42}; Score: 0.7878594965430807\n",
      "2022-07-14 20:48:15,598 - Hyper-Parameters - INFO - TRIAL 677. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:16,198 - Hyper-Parameters - INFO - TRIAL 678. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:16,688 - Hyper-Parameters - INFO - TRIAL 681. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7676539987218554\n",
      "2022-07-14 20:48:17,385 - Hyper-Parameters - INFO - TRIAL 682. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 48}; Score: 0.789808217291193\n",
      "2022-07-14 20:48:17,968 - Hyper-Parameters - INFO - TRIAL 684. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:18,601 - Hyper-Parameters - INFO - TRIAL 685. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:19,254 - Hyper-Parameters - INFO - TRIAL 686. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:19,836 - Hyper-Parameters - INFO - TRIAL 687. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 42}; Score: 0.789808217291193\n",
      "2022-07-14 20:48:20,472 - Hyper-Parameters - INFO - TRIAL 690. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 42}; Score: 0.7896620382423478\n",
      "2022-07-14 20:48:21,116 - Hyper-Parameters - INFO - TRIAL 692. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:21,700 - Hyper-Parameters - INFO - TRIAL 693. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:22,337 - Hyper-Parameters - INFO - TRIAL 696. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:22,980 - Hyper-Parameters - INFO - TRIAL 697. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:23,549 - Hyper-Parameters - INFO - TRIAL 698. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:24,211 - Hyper-Parameters - INFO - TRIAL 700. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07, 'max_iter': 58}; Score: 0.7881000053127035\n",
      "2022-07-14 20:48:24,853 - Hyper-Parameters - INFO - TRIAL 702. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:25,504 - Hyper-Parameters - INFO - TRIAL 703. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.09, 'max_iter': 58}; Score: 0.7858426086799593\n",
      "2022-07-14 20:48:26,116 - Hyper-Parameters - INFO - TRIAL 704. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:26,769 - Hyper-Parameters - INFO - TRIAL 707. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:27,352 - Hyper-Parameters - INFO - TRIAL 708. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:28,024 - Hyper-Parameters - INFO - TRIAL 709. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 42}; Score: 0.7896620382423478\n",
      "2022-07-14 20:48:28,660 - Hyper-Parameters - INFO - TRIAL 711. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 50}; Score: 0.789808217291193\n",
      "2022-07-14 20:48:29,237 - Hyper-Parameters - INFO - TRIAL 712. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:29,871 - Hyper-Parameters - INFO - TRIAL 714. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:30,503 - Hyper-Parameters - INFO - TRIAL 715. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:31,084 - Hyper-Parameters - INFO - TRIAL 717. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:31,698 - Hyper-Parameters - INFO - TRIAL 719. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:32,324 - Hyper-Parameters - INFO - TRIAL 721. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:32,879 - Hyper-Parameters - INFO - TRIAL 722. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 50}; Score: 0.7896620382423478\n",
      "2022-07-14 20:48:33,514 - Hyper-Parameters - INFO - TRIAL 723. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:34,148 - Hyper-Parameters - INFO - TRIAL 726. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 54}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:34,558 - Hyper-Parameters - INFO - TRIAL 727. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7676539987218554\n",
      "2022-07-14 20:48:35,169 - Hyper-Parameters - INFO - TRIAL 728. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:35,785 - Hyper-Parameters - INFO - TRIAL 730. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 48}; Score: 0.789808217291193\n",
      "2022-07-14 20:48:36,361 - Hyper-Parameters - INFO - TRIAL 731. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:36,996 - Hyper-Parameters - INFO - TRIAL 732. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 42}; Score: 0.7896620382423478\n",
      "2022-07-14 20:48:37,601 - Hyper-Parameters - INFO - TRIAL 734. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 54}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:38,179 - Hyper-Parameters - INFO - TRIAL 735. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:38,825 - Hyper-Parameters - INFO - TRIAL 736. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:39,444 - Hyper-Parameters - INFO - TRIAL 737. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 52}; Score: 0.789808217291193\n",
      "2022-07-14 20:48:40,021 - Hyper-Parameters - INFO - TRIAL 738. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:40,708 - Hyper-Parameters - INFO - TRIAL 743. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:41,353 - Hyper-Parameters - INFO - TRIAL 744. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:41,939 - Hyper-Parameters - INFO - TRIAL 747. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:42,566 - Hyper-Parameters - INFO - TRIAL 749. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:48:43,014 - Hyper-Parameters - INFO - TRIAL 750. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 60}; Score: 0.7706817631464509\n",
      "2022-07-14 20:48:43,618 - Hyper-Parameters - INFO - TRIAL 751. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:44,250 - Hyper-Parameters - INFO - TRIAL 753. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:44,898 - Hyper-Parameters - INFO - TRIAL 755. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:45,553 - Hyper-Parameters - INFO - TRIAL 756. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07500000000000001, 'max_iter': 42}; Score: 0.788100402137102\n",
      "2022-07-14 20:48:46,178 - Hyper-Parameters - INFO - TRIAL 758. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:46,778 - Hyper-Parameters - INFO - TRIAL 759. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:47,370 - Hyper-Parameters - INFO - TRIAL 760. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:48,016 - Hyper-Parameters - INFO - TRIAL 761. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:48,670 - Hyper-Parameters - INFO - TRIAL 762. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:49,335 - Hyper-Parameters - INFO - TRIAL 764. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:48:49,984 - Hyper-Parameters - INFO - TRIAL 766. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 46}; Score: 0.7896620382423478\n",
      "2022-07-14 20:48:50,646 - Hyper-Parameters - INFO - TRIAL 768. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:51,250 - Hyper-Parameters - INFO - TRIAL 770. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:51,852 - Hyper-Parameters - INFO - TRIAL 772. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:52,475 - Hyper-Parameters - INFO - TRIAL 774. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:53,043 - Hyper-Parameters - INFO - TRIAL 775. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:53,648 - Hyper-Parameters - INFO - TRIAL 777. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:54,319 - Hyper-Parameters - INFO - TRIAL 778. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 54}; Score: 0.789808217291193\n",
      "2022-07-14 20:48:54,897 - Hyper-Parameters - INFO - TRIAL 779. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 42}; Score: 0.7896620382423478\n",
      "2022-07-14 20:48:55,536 - Hyper-Parameters - INFO - TRIAL 781. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:56,133 - Hyper-Parameters - INFO - TRIAL 782. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:56,753 - Hyper-Parameters - INFO - TRIAL 783. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:57,339 - Hyper-Parameters - INFO - TRIAL 784. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:58,001 - Hyper-Parameters - INFO - TRIAL 786. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:58,607 - Hyper-Parameters - INFO - TRIAL 787. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:59,218 - Hyper-Parameters - INFO - TRIAL 788. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:48:59,976 - Hyper-Parameters - INFO - TRIAL 790. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.095, 'max_iter': 48}; Score: 0.7850800530975821\n",
      "2022-07-14 20:49:00,547 - Hyper-Parameters - INFO - TRIAL 791. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:01,172 - Hyper-Parameters - INFO - TRIAL 793. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:01,803 - Hyper-Parameters - INFO - TRIAL 796. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 56}; Score: 0.7896620382423478\n",
      "2022-07-14 20:49:02,421 - Hyper-Parameters - INFO - TRIAL 798. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:03,036 - Hyper-Parameters - INFO - TRIAL 800. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:49:03,646 - Hyper-Parameters - INFO - TRIAL 802. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:04,214 - Hyper-Parameters - INFO - TRIAL 803. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:04,890 - Hyper-Parameters - INFO - TRIAL 804. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:05,501 - Hyper-Parameters - INFO - TRIAL 806. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 42}; Score: 0.7896620382423478\n",
      "2022-07-14 20:49:06,071 - Hyper-Parameters - INFO - TRIAL 807. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:06,681 - Hyper-Parameters - INFO - TRIAL 808. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:49:07,315 - Hyper-Parameters - INFO - TRIAL 809. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:07,881 - Hyper-Parameters - INFO - TRIAL 810. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:08,547 - Hyper-Parameters - INFO - TRIAL 811. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:09,153 - Hyper-Parameters - INFO - TRIAL 812. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:09,761 - Hyper-Parameters - INFO - TRIAL 814. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:10,486 - Hyper-Parameters - INFO - TRIAL 815. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:11,102 - Hyper-Parameters - INFO - TRIAL 816. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:11,531 - Hyper-Parameters - INFO - TRIAL 817. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7676539987218554\n",
      "2022-07-14 20:49:12,139 - Hyper-Parameters - INFO - TRIAL 818. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 42}; Score: 0.7896620382423478\n",
      "2022-07-14 20:49:12,783 - Hyper-Parameters - INFO - TRIAL 819. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:13,434 - Hyper-Parameters - INFO - TRIAL 820. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 42}; Score: 0.789808217291193\n",
      "2022-07-14 20:49:14,071 - Hyper-Parameters - INFO - TRIAL 822. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:14,702 - Hyper-Parameters - INFO - TRIAL 825. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:15,290 - Hyper-Parameters - INFO - TRIAL 826. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:15,957 - Hyper-Parameters - INFO - TRIAL 827. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:16,600 - Hyper-Parameters - INFO - TRIAL 829. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 44}; Score: 0.7896620382423478\n",
      "2022-07-14 20:49:17,188 - Hyper-Parameters - INFO - TRIAL 831. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:18,101 - Hyper-Parameters - INFO - TRIAL 832. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07, 'max_iter': 60}; Score: 0.7881000053127035\n",
      "2022-07-14 20:49:18,768 - Hyper-Parameters - INFO - TRIAL 834. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.065, 'max_iter': 56}; Score: 0.7886045038906973\n",
      "2022-07-14 20:49:19,385 - Hyper-Parameters - INFO - TRIAL 835. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 60}; Score: 0.789808217291193\n",
      "2022-07-14 20:49:20,030 - Hyper-Parameters - INFO - TRIAL 838. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:20,651 - Hyper-Parameters - INFO - TRIAL 839. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:21,302 - Hyper-Parameters - INFO - TRIAL 842. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:21,952 - Hyper-Parameters - INFO - TRIAL 843. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:22,615 - Hyper-Parameters - INFO - TRIAL 845. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:23,202 - Hyper-Parameters - INFO - TRIAL 846. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:23,869 - Hyper-Parameters - INFO - TRIAL 847. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:24,534 - Hyper-Parameters - INFO - TRIAL 850. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 50}; Score: 0.789808217291193\n",
      "2022-07-14 20:49:25,136 - Hyper-Parameters - INFO - TRIAL 852. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 60}; Score: 0.7896620382423478\n",
      "2022-07-14 20:49:25,817 - Hyper-Parameters - INFO - TRIAL 854. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:26,520 - Hyper-Parameters - INFO - TRIAL 855. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:27,152 - Hyper-Parameters - INFO - TRIAL 856. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:27,818 - Hyper-Parameters - INFO - TRIAL 858. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:28,330 - Hyper-Parameters - INFO - TRIAL 861. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 60}; Score: 0.7706817631464509\n",
      "2022-07-14 20:49:28,902 - Hyper-Parameters - INFO - TRIAL 862. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:29,510 - Hyper-Parameters - INFO - TRIAL 863. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:30,185 - Hyper-Parameters - INFO - TRIAL 866. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 40}; Score: 0.7896620382423478\n",
      "2022-07-14 20:49:30,800 - Hyper-Parameters - INFO - TRIAL 868. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:31,404 - Hyper-Parameters - INFO - TRIAL 869. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:32,066 - Hyper-Parameters - INFO - TRIAL 870. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:32,640 - Hyper-Parameters - INFO - TRIAL 871. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:33,267 - Hyper-Parameters - INFO - TRIAL 872. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:33,873 - Hyper-Parameters - INFO - TRIAL 873. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 54}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:34,483 - Hyper-Parameters - INFO - TRIAL 875. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 54}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:35,123 - Hyper-Parameters - INFO - TRIAL 877. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 54}; Score: 0.789808217291193\n",
      "2022-07-14 20:49:35,756 - Hyper-Parameters - INFO - TRIAL 879. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:36,340 - Hyper-Parameters - INFO - TRIAL 880. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:49:37,005 - Hyper-Parameters - INFO - TRIAL 881. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:37,657 - Hyper-Parameters - INFO - TRIAL 882. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:38,288 - Hyper-Parameters - INFO - TRIAL 885. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:38,884 - Hyper-Parameters - INFO - TRIAL 886. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:39,513 - Hyper-Parameters - INFO - TRIAL 887. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:40,184 - Hyper-Parameters - INFO - TRIAL 889. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:40,816 - Hyper-Parameters - INFO - TRIAL 891. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:41,456 - Hyper-Parameters - INFO - TRIAL 892. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:42,083 - Hyper-Parameters - INFO - TRIAL 894. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 40}; Score: 0.7896620382423478\n",
      "2022-07-14 20:49:42,735 - Hyper-Parameters - INFO - TRIAL 896. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 40}; Score: 0.789808217291193\n",
      "2022-07-14 20:49:43,422 - Hyper-Parameters - INFO - TRIAL 897. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.08, 'max_iter': 48}; Score: 0.7878594965430807\n",
      "2022-07-14 20:49:44,011 - Hyper-Parameters - INFO - TRIAL 898. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:44,655 - Hyper-Parameters - INFO - TRIAL 899. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:45,283 - Hyper-Parameters - INFO - TRIAL 900. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:45,969 - Hyper-Parameters - INFO - TRIAL 905. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:46,548 - Hyper-Parameters - INFO - TRIAL 906. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:47,168 - Hyper-Parameters - INFO - TRIAL 907. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:47,816 - Hyper-Parameters - INFO - TRIAL 908. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:48,454 - Hyper-Parameters - INFO - TRIAL 909. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 50}; Score: 0.7896620382423478\n",
      "2022-07-14 20:49:49,050 - Hyper-Parameters - INFO - TRIAL 910. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:49,706 - Hyper-Parameters - INFO - TRIAL 912. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:50,331 - Hyper-Parameters - INFO - TRIAL 913. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 44}; Score: 0.789808217291193\n",
      "2022-07-14 20:49:50,968 - Hyper-Parameters - INFO - TRIAL 915. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:51,586 - Hyper-Parameters - INFO - TRIAL 916. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:52,223 - Hyper-Parameters - INFO - TRIAL 917. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:52,941 - Hyper-Parameters - INFO - TRIAL 921. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 42}; Score: 0.7896620382423478\n",
      "2022-07-14 20:49:53,556 - Hyper-Parameters - INFO - TRIAL 922. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 42}; Score: 0.789808217291193\n",
      "2022-07-14 20:49:54,167 - Hyper-Parameters - INFO - TRIAL 924. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:54,833 - Hyper-Parameters - INFO - TRIAL 925. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:55,295 - Hyper-Parameters - INFO - TRIAL 927. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.085, 'max_iter': 44}; Score: 0.7802447135372184\n",
      "2022-07-14 20:49:55,865 - Hyper-Parameters - INFO - TRIAL 928. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:56,484 - Hyper-Parameters - INFO - TRIAL 929. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:57,063 - Hyper-Parameters - INFO - TRIAL 930. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:57,772 - Hyper-Parameters - INFO - TRIAL 932. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.1, 'max_iter': 42}; Score: 0.7849401308591\n",
      "2022-07-14 20:49:58,454 - Hyper-Parameters - INFO - TRIAL 933. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 46}; Score: 0.7896620382423478\n",
      "2022-07-14 20:49:59,039 - Hyper-Parameters - INFO - TRIAL 935. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:49:59,683 - Hyper-Parameters - INFO - TRIAL 936. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:00,303 - Hyper-Parameters - INFO - TRIAL 937. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:00,960 - Hyper-Parameters - INFO - TRIAL 938. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 52}; Score: 0.789808217291193\n",
      "2022-07-14 20:50:01,585 - Hyper-Parameters - INFO - TRIAL 940. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:02,219 - Hyper-Parameters - INFO - TRIAL 941. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:02,818 - Hyper-Parameters - INFO - TRIAL 942. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:03,464 - Hyper-Parameters - INFO - TRIAL 944. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:04,165 - Hyper-Parameters - INFO - TRIAL 947. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:04,598 - Hyper-Parameters - INFO - TRIAL 950. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7676539987218554\n",
      "2022-07-14 20:50:05,187 - Hyper-Parameters - INFO - TRIAL 951. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 60}; Score: 0.7896620382423478\n",
      "2022-07-14 20:50:05,881 - Hyper-Parameters - INFO - TRIAL 953. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07, 'max_iter': 48}; Score: 0.7881000053127035\n",
      "2022-07-14 20:50:06,505 - Hyper-Parameters - INFO - TRIAL 954. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 58}; Score: 0.789808217291193\n",
      "2022-07-14 20:50:07,069 - Hyper-Parameters - INFO - TRIAL 955. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:07,716 - Hyper-Parameters - INFO - TRIAL 957. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:08,348 - Hyper-Parameters - INFO - TRIAL 959. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:08,973 - Hyper-Parameters - INFO - TRIAL 960. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:09,612 - Hyper-Parameters - INFO - TRIAL 962. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:10,251 - Hyper-Parameters - INFO - TRIAL 965. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:10,870 - Hyper-Parameters - INFO - TRIAL 966. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 50}; Score: 0.7896620382423478\n",
      "2022-07-14 20:50:11,536 - Hyper-Parameters - INFO - TRIAL 968. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:12,152 - Hyper-Parameters - INFO - TRIAL 969. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:12,753 - Hyper-Parameters - INFO - TRIAL 970. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:13,376 - Hyper-Parameters - INFO - TRIAL 971. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:14,016 - Hyper-Parameters - INFO - TRIAL 973. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 52}; Score: 0.789808217291193\n",
      "2022-07-14 20:50:14,490 - Hyper-Parameters - INFO - TRIAL 974. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 54}; Score: 0.7676539987218554\n",
      "2022-07-14 20:50:15,126 - Hyper-Parameters - INFO - TRIAL 976. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:15,733 - Hyper-Parameters - INFO - TRIAL 977. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:16,300 - Hyper-Parameters - INFO - TRIAL 979. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 46}; Score: 0.7896620382423478\n",
      "2022-07-14 20:50:17,185 - Hyper-Parameters - INFO - TRIAL 982. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.09, 'max_iter': 42}; Score: 0.7858426086799593\n",
      "2022-07-14 20:50:17,801 - Hyper-Parameters - INFO - TRIAL 984. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:18,419 - Hyper-Parameters - INFO - TRIAL 985. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 48}; Score: 0.789808217291193\n",
      "2022-07-14 20:50:19,050 - Hyper-Parameters - INFO - TRIAL 986. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:19,703 - Hyper-Parameters - INFO - TRIAL 987. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:20,316 - Hyper-Parameters - INFO - TRIAL 988. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:21,062 - Hyper-Parameters - INFO - TRIAL 990. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07500000000000001, 'max_iter': 42}; Score: 0.788100402137102\n",
      "2022-07-14 20:50:21,688 - Hyper-Parameters - INFO - TRIAL 992. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:22,267 - Hyper-Parameters - INFO - TRIAL 993. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:22,919 - Hyper-Parameters - INFO - TRIAL 994. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:23,317 - Hyper-Parameters - INFO - TRIAL 995. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 42}; Score: 0.7706817631464509\n",
      "2022-07-14 20:50:23,902 - Hyper-Parameters - INFO - TRIAL 996. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:24,577 - Hyper-Parameters - INFO - TRIAL 999. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 44}; Score: 0.7896620382423478\n",
      "2022-07-14 20:50:25,253 - Hyper-Parameters - INFO - TRIAL 1000. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:25,883 - Hyper-Parameters - INFO - TRIAL 1002. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:26,534 - Hyper-Parameters - INFO - TRIAL 1003. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:27,165 - Hyper-Parameters - INFO - TRIAL 1004. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:27,736 - Hyper-Parameters - INFO - TRIAL 1005. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:28,365 - Hyper-Parameters - INFO - TRIAL 1006. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:29,027 - Hyper-Parameters - INFO - TRIAL 1009. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 42}; Score: 0.7896620382423478\n",
      "2022-07-14 20:50:29,639 - Hyper-Parameters - INFO - TRIAL 1011. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:30,371 - Hyper-Parameters - INFO - TRIAL 1012. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:30,981 - Hyper-Parameters - INFO - TRIAL 1014. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:31,420 - Hyper-Parameters - INFO - TRIAL 1016. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 42}; Score: 0.7706817631464509\n",
      "2022-07-14 20:50:32,049 - Hyper-Parameters - INFO - TRIAL 1017. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:32,683 - Hyper-Parameters - INFO - TRIAL 1019. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:33,307 - Hyper-Parameters - INFO - TRIAL 1021. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:33,963 - Hyper-Parameters - INFO - TRIAL 1022. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 58}; Score: 0.789808217291193\n",
      "2022-07-14 20:50:34,563 - Hyper-Parameters - INFO - TRIAL 1023. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:35,183 - Hyper-Parameters - INFO - TRIAL 1024. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:35,889 - Hyper-Parameters - INFO - TRIAL 1027. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 44}; Score: 0.7896620382423478\n",
      "2022-07-14 20:50:36,493 - Hyper-Parameters - INFO - TRIAL 1028. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:37,098 - Hyper-Parameters - INFO - TRIAL 1029. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:37,735 - Hyper-Parameters - INFO - TRIAL 1030. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:38,377 - Hyper-Parameters - INFO - TRIAL 1033. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:38,997 - Hyper-Parameters - INFO - TRIAL 1036. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 54}; Score: 0.7896620382423478\n",
      "2022-07-14 20:50:39,721 - Hyper-Parameters - INFO - TRIAL 1038. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:40,120 - Hyper-Parameters - INFO - TRIAL 1039. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.065, 'max_iter': 44}; Score: 0.7723418649775929\n",
      "2022-07-14 20:50:40,738 - Hyper-Parameters - INFO - TRIAL 1040. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:41,406 - Hyper-Parameters - INFO - TRIAL 1042. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:42,068 - Hyper-Parameters - INFO - TRIAL 1044. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:42,703 - Hyper-Parameters - INFO - TRIAL 1045. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 54}; Score: 0.789808217291193\n",
      "2022-07-14 20:50:43,359 - Hyper-Parameters - INFO - TRIAL 1047. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:43,941 - Hyper-Parameters - INFO - TRIAL 1048. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:44,569 - Hyper-Parameters - INFO - TRIAL 1049. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:45,167 - Hyper-Parameters - INFO - TRIAL 1050. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:45,753 - Hyper-Parameters - INFO - TRIAL 1051. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 58}; Score: 0.789808217291193\n",
      "2022-07-14 20:50:46,427 - Hyper-Parameters - INFO - TRIAL 1053. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 54}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:47,055 - Hyper-Parameters - INFO - TRIAL 1056. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:47,670 - Hyper-Parameters - INFO - TRIAL 1058. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 52}; Score: 0.7896620382423478\n",
      "2022-07-14 20:50:48,254 - Hyper-Parameters - INFO - TRIAL 1060. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:48,891 - Hyper-Parameters - INFO - TRIAL 1061. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:49,538 - Hyper-Parameters - INFO - TRIAL 1063. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:50,166 - Hyper-Parameters - INFO - TRIAL 1064. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:50,818 - Hyper-Parameters - INFO - TRIAL 1067. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:51,516 - Hyper-Parameters - INFO - TRIAL 1068. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.085, 'max_iter': 40}; Score: 0.7873915552483234\n",
      "2022-07-14 20:50:52,157 - Hyper-Parameters - INFO - TRIAL 1070. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 40}; Score: 0.7896620382423478\n",
      "2022-07-14 20:50:52,783 - Hyper-Parameters - INFO - TRIAL 1071. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:53,399 - Hyper-Parameters - INFO - TRIAL 1072. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 40}; Score: 0.789808217291193\n",
      "2022-07-14 20:50:53,992 - Hyper-Parameters - INFO - TRIAL 1074. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:54,654 - Hyper-Parameters - INFO - TRIAL 1075. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:55,313 - Hyper-Parameters - INFO - TRIAL 1076. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:55,960 - Hyper-Parameters - INFO - TRIAL 1078. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:56,594 - Hyper-Parameters - INFO - TRIAL 1079. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:50:57,257 - Hyper-Parameters - INFO - TRIAL 1081. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:57,900 - Hyper-Parameters - INFO - TRIAL 1084. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 46}; Score: 0.7896620382423478\n",
      "2022-07-14 20:50:58,586 - Hyper-Parameters - INFO - TRIAL 1086. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:59,214 - Hyper-Parameters - INFO - TRIAL 1087. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:50:59,795 - Hyper-Parameters - INFO - TRIAL 1088. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:00,458 - Hyper-Parameters - INFO - TRIAL 1091. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:01,164 - Hyper-Parameters - INFO - TRIAL 1095. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:01,839 - Hyper-Parameters - INFO - TRIAL 1097. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07500000000000001, 'max_iter': 50}; Score: 0.788100402137102\n",
      "2022-07-14 20:51:02,500 - Hyper-Parameters - INFO - TRIAL 1098. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:03,135 - Hyper-Parameters - INFO - TRIAL 1099. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:03,790 - Hyper-Parameters - INFO - TRIAL 1100. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:04,407 - Hyper-Parameters - INFO - TRIAL 1102. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 50}; Score: 0.7896620382423478\n",
      "2022-07-14 20:51:05,002 - Hyper-Parameters - INFO - TRIAL 1103. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:05,652 - Hyper-Parameters - INFO - TRIAL 1105. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:06,092 - Hyper-Parameters - INFO - TRIAL 1106. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 50}; Score: 0.7706817631464509\n",
      "2022-07-14 20:51:06,722 - Hyper-Parameters - INFO - TRIAL 1108. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 54}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:07,353 - Hyper-Parameters - INFO - TRIAL 1109. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:08,039 - Hyper-Parameters - INFO - TRIAL 1111. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 54}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:08,671 - Hyper-Parameters - INFO - TRIAL 1113. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 60}; Score: 0.7896620382423478\n",
      "2022-07-14 20:51:09,318 - Hyper-Parameters - INFO - TRIAL 1115. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:09,916 - Hyper-Parameters - INFO - TRIAL 1116. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 48}; Score: 0.789808217291193\n",
      "2022-07-14 20:51:10,515 - Hyper-Parameters - INFO - TRIAL 1117. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:11,155 - Hyper-Parameters - INFO - TRIAL 1118. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:11,764 - Hyper-Parameters - INFO - TRIAL 1119. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:12,419 - Hyper-Parameters - INFO - TRIAL 1123. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:13,068 - Hyper-Parameters - INFO - TRIAL 1124. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:13,738 - Hyper-Parameters - INFO - TRIAL 1126. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:14,419 - Hyper-Parameters - INFO - TRIAL 1127. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:14,847 - Hyper-Parameters - INFO - TRIAL 1128. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7676539987218554\n",
      "2022-07-14 20:51:15,730 - Hyper-Parameters - INFO - TRIAL 1131. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 44}; Score: 0.7896620382423478\n",
      "2022-07-14 20:51:16,369 - Hyper-Parameters - INFO - TRIAL 1132. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:17,000 - Hyper-Parameters - INFO - TRIAL 1134. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 60}; Score: 0.789808217291193\n",
      "2022-07-14 20:51:17,634 - Hyper-Parameters - INFO - TRIAL 1135. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:18,354 - Hyper-Parameters - INFO - TRIAL 1136. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:19,033 - Hyper-Parameters - INFO - TRIAL 1139. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:19,665 - Hyper-Parameters - INFO - TRIAL 1140. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:20,284 - Hyper-Parameters - INFO - TRIAL 1141. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 52}; Score: 0.7896620382423478\n",
      "2022-07-14 20:51:20,921 - Hyper-Parameters - INFO - TRIAL 1144. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:21,550 - Hyper-Parameters - INFO - TRIAL 1145. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:51:22,199 - Hyper-Parameters - INFO - TRIAL 1147. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:22,666 - Hyper-Parameters - INFO - TRIAL 1150. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7676539987218554\n",
      "2022-07-14 20:51:23,334 - Hyper-Parameters - INFO - TRIAL 1152. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:24,041 - Hyper-Parameters - INFO - TRIAL 1153. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:24,637 - Hyper-Parameters - INFO - TRIAL 1154. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:25,276 - Hyper-Parameters - INFO - TRIAL 1157. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 46}; Score: 0.7896620382423478\n",
      "2022-07-14 20:51:25,903 - Hyper-Parameters - INFO - TRIAL 1158. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:26,475 - Hyper-Parameters - INFO - TRIAL 1159. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:27,121 - Hyper-Parameters - INFO - TRIAL 1160. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:27,783 - Hyper-Parameters - INFO - TRIAL 1162. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:51:28,437 - Hyper-Parameters - INFO - TRIAL 1164. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:29,137 - Hyper-Parameters - INFO - TRIAL 1166. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:29,728 - Hyper-Parameters - INFO - TRIAL 1167. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:30,359 - Hyper-Parameters - INFO - TRIAL 1170. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:31,018 - Hyper-Parameters - INFO - TRIAL 1171. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:31,740 - Hyper-Parameters - INFO - TRIAL 1174. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:32,345 - Hyper-Parameters - INFO - TRIAL 1175. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:51:32,994 - Hyper-Parameters - INFO - TRIAL 1176. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:33,670 - Hyper-Parameters - INFO - TRIAL 1177. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 60}; Score: 0.789808217291193\n",
      "2022-07-14 20:51:34,385 - Hyper-Parameters - INFO - TRIAL 1180. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:35,023 - Hyper-Parameters - INFO - TRIAL 1181. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:35,673 - Hyper-Parameters - INFO - TRIAL 1183. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:36,306 - Hyper-Parameters - INFO - TRIAL 1184. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 42}; Score: 0.789808217291193\n",
      "2022-07-14 20:51:36,987 - Hyper-Parameters - INFO - TRIAL 1187. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:37,770 - Hyper-Parameters - INFO - TRIAL 1188. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.08, 'max_iter': 60}; Score: 0.7878594965430807\n",
      "2022-07-14 20:51:38,536 - Hyper-Parameters - INFO - TRIAL 1190. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:39,230 - Hyper-Parameters - INFO - TRIAL 1192. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:40,181 - Hyper-Parameters - INFO - TRIAL 1196. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:40,613 - Hyper-Parameters - INFO - TRIAL 1197. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 58}; Score: 0.7653885569492547\n",
      "2022-07-14 20:51:41,218 - Hyper-Parameters - INFO - TRIAL 1198. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07, 'max_iter': 52}; Score: 0.7881000053127035\n",
      "2022-07-14 20:51:41,948 - Hyper-Parameters - INFO - TRIAL 1200. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:42,568 - Hyper-Parameters - INFO - TRIAL 1201. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:43,323 - Hyper-Parameters - INFO - TRIAL 1202. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.095, 'max_iter': 42}; Score: 0.7850800530975821\n",
      "2022-07-14 20:51:43,930 - Hyper-Parameters - INFO - TRIAL 1203. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:44,522 - Hyper-Parameters - INFO - TRIAL 1204. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:45,158 - Hyper-Parameters - INFO - TRIAL 1205. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:45,864 - Hyper-Parameters - INFO - TRIAL 1206. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.09, 'max_iter': 40}; Score: 0.7858426086799593\n",
      "2022-07-14 20:51:46,491 - Hyper-Parameters - INFO - TRIAL 1209. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.065, 'max_iter': 40}; Score: 0.7886045038906973\n",
      "2022-07-14 20:51:47,147 - Hyper-Parameters - INFO - TRIAL 1211. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:47,760 - Hyper-Parameters - INFO - TRIAL 1212. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 44}; Score: 0.789808217291193\n",
      "2022-07-14 20:51:48,368 - Hyper-Parameters - INFO - TRIAL 1214. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 40}; Score: 0.7896620382423478\n",
      "2022-07-14 20:51:48,821 - Hyper-Parameters - INFO - TRIAL 1216. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7676539987218554\n",
      "2022-07-14 20:51:49,489 - Hyper-Parameters - INFO - TRIAL 1217. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:50,174 - Hyper-Parameters - INFO - TRIAL 1218. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:50,823 - Hyper-Parameters - INFO - TRIAL 1219. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:51,458 - Hyper-Parameters - INFO - TRIAL 1221. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:52,083 - Hyper-Parameters - INFO - TRIAL 1224. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:52,736 - Hyper-Parameters - INFO - TRIAL 1225. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:53,380 - Hyper-Parameters - INFO - TRIAL 1227. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 56}; Score: 0.7896620382423478\n",
      "2022-07-14 20:51:53,976 - Hyper-Parameters - INFO - TRIAL 1228. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 48}; Score: 0.789808217291193\n",
      "2022-07-14 20:51:54,627 - Hyper-Parameters - INFO - TRIAL 1229. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:55,338 - Hyper-Parameters - INFO - TRIAL 1230. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:55,971 - Hyper-Parameters - INFO - TRIAL 1232. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:56,608 - Hyper-Parameters - INFO - TRIAL 1233. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:57,282 - Hyper-Parameters - INFO - TRIAL 1237. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 44}; Score: 0.7896620382423478\n",
      "2022-07-14 20:51:57,896 - Hyper-Parameters - INFO - TRIAL 1238. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:58,324 - Hyper-Parameters - INFO - TRIAL 1239. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7676539987218554\n",
      "2022-07-14 20:51:58,988 - Hyper-Parameters - INFO - TRIAL 1241. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:51:59,856 - Hyper-Parameters - INFO - TRIAL 1246. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 58}; Score: 0.789808217291193\n",
      "2022-07-14 20:52:00,509 - Hyper-Parameters - INFO - TRIAL 1247. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:01,198 - Hyper-Parameters - INFO - TRIAL 1249. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:01,771 - Hyper-Parameters - INFO - TRIAL 1250. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:02,443 - Hyper-Parameters - INFO - TRIAL 1253. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:03,103 - Hyper-Parameters - INFO - TRIAL 1254. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 44}; Score: 0.7896620382423478\n",
      "2022-07-14 20:52:03,735 - Hyper-Parameters - INFO - TRIAL 1255. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 54}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:04,405 - Hyper-Parameters - INFO - TRIAL 1256. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:05,039 - Hyper-Parameters - INFO - TRIAL 1257. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:05,670 - Hyper-Parameters - INFO - TRIAL 1259. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 44}; Score: 0.789808217291193\n",
      "2022-07-14 20:52:06,404 - Hyper-Parameters - INFO - TRIAL 1261. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:07,034 - Hyper-Parameters - INFO - TRIAL 1262. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:07,670 - Hyper-Parameters - INFO - TRIAL 1263. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:08,330 - Hyper-Parameters - INFO - TRIAL 1264. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:09,040 - Hyper-Parameters - INFO - TRIAL 1266. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:09,655 - Hyper-Parameters - INFO - TRIAL 1267. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 40}; Score: 0.7896620382423478\n",
      "2022-07-14 20:52:10,305 - Hyper-Parameters - INFO - TRIAL 1268. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:11,054 - Hyper-Parameters - INFO - TRIAL 1270. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.1, 'max_iter': 44}; Score: 0.7849401308591\n",
      "2022-07-14 20:52:11,704 - Hyper-Parameters - INFO - TRIAL 1272. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:12,331 - Hyper-Parameters - INFO - TRIAL 1273. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:12,930 - Hyper-Parameters - INFO - TRIAL 1274. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 58}; Score: 0.789808217291193\n",
      "2022-07-14 20:52:13,568 - Hyper-Parameters - INFO - TRIAL 1275. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:14,202 - Hyper-Parameters - INFO - TRIAL 1276. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:14,845 - Hyper-Parameters - INFO - TRIAL 1277. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:15,520 - Hyper-Parameters - INFO - TRIAL 1280. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 56}; Score: 0.789808217291193\n",
      "2022-07-14 20:52:16,150 - Hyper-Parameters - INFO - TRIAL 1281. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:16,874 - Hyper-Parameters - INFO - TRIAL 1282. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:17,509 - Hyper-Parameters - INFO - TRIAL 1285. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 40}; Score: 0.7896620382423478\n",
      "2022-07-14 20:52:18,129 - Hyper-Parameters - INFO - TRIAL 1286. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 54}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:18,804 - Hyper-Parameters - INFO - TRIAL 1288. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:19,413 - Hyper-Parameters - INFO - TRIAL 1289. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 60}; Score: 0.789808217291193\n",
      "2022-07-14 20:52:20,038 - Hyper-Parameters - INFO - TRIAL 1290. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:20,643 - Hyper-Parameters - INFO - TRIAL 1291. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:21,255 - Hyper-Parameters - INFO - TRIAL 1292. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:21,990 - Hyper-Parameters - INFO - TRIAL 1293. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:22,620 - Hyper-Parameters - INFO - TRIAL 1296. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:23,237 - Hyper-Parameters - INFO - TRIAL 1297. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 42}; Score: 0.7896620382423478\n",
      "2022-07-14 20:52:23,914 - Hyper-Parameters - INFO - TRIAL 1299. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:24,557 - Hyper-Parameters - INFO - TRIAL 1300. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:25,197 - Hyper-Parameters - INFO - TRIAL 1303. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:25,654 - Hyper-Parameters - INFO - TRIAL 1305. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 56}; Score: 0.7706817631464509\n",
      "2022-07-14 20:52:26,350 - Hyper-Parameters - INFO - TRIAL 1307. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:26,963 - Hyper-Parameters - INFO - TRIAL 1308. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:27,665 - Hyper-Parameters - INFO - TRIAL 1309. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:28,354 - Hyper-Parameters - INFO - TRIAL 1310. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 56}; Score: 0.7896620382423478\n",
      "2022-07-14 20:52:28,985 - Hyper-Parameters - INFO - TRIAL 1311. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:29,661 - Hyper-Parameters - INFO - TRIAL 1313. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:30,289 - Hyper-Parameters - INFO - TRIAL 1314. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:30,926 - Hyper-Parameters - INFO - TRIAL 1316. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:31,568 - Hyper-Parameters - INFO - TRIAL 1317. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 40}; Score: 0.7896620382423478\n",
      "2022-07-14 20:52:32,443 - Hyper-Parameters - INFO - TRIAL 1319. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:33,072 - Hyper-Parameters - INFO - TRIAL 1320. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 56}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:33,745 - Hyper-Parameters - INFO - TRIAL 1324. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:34,453 - Hyper-Parameters - INFO - TRIAL 1326. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:35,040 - Hyper-Parameters - INFO - TRIAL 1327. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:35,705 - Hyper-Parameters - INFO - TRIAL 1328. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 60}; Score: 0.789808217291193\n",
      "2022-07-14 20:52:36,408 - Hyper-Parameters - INFO - TRIAL 1331. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:37,009 - Hyper-Parameters - INFO - TRIAL 1332. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:37,673 - Hyper-Parameters - INFO - TRIAL 1333. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.065, 'max_iter': 58}; Score: 0.7886045038906973\n",
      "2022-07-14 20:52:38,345 - Hyper-Parameters - INFO - TRIAL 1334. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:52:38,958 - Hyper-Parameters - INFO - TRIAL 1335. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:39,590 - Hyper-Parameters - INFO - TRIAL 1337. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:40,241 - Hyper-Parameters - INFO - TRIAL 1338. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 54}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:40,842 - Hyper-Parameters - INFO - TRIAL 1340. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:52:41,513 - Hyper-Parameters - INFO - TRIAL 1342. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:42,133 - Hyper-Parameters - INFO - TRIAL 1343. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:42,739 - Hyper-Parameters - INFO - TRIAL 1344. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:43,489 - Hyper-Parameters - INFO - TRIAL 1348. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 58}; Score: 0.789808217291193\n",
      "2022-07-14 20:52:44,158 - Hyper-Parameters - INFO - TRIAL 1349. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:44,607 - Hyper-Parameters - INFO - TRIAL 1350. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7676539987218554\n",
      "2022-07-14 20:52:45,288 - Hyper-Parameters - INFO - TRIAL 1353. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 60}; Score: 0.7896620382423478\n",
      "2022-07-14 20:52:45,974 - Hyper-Parameters - INFO - TRIAL 1354. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:46,561 - Hyper-Parameters - INFO - TRIAL 1355. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:47,192 - Hyper-Parameters - INFO - TRIAL 1356. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:47,820 - Hyper-Parameters - INFO - TRIAL 1358. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:48,501 - Hyper-Parameters - INFO - TRIAL 1361. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:49,172 - Hyper-Parameters - INFO - TRIAL 1362. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:49,811 - Hyper-Parameters - INFO - TRIAL 1363. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:50,435 - Hyper-Parameters - INFO - TRIAL 1364. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 44}; Score: 0.789808217291193\n",
      "2022-07-14 20:52:51,106 - Hyper-Parameters - INFO - TRIAL 1366. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:51,844 - Hyper-Parameters - INFO - TRIAL 1368. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07500000000000001, 'max_iter': 58}; Score: 0.788100402137102\n",
      "2022-07-14 20:52:52,266 - Hyper-Parameters - INFO - TRIAL 1370. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7676539987218554\n",
      "2022-07-14 20:52:52,968 - Hyper-Parameters - INFO - TRIAL 1371. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:53,592 - Hyper-Parameters - INFO - TRIAL 1372. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 40}; Score: 0.7896620382423478\n",
      "2022-07-14 20:52:54,242 - Hyper-Parameters - INFO - TRIAL 1374. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:55,031 - Hyper-Parameters - INFO - TRIAL 1375. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:55,690 - Hyper-Parameters - INFO - TRIAL 1376. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:56,333 - Hyper-Parameters - INFO - TRIAL 1379. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:57,019 - Hyper-Parameters - INFO - TRIAL 1380. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 52}; Score: 0.7896620382423478\n",
      "2022-07-14 20:52:57,751 - Hyper-Parameters - INFO - TRIAL 1384. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:58,386 - Hyper-Parameters - INFO - TRIAL 1385. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:52:59,051 - Hyper-Parameters - INFO - TRIAL 1386. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 40}; Score: 0.789808217291193\n",
      "2022-07-14 20:52:59,690 - Hyper-Parameters - INFO - TRIAL 1387. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:00,339 - Hyper-Parameters - INFO - TRIAL 1388. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:00,989 - Hyper-Parameters - INFO - TRIAL 1390. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:01,627 - Hyper-Parameters - INFO - TRIAL 1392. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 54}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:02,045 - Hyper-Parameters - INFO - TRIAL 1393. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7676539987218554\n",
      "2022-07-14 20:53:02,725 - Hyper-Parameters - INFO - TRIAL 1396. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 44}; Score: 0.789808217291193\n",
      "2022-07-14 20:53:03,413 - Hyper-Parameters - INFO - TRIAL 1398. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 52}; Score: 0.7896620382423478\n",
      "2022-07-14 20:53:04,022 - Hyper-Parameters - INFO - TRIAL 1400. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 54}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:04,724 - Hyper-Parameters - INFO - TRIAL 1401. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:05,357 - Hyper-Parameters - INFO - TRIAL 1402. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:05,924 - Hyper-Parameters - INFO - TRIAL 1403. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:06,617 - Hyper-Parameters - INFO - TRIAL 1404. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07500000000000001, 'max_iter': 58}; Score: 0.788100402137102\n",
      "2022-07-14 20:53:07,501 - Hyper-Parameters - INFO - TRIAL 1407. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:08,078 - Hyper-Parameters - INFO - TRIAL 1408. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:08,769 - Hyper-Parameters - INFO - TRIAL 1410. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 52}; Score: 0.789808217291193\n",
      "2022-07-14 20:53:09,434 - Hyper-Parameters - INFO - TRIAL 1411. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:10,039 - Hyper-Parameters - INFO - TRIAL 1412. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 52}; Score: 0.7896620382423478\n",
      "2022-07-14 20:53:10,718 - Hyper-Parameters - INFO - TRIAL 1413. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:11,420 - Hyper-Parameters - INFO - TRIAL 1417. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 54}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:12,115 - Hyper-Parameters - INFO - TRIAL 1420. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:12,771 - Hyper-Parameters - INFO - TRIAL 1421. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:13,422 - Hyper-Parameters - INFO - TRIAL 1422. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:14,089 - Hyper-Parameters - INFO - TRIAL 1423. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 50}; Score: 0.7896620382423478\n",
      "2022-07-14 20:53:14,765 - Hyper-Parameters - INFO - TRIAL 1424. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.07, 'max_iter': 42}; Score: 0.7881000053127035\n",
      "2022-07-14 20:53:15,459 - Hyper-Parameters - INFO - TRIAL 1426. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:16,095 - Hyper-Parameters - INFO - TRIAL 1427. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:16,764 - Hyper-Parameters - INFO - TRIAL 1428. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:17,434 - Hyper-Parameters - INFO - TRIAL 1429. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 58}; Score: 0.789808217291193\n",
      "2022-07-14 20:53:18,071 - Hyper-Parameters - INFO - TRIAL 1431. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:18,732 - Hyper-Parameters - INFO - TRIAL 1432. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:19,672 - Hyper-Parameters - INFO - TRIAL 1436. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:20,082 - Hyper-Parameters - INFO - TRIAL 1437. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l1', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7676539987218554\n",
      "2022-07-14 20:53:20,743 - Hyper-Parameters - INFO - TRIAL 1438. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 56}; Score: 0.789808217291193\n",
      "2022-07-14 20:53:21,426 - Hyper-Parameters - INFO - TRIAL 1440. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:22,040 - Hyper-Parameters - INFO - TRIAL 1441. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 50}; Score: 0.7896620382423478\n",
      "2022-07-14 20:53:22,693 - Hyper-Parameters - INFO - TRIAL 1442. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:23,290 - Hyper-Parameters - INFO - TRIAL 1443. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 44}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:23,924 - Hyper-Parameters - INFO - TRIAL 1445. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:24,593 - Hyper-Parameters - INFO - TRIAL 1446. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:25,300 - Hyper-Parameters - INFO - TRIAL 1449. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:25,940 - Hyper-Parameters - INFO - TRIAL 1450. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 50}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:26,654 - Hyper-Parameters - INFO - TRIAL 1451. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.085, 'max_iter': 50}; Score: 0.7873915552483234\n",
      "2022-07-14 20:53:27,434 - Hyper-Parameters - INFO - TRIAL 1457. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 50}; Score: 0.789808217291193\n",
      "2022-07-14 20:53:28,076 - Hyper-Parameters - INFO - TRIAL 1459. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:28,769 - Hyper-Parameters - INFO - TRIAL 1460. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:29,540 - Hyper-Parameters - INFO - TRIAL 1461. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.095, 'max_iter': 50}; Score: 0.7850800530975821\n",
      "2022-07-14 20:53:30,402 - Hyper-Parameters - INFO - TRIAL 1464. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 46}; Score: 0.7896620382423478\n",
      "2022-07-14 20:53:31,093 - Hyper-Parameters - INFO - TRIAL 1465. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:31,725 - Hyper-Parameters - INFO - TRIAL 1466. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 60}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:32,340 - Hyper-Parameters - INFO - TRIAL 1467. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:32,984 - Hyper-Parameters - INFO - TRIAL 1468. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 40}; Score: 0.789808217291193\n",
      "2022-07-14 20:53:33,720 - Hyper-Parameters - INFO - TRIAL 1470. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.08, 'max_iter': 40}; Score: 0.7878594965430807\n",
      "2022-07-14 20:53:34,305 - Hyper-Parameters - INFO - TRIAL 1471. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 58}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:35,009 - Hyper-Parameters - INFO - TRIAL 1473. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:35,652 - Hyper-Parameters - INFO - TRIAL 1474. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 52}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:36,291 - Hyper-Parameters - INFO - TRIAL 1476. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 40}; Score: 0.7896620382423478\n",
      "2022-07-14 20:53:36,959 - Hyper-Parameters - INFO - TRIAL 1478. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:37,586 - Hyper-Parameters - INFO - TRIAL 1479. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:38,187 - Hyper-Parameters - INFO - TRIAL 1480. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 42}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:38,896 - Hyper-Parameters - INFO - TRIAL 1484. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:39,576 - Hyper-Parameters - INFO - TRIAL 1485. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.060000000000000005, 'max_iter': 46}; Score: 0.789808217291193\n",
      "2022-07-14 20:53:40,187 - Hyper-Parameters - INFO - TRIAL 1486. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 46}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:40,920 - Hyper-Parameters - INFO - TRIAL 1489. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.05, 'max_iter': 48}; Score: 0.7896620382423478\n",
      "2022-07-14 20:53:41,691 - Hyper-Parameters - INFO - TRIAL 1490. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 40}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:42,512 - Hyper-Parameters - INFO - TRIAL 1492. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:43,140 - Hyper-Parameters - INFO - TRIAL 1493. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:43,795 - Hyper-Parameters - INFO - TRIAL 1494. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:44,433 - Hyper-Parameters - INFO - TRIAL 1497. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:45,075 - Hyper-Parameters - INFO - TRIAL 1498. Parameters: {'method': 'liblinear+l1_l2', 'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}; Score: 0.7906355733574959\n",
      "2022-07-14 20:53:45,115 - Hyper-Parameters - INFO - Best score value: 0.7906355733574959\n"
     ]
    }
   ],
   "source": [
    "target_feature_name = \"Activity\"\n",
    "X = data.drop([target_feature_name], axis=1)\n",
    "Y = data[target_feature_name]\n",
    "samples = make_holdout_sample_sklearn(\n",
    "    X, Y,\n",
    "    holdout_sample_size=0.2,\n",
    "    seed=ML_SEED,\n",
    "    shuffle=True,\n",
    "    stratify=Y\n",
    ")\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "\n",
    "    # the method to use is a hyperparameter to optimize\n",
    "    method = trial.suggest_categorical(\n",
    "        \"method\", [\n",
    "            'lbfgs+l2',\n",
    "            'sag+l2',\n",
    "            'saga+l1', 'saga+l2', 'saga+elasticnet',\n",
    "            'liblinear+l1_l2',\n",
    "            'newton-cg+l2'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    solver       = trial.suggest_categorical('solver',       ['lbfgs', 'sag', 'saga', 'liblinear', 'newton-cg'])\n",
    "    penalty      = trial.suggest_categorical('penalty',      ['l1', 'l2', 'elasticnet'])\n",
    "    class_weight = trial.suggest_categorical('class_weight', ['balanced', None])\n",
    "    n_jobs       = trial.suggest_categorical('n_jobs',       [ML_JOBS, 1])\n",
    "\n",
    "    # LOG.info(f\"TRIAL: solver {solver}, penalty {penalty}, class_weight {class_weight}\")\n",
    "\n",
    "    p_are_appropriate = False\n",
    "    match method:\n",
    "        case 'lbfgs+l2':        p_are_appropriate = all([solver == 'lbfgs',     penalty in ['l2'],         class_weight in ['balanced', None], n_jobs == ML_JOBS]),\n",
    "        case 'sag+l2':          p_are_appropriate = all([solver == 'sag',       penalty in ['l2'],         class_weight in ['balanced', None], n_jobs == ML_JOBS]),\n",
    "        case 'saga+l1':         p_are_appropriate = all([solver == 'saga',      penalty in ['l1'],         class_weight in ['balanced', None], n_jobs == ML_JOBS]),\n",
    "        case 'saga+l2':         p_are_appropriate = all([solver == 'saga',      penalty in ['l2'],         class_weight in ['balanced', None], n_jobs == ML_JOBS]),\n",
    "        case 'saga+elasticnet': p_are_appropriate = all([solver == 'saga',      penalty in ['elasticnet'], class_weight in ['balanced', None], n_jobs == ML_JOBS]),\n",
    "        case 'liblinear+l1_l2': p_are_appropriate = all([solver == 'liblinear', penalty in ['l1', 'l2'],   class_weight in ['balanced', None], n_jobs == 1]),\n",
    "        case 'newton-cg+l2':    p_are_appropriate = all([solver == 'newton-cg', penalty in ['l2'],         class_weight in ['balanced', None], n_jobs == ML_JOBS]),\n",
    "\n",
    "    if p_are_appropriate == False:\n",
    "        raise optuna.TrialPruned()\n",
    "    elif isinstance(p_are_appropriate, tuple) and p_are_appropriate[0] == False:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    C_f = None\n",
    "    max_iter = None\n",
    "    l1_ratio = None\n",
    "\n",
    "    match method:\n",
    "        case 'lbfgs+l2':\n",
    "            C_f        = trial.suggest_float('C', 0.014, 0.021, step=0.001)\n",
    "            max_iter = trial.suggest_int('max_iter', 400, 900, 100)\n",
    "        case 'sag+l2':\n",
    "            C_f        = trial.suggest_float('C', 0.016, 0.024, step=0.001)\n",
    "            max_iter = trial.suggest_int('max_iter', 400, 900, 100)\n",
    "        case 'saga+l1':\n",
    "            C_f        = trial.suggest_float('C', 0.001, 0.011, step=0.001)\n",
    "            max_iter = trial.suggest_int('max_iter', 400, 900, 100)\n",
    "        case 'saga+l2':\n",
    "            C_f        = trial.suggest_float('C', 0.015, 0.03, step=0.001)\n",
    "            max_iter = trial.suggest_int('max_iter', 400, 900, 100)\n",
    "        case 'saga+elasticnet':\n",
    "            C_f        = trial.suggest_float('C', 0.018, 0.027, step=0.001)\n",
    "            max_iter = trial.suggest_int('max_iter', 400, 900, 100)\n",
    "            l1_ratio = trial.suggest_float('l1_ratio', 0.006, 0.012, step=0.001),\n",
    "        case 'liblinear+l1_l2':\n",
    "            C_f        = trial.suggest_float('C', 0.05, 0.1, step=0.005)\n",
    "            max_iter = trial.suggest_int('max_iter', 40, 60, 2)\n",
    "        case 'newton-cg+l2':\n",
    "            C_f        = trial.suggest_float('C', 0.05, 0.1, step=0.005)\n",
    "            max_iter = trial.suggest_int('max_iter', 40, 60, 2),\n",
    "\n",
    "\n",
    "    if isinstance(C_f, tuple):\n",
    "        C_f = C_f[0]\n",
    "    if isinstance(max_iter, tuple):\n",
    "        max_iter = max_iter[0]\n",
    "    if isinstance(l1_ratio, tuple):\n",
    "        l1_ratio = l1_ratio[0]\n",
    "\n",
    "    model = linear_model.LogisticRegression(\n",
    "        solver=solver, penalty=penalty, C=C_f, class_weight=class_weight, l1_ratio=l1_ratio,\n",
    "        max_iter=max_iter, random_state=ML_SEED, n_jobs=n_jobs\n",
    "    )\n",
    "\n",
    "    assert model != None, f\"Model is not created, the method is \\\"{method}\\\"\"\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"error\")\n",
    "        try:\n",
    "            score = cross_val_score(\n",
    "                model, samples['X_train'], samples['Y_train'], cv=5, scoring=\"f1\", n_jobs=-1).mean()\n",
    "            LOG.info(f\"TRIAL {trial.number}. Parameters: {trial.params}; Score: {score}\")\n",
    "            return score\n",
    "        except Warning or exceptions.NotFittedError:\n",
    "            # LOG.info(f\"NOT FITTED; Model: {model}.\\n----------\")\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study = optuna.create_study(study_name=\"LogisticRegression\", direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=1500)\n",
    "LOG.info(f\"Best score value: {study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-14 20:54:02,040 - Hyper-Parameters - INFO - Best method: \"liblinear+l1_l2\", parameters: {'solver': 'liblinear', 'penalty': 'l2', 'class_weight': None, 'n_jobs': 1, 'C': 0.055, 'max_iter': 48}\n",
      "2022-07-14 20:54:02,269 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, train dataset: 0.8439271859146522\n",
      "2022-07-14 20:54:02,271 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, train dataset: 0.820185614849188\n",
      "2022-07-14 20:54:02,273 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, train dataset: 0.8690842040565457\n",
      "2022-07-14 20:54:02,275 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, train dataset: 0.8256666666666667\n",
      "2022-07-14 20:54:02,276 - Hyper-Parameters - INFO - -----\n",
      "2022-07-14 20:54:02,288 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, test dataset: 0.7834319526627218\n",
      "2022-07-14 20:54:02,289 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, test dataset: 0.7557077625570776\n",
      "2022-07-14 20:54:02,290 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, test dataset: 0.8132678132678133\n",
      "2022-07-14 20:54:02,291 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, test dataset: 0.7563249001331558\n"
     ]
    }
   ],
   "source": [
    "best_parameters = dict(study.best_params)\n",
    "best_method = best_parameters['method']\n",
    "del best_parameters['method']\n",
    "# best_parameters = {k.replace(best_method + '.', ''): v for k, v in best_parameters.items()}\n",
    "LOG.info(f\"Best method: \\\"{best_method}\\\", parameters: {best_parameters}\")\n",
    "\n",
    "best_model = linear_model.LogisticRegression(\n",
    "    **best_parameters,\n",
    "    random_state=ML_SEED,\n",
    ")\n",
    "best_model.fit(samples['X_train'], samples['Y_train'])\n",
    "log_f1_scores(samples, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna.visualization.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "f1_score",
         "type": "scatter",
         "x": [
          31,
          32,
          38,
          41,
          44,
          45,
          46,
          47,
          48,
          51,
          52,
          53,
          55,
          56,
          57,
          61,
          62,
          63,
          64,
          66,
          69,
          71,
          72,
          74,
          78,
          81,
          82,
          83,
          84,
          88,
          91,
          92,
          93,
          94,
          96,
          100,
          101,
          102,
          103,
          104,
          105,
          107,
          111,
          112,
          113,
          114,
          115,
          116,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          148,
          150,
          151,
          152,
          153,
          154,
          157,
          160,
          161,
          162,
          163,
          164,
          165,
          167,
          168,
          169,
          171,
          172,
          173,
          174,
          178,
          179,
          181,
          182,
          183,
          184,
          186,
          187,
          188,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          211,
          212,
          213,
          214,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          225,
          229,
          230,
          231,
          232,
          233,
          235,
          236,
          237,
          240,
          241,
          242,
          243,
          245,
          246,
          248,
          249,
          251,
          253,
          254,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          268,
          269,
          270,
          273,
          275,
          276,
          277,
          279,
          280,
          281,
          283,
          285,
          286,
          287,
          288,
          290,
          291,
          294,
          296,
          298,
          300,
          302,
          303,
          305,
          306,
          307,
          309,
          310,
          311,
          312,
          313,
          315,
          316,
          317,
          320,
          323,
          324,
          327,
          328,
          329,
          330,
          331,
          332,
          334,
          335,
          337,
          338,
          339,
          340,
          344,
          345,
          346,
          347,
          349,
          350,
          352,
          354,
          355,
          356,
          358,
          359,
          363,
          364,
          365,
          366,
          367,
          370,
          371,
          372,
          374,
          376,
          377,
          381,
          382,
          383,
          384,
          388,
          389,
          390,
          391,
          392,
          394,
          395,
          397,
          402,
          403,
          404,
          405,
          407,
          408,
          409,
          410,
          413,
          414,
          416,
          418,
          419,
          421,
          423,
          424,
          425,
          426,
          427,
          430,
          433,
          434,
          435,
          437,
          438,
          441,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          455,
          456,
          458,
          459,
          461,
          463,
          464,
          465,
          466,
          467,
          468,
          470,
          473,
          474,
          475,
          478,
          480,
          482,
          483,
          485,
          486,
          487,
          488,
          490,
          491,
          493,
          494,
          495,
          498,
          499,
          501,
          503,
          505,
          506,
          507,
          509,
          510,
          513,
          514,
          515,
          518,
          520,
          521,
          522,
          524,
          525,
          526,
          527,
          529,
          530,
          532,
          537,
          539,
          540,
          541,
          543,
          544,
          545,
          546,
          549,
          550,
          552,
          553,
          556,
          558,
          559,
          561,
          564,
          566,
          567,
          568,
          570,
          572,
          574,
          575,
          576,
          577,
          578,
          579,
          581,
          583,
          584,
          585,
          586,
          587,
          590,
          592,
          595,
          596,
          597,
          598,
          599,
          601,
          603,
          604,
          605,
          606,
          608,
          610,
          613,
          615,
          616,
          617,
          619,
          621,
          623,
          624,
          626,
          628,
          629,
          630,
          632,
          635,
          637,
          638,
          639,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          650,
          651,
          652,
          653,
          655,
          658,
          660,
          661,
          663,
          664,
          667,
          668,
          669,
          671,
          673,
          675,
          677,
          678,
          681,
          682,
          684,
          685,
          686,
          687,
          690,
          692,
          693,
          696,
          697,
          698,
          700,
          702,
          703,
          704,
          707,
          708,
          709,
          711,
          712,
          714,
          715,
          717,
          719,
          721,
          722,
          723,
          726,
          727,
          728,
          730,
          731,
          732,
          734,
          735,
          736,
          737,
          738,
          743,
          744,
          747,
          749,
          750,
          751,
          753,
          755,
          756,
          758,
          759,
          760,
          761,
          762,
          764,
          766,
          768,
          770,
          772,
          774,
          775,
          777,
          778,
          779,
          781,
          782,
          783,
          784,
          786,
          787,
          788,
          790,
          791,
          793,
          796,
          798,
          800,
          802,
          803,
          804,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          822,
          825,
          826,
          827,
          829,
          831,
          832,
          834,
          835,
          838,
          839,
          842,
          843,
          845,
          846,
          847,
          850,
          852,
          854,
          855,
          856,
          858,
          861,
          862,
          863,
          866,
          868,
          869,
          870,
          871,
          872,
          873,
          875,
          877,
          879,
          880,
          881,
          882,
          885,
          886,
          887,
          889,
          891,
          892,
          894,
          896,
          897,
          898,
          899,
          900,
          905,
          906,
          907,
          908,
          909,
          910,
          912,
          913,
          915,
          916,
          917,
          921,
          922,
          924,
          925,
          927,
          928,
          929,
          930,
          932,
          933,
          935,
          936,
          937,
          938,
          940,
          941,
          942,
          944,
          947,
          950,
          951,
          953,
          954,
          955,
          957,
          959,
          960,
          962,
          965,
          966,
          968,
          969,
          970,
          971,
          973,
          974,
          976,
          977,
          979,
          982,
          984,
          985,
          986,
          987,
          988,
          990,
          992,
          993,
          994,
          995,
          996,
          999,
          1000,
          1002,
          1003,
          1004,
          1005,
          1006,
          1009,
          1011,
          1012,
          1014,
          1016,
          1017,
          1019,
          1021,
          1022,
          1023,
          1024,
          1027,
          1028,
          1029,
          1030,
          1033,
          1036,
          1038,
          1039,
          1040,
          1042,
          1044,
          1045,
          1047,
          1048,
          1049,
          1050,
          1051,
          1053,
          1056,
          1058,
          1060,
          1061,
          1063,
          1064,
          1067,
          1068,
          1070,
          1071,
          1072,
          1074,
          1075,
          1076,
          1078,
          1079,
          1081,
          1084,
          1086,
          1087,
          1088,
          1091,
          1095,
          1097,
          1098,
          1099,
          1100,
          1102,
          1103,
          1105,
          1106,
          1108,
          1109,
          1111,
          1113,
          1115,
          1116,
          1117,
          1118,
          1119,
          1123,
          1124,
          1126,
          1127,
          1128,
          1131,
          1132,
          1134,
          1135,
          1136,
          1139,
          1140,
          1141,
          1144,
          1145,
          1147,
          1150,
          1152,
          1153,
          1154,
          1157,
          1158,
          1159,
          1160,
          1162,
          1164,
          1166,
          1167,
          1170,
          1171,
          1174,
          1175,
          1176,
          1177,
          1180,
          1181,
          1183,
          1184,
          1187,
          1188,
          1190,
          1192,
          1196,
          1197,
          1198,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1209,
          1211,
          1212,
          1214,
          1216,
          1217,
          1218,
          1219,
          1221,
          1224,
          1225,
          1227,
          1228,
          1229,
          1230,
          1232,
          1233,
          1237,
          1238,
          1239,
          1241,
          1246,
          1247,
          1249,
          1250,
          1253,
          1254,
          1255,
          1256,
          1257,
          1259,
          1261,
          1262,
          1263,
          1264,
          1266,
          1267,
          1268,
          1270,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1280,
          1281,
          1282,
          1285,
          1286,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1296,
          1297,
          1299,
          1300,
          1303,
          1305,
          1307,
          1308,
          1309,
          1310,
          1311,
          1313,
          1314,
          1316,
          1317,
          1319,
          1320,
          1324,
          1326,
          1327,
          1328,
          1331,
          1332,
          1333,
          1334,
          1335,
          1337,
          1338,
          1340,
          1342,
          1343,
          1344,
          1348,
          1349,
          1350,
          1353,
          1354,
          1355,
          1356,
          1358,
          1361,
          1362,
          1363,
          1364,
          1366,
          1368,
          1370,
          1371,
          1372,
          1374,
          1375,
          1376,
          1379,
          1380,
          1384,
          1385,
          1386,
          1387,
          1388,
          1390,
          1392,
          1393,
          1396,
          1398,
          1400,
          1401,
          1402,
          1403,
          1404,
          1407,
          1408,
          1410,
          1411,
          1412,
          1413,
          1417,
          1420,
          1421,
          1422,
          1423,
          1424,
          1426,
          1427,
          1428,
          1429,
          1431,
          1432,
          1436,
          1437,
          1438,
          1440,
          1441,
          1442,
          1443,
          1445,
          1446,
          1449,
          1450,
          1451,
          1457,
          1459,
          1460,
          1461,
          1464,
          1465,
          1466,
          1467,
          1468,
          1470,
          1471,
          1473,
          1474,
          1476,
          1478,
          1479,
          1480,
          1484,
          1485,
          1486,
          1489,
          1490,
          1492,
          1493,
          1494,
          1497,
          1498
         ],
         "y": [
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7850800530975821,
          0.7828272048898637,
          0.7873915552483234,
          0.7878594965430807,
          0.7878594965430807,
          0.7878594965430807,
          0.7878594965430807,
          0.7878594965430807,
          0.7878594965430807,
          0.7878594965430807,
          0.7878594965430807,
          0.788100402137102,
          0.788100402137102,
          0.788100402137102,
          0.7881000053127035,
          0.7881000053127035,
          0.7881000053127035,
          0.7886045038906973,
          0.7886045038906973,
          0.7886045038906973,
          0.7881000053127035,
          0.7886045038906973,
          0.789808217291193,
          0.789808217291193,
          0.789808217291193,
          0.789808217291193,
          0.789808217291193,
          0.789808217291193,
          0.789808217291193,
          0.789808217291193,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7676539987218554,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7676539987218554,
          0.7906355733574959,
          0.789808217291193,
          0.7858426086799593,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7653885569492547,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7676539987218554,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7676539987218554,
          0.7906355733574959,
          0.7873915552483234,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7653885569492547,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7850800530975821,
          0.7896620382423478,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.788100402137102,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7676539987218554,
          0.7886045038906973,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7676539987218554,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7881000053127035,
          0.7896620382423478,
          0.7676539987218554,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7706817631464509,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7873915552483234,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7676539987218554,
          0.7906355733574959,
          0.789808217291193,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.788100402137102,
          0.7906355733574959,
          0.7653885569492547,
          0.7906355733574959,
          0.7850800530975821,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.789808217291193,
          0.7886045038906973,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7858426086799593,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7878594965430807,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7676539987218554,
          0.7896620382423478,
          0.7906355733574959,
          0.7881000053127035,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7849401308591,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7873915552483234,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7676539987218554,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7886045038906973,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7706817631464509,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7878594965430807,
          0.7906355733574959,
          0.7906355733574959,
          0.7676539987218554,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7881000053127035,
          0.7906355733574959,
          0.7858426086799593,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7676539987218554,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7706817631464509,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.788100402137102,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7850800530975821,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7676539987218554,
          0.7896620382423478,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7881000053127035,
          0.7886045038906973,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7706817631464509,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.789808217291193,
          0.7878594965430807,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7802447135372184,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7849401308591,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7676539987218554,
          0.7896620382423478,
          0.7881000053127035,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7676539987218554,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7858426086799593,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.788100402137102,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7706817631464509,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7706817631464509,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7723418649775929,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7873915552483234,
          0.7896620382423478,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.788100402137102,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7706817631464509,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7676539987218554,
          0.7896620382423478,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7676539987218554,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7878594965430807,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7653885569492547,
          0.7881000053127035,
          0.7906355733574959,
          0.7906355733574959,
          0.7850800530975821,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7858426086799593,
          0.7886045038906973,
          0.7906355733574959,
          0.789808217291193,
          0.7896620382423478,
          0.7676539987218554,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7676539987218554,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7849401308591,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7706817631464509,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7886045038906973,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7676539987218554,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.788100402137102,
          0.7676539987218554,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7676539987218554,
          0.789808217291193,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.788100402137102,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7881000053127035,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7676539987218554,
          0.789808217291193,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7873915552483234,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7850800530975821,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7878594965430807,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.789808217291193,
          0.7906355733574959,
          0.7896620382423478,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959
         ]
        },
        {
         "name": "Best Value",
         "type": "scatter",
         "x": [
          31,
          32,
          38,
          41,
          44,
          45,
          46,
          47,
          48,
          51,
          52,
          53,
          55,
          56,
          57,
          61,
          62,
          63,
          64,
          66,
          69,
          71,
          72,
          74,
          78,
          81,
          82,
          83,
          84,
          88,
          91,
          92,
          93,
          94,
          96,
          100,
          101,
          102,
          103,
          104,
          105,
          107,
          111,
          112,
          113,
          114,
          115,
          116,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          148,
          150,
          151,
          152,
          153,
          154,
          157,
          160,
          161,
          162,
          163,
          164,
          165,
          167,
          168,
          169,
          171,
          172,
          173,
          174,
          178,
          179,
          181,
          182,
          183,
          184,
          186,
          187,
          188,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          211,
          212,
          213,
          214,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          225,
          229,
          230,
          231,
          232,
          233,
          235,
          236,
          237,
          240,
          241,
          242,
          243,
          245,
          246,
          248,
          249,
          251,
          253,
          254,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          268,
          269,
          270,
          273,
          275,
          276,
          277,
          279,
          280,
          281,
          283,
          285,
          286,
          287,
          288,
          290,
          291,
          294,
          296,
          298,
          300,
          302,
          303,
          305,
          306,
          307,
          309,
          310,
          311,
          312,
          313,
          315,
          316,
          317,
          320,
          323,
          324,
          327,
          328,
          329,
          330,
          331,
          332,
          334,
          335,
          337,
          338,
          339,
          340,
          344,
          345,
          346,
          347,
          349,
          350,
          352,
          354,
          355,
          356,
          358,
          359,
          363,
          364,
          365,
          366,
          367,
          370,
          371,
          372,
          374,
          376,
          377,
          381,
          382,
          383,
          384,
          388,
          389,
          390,
          391,
          392,
          394,
          395,
          397,
          402,
          403,
          404,
          405,
          407,
          408,
          409,
          410,
          413,
          414,
          416,
          418,
          419,
          421,
          423,
          424,
          425,
          426,
          427,
          430,
          433,
          434,
          435,
          437,
          438,
          441,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          455,
          456,
          458,
          459,
          461,
          463,
          464,
          465,
          466,
          467,
          468,
          470,
          473,
          474,
          475,
          478,
          480,
          482,
          483,
          485,
          486,
          487,
          488,
          490,
          491,
          493,
          494,
          495,
          498,
          499,
          501,
          503,
          505,
          506,
          507,
          509,
          510,
          513,
          514,
          515,
          518,
          520,
          521,
          522,
          524,
          525,
          526,
          527,
          529,
          530,
          532,
          537,
          539,
          540,
          541,
          543,
          544,
          545,
          546,
          549,
          550,
          552,
          553,
          556,
          558,
          559,
          561,
          564,
          566,
          567,
          568,
          570,
          572,
          574,
          575,
          576,
          577,
          578,
          579,
          581,
          583,
          584,
          585,
          586,
          587,
          590,
          592,
          595,
          596,
          597,
          598,
          599,
          601,
          603,
          604,
          605,
          606,
          608,
          610,
          613,
          615,
          616,
          617,
          619,
          621,
          623,
          624,
          626,
          628,
          629,
          630,
          632,
          635,
          637,
          638,
          639,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          650,
          651,
          652,
          653,
          655,
          658,
          660,
          661,
          663,
          664,
          667,
          668,
          669,
          671,
          673,
          675,
          677,
          678,
          681,
          682,
          684,
          685,
          686,
          687,
          690,
          692,
          693,
          696,
          697,
          698,
          700,
          702,
          703,
          704,
          707,
          708,
          709,
          711,
          712,
          714,
          715,
          717,
          719,
          721,
          722,
          723,
          726,
          727,
          728,
          730,
          731,
          732,
          734,
          735,
          736,
          737,
          738,
          743,
          744,
          747,
          749,
          750,
          751,
          753,
          755,
          756,
          758,
          759,
          760,
          761,
          762,
          764,
          766,
          768,
          770,
          772,
          774,
          775,
          777,
          778,
          779,
          781,
          782,
          783,
          784,
          786,
          787,
          788,
          790,
          791,
          793,
          796,
          798,
          800,
          802,
          803,
          804,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          822,
          825,
          826,
          827,
          829,
          831,
          832,
          834,
          835,
          838,
          839,
          842,
          843,
          845,
          846,
          847,
          850,
          852,
          854,
          855,
          856,
          858,
          861,
          862,
          863,
          866,
          868,
          869,
          870,
          871,
          872,
          873,
          875,
          877,
          879,
          880,
          881,
          882,
          885,
          886,
          887,
          889,
          891,
          892,
          894,
          896,
          897,
          898,
          899,
          900,
          905,
          906,
          907,
          908,
          909,
          910,
          912,
          913,
          915,
          916,
          917,
          921,
          922,
          924,
          925,
          927,
          928,
          929,
          930,
          932,
          933,
          935,
          936,
          937,
          938,
          940,
          941,
          942,
          944,
          947,
          950,
          951,
          953,
          954,
          955,
          957,
          959,
          960,
          962,
          965,
          966,
          968,
          969,
          970,
          971,
          973,
          974,
          976,
          977,
          979,
          982,
          984,
          985,
          986,
          987,
          988,
          990,
          992,
          993,
          994,
          995,
          996,
          999,
          1000,
          1002,
          1003,
          1004,
          1005,
          1006,
          1009,
          1011,
          1012,
          1014,
          1016,
          1017,
          1019,
          1021,
          1022,
          1023,
          1024,
          1027,
          1028,
          1029,
          1030,
          1033,
          1036,
          1038,
          1039,
          1040,
          1042,
          1044,
          1045,
          1047,
          1048,
          1049,
          1050,
          1051,
          1053,
          1056,
          1058,
          1060,
          1061,
          1063,
          1064,
          1067,
          1068,
          1070,
          1071,
          1072,
          1074,
          1075,
          1076,
          1078,
          1079,
          1081,
          1084,
          1086,
          1087,
          1088,
          1091,
          1095,
          1097,
          1098,
          1099,
          1100,
          1102,
          1103,
          1105,
          1106,
          1108,
          1109,
          1111,
          1113,
          1115,
          1116,
          1117,
          1118,
          1119,
          1123,
          1124,
          1126,
          1127,
          1128,
          1131,
          1132,
          1134,
          1135,
          1136,
          1139,
          1140,
          1141,
          1144,
          1145,
          1147,
          1150,
          1152,
          1153,
          1154,
          1157,
          1158,
          1159,
          1160,
          1162,
          1164,
          1166,
          1167,
          1170,
          1171,
          1174,
          1175,
          1176,
          1177,
          1180,
          1181,
          1183,
          1184,
          1187,
          1188,
          1190,
          1192,
          1196,
          1197,
          1198,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1209,
          1211,
          1212,
          1214,
          1216,
          1217,
          1218,
          1219,
          1221,
          1224,
          1225,
          1227,
          1228,
          1229,
          1230,
          1232,
          1233,
          1237,
          1238,
          1239,
          1241,
          1246,
          1247,
          1249,
          1250,
          1253,
          1254,
          1255,
          1256,
          1257,
          1259,
          1261,
          1262,
          1263,
          1264,
          1266,
          1267,
          1268,
          1270,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1280,
          1281,
          1282,
          1285,
          1286,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1296,
          1297,
          1299,
          1300,
          1303,
          1305,
          1307,
          1308,
          1309,
          1310,
          1311,
          1313,
          1314,
          1316,
          1317,
          1319,
          1320,
          1324,
          1326,
          1327,
          1328,
          1331,
          1332,
          1333,
          1334,
          1335,
          1337,
          1338,
          1340,
          1342,
          1343,
          1344,
          1348,
          1349,
          1350,
          1353,
          1354,
          1355,
          1356,
          1358,
          1361,
          1362,
          1363,
          1364,
          1366,
          1368,
          1370,
          1371,
          1372,
          1374,
          1375,
          1376,
          1379,
          1380,
          1384,
          1385,
          1386,
          1387,
          1388,
          1390,
          1392,
          1393,
          1396,
          1398,
          1400,
          1401,
          1402,
          1403,
          1404,
          1407,
          1408,
          1410,
          1411,
          1412,
          1413,
          1417,
          1420,
          1421,
          1422,
          1423,
          1424,
          1426,
          1427,
          1428,
          1429,
          1431,
          1432,
          1436,
          1437,
          1438,
          1440,
          1441,
          1442,
          1443,
          1445,
          1446,
          1449,
          1450,
          1451,
          1457,
          1459,
          1460,
          1461,
          1464,
          1465,
          1466,
          1467,
          1468,
          1470,
          1471,
          1473,
          1474,
          1476,
          1478,
          1479,
          1480,
          1484,
          1485,
          1486,
          1489,
          1490,
          1492,
          1493,
          1494,
          1497,
          1498
         ],
         "y": [
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7849401308591,
          0.7850800530975821,
          0.7850800530975821,
          0.7873915552483234,
          0.7878594965430807,
          0.7878594965430807,
          0.7878594965430807,
          0.7878594965430807,
          0.7878594965430807,
          0.7878594965430807,
          0.7878594965430807,
          0.7878594965430807,
          0.788100402137102,
          0.788100402137102,
          0.788100402137102,
          0.788100402137102,
          0.788100402137102,
          0.788100402137102,
          0.7886045038906973,
          0.7886045038906973,
          0.7886045038906973,
          0.7886045038906973,
          0.7886045038906973,
          0.789808217291193,
          0.789808217291193,
          0.789808217291193,
          0.789808217291193,
          0.789808217291193,
          0.789808217291193,
          0.789808217291193,
          0.789808217291193,
          0.789808217291193,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959,
          0.7906355733574959
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "#Trials"
         }
        },
        "yaxis": {
         "title": {
          "text": "f1_score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(study, target_name=\"f1_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 `optuna` + `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-14 20:57:25,305 - Hyper-Parameters - INFO - A holdout sample is selected. Train sample size - 3000 (0.8), test sample size 751 (0.2).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-14 20:57:25,307]\u001b[0m A new study created in memory with name: RandomForestClassifier\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 20:57:45,792]\u001b[0m Trial 0 finished with value: 0.8096700278993263 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 4, 'max_features': 0.48000000000000004, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 0 with value: 0.8096700278993263.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 20:58:01,627]\u001b[0m Trial 1 finished with value: 0.8119482879778085 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.36, 'bootstrap': True, 'class_weight': 'balanced', 'n_jobs': 12}. Best is trial 1 with value: 0.8119482879778085.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 20:58:14,879]\u001b[0m Trial 2 finished with value: 0.8081147048141112 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 3, 'max_features': 0.36, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 1 with value: 0.8119482879778085.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 20:58:31,710]\u001b[0m Trial 3 finished with value: 0.8091243587863252 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 3, 'max_features': 0.34, 'bootstrap': True, 'class_weight': 'balanced', 'n_jobs': 12}. Best is trial 1 with value: 0.8119482879778085.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 20:58:44,337]\u001b[0m Trial 4 finished with value: 0.8070361089858761 and parameters: {'n_estimators': 350, 'criterion': 'log_loss', 'max_depth': 7, 'min_samples_leaf': 3, 'max_features': 0.30000000000000004, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 1 with value: 0.8119482879778085.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 20:59:02,692]\u001b[0m Trial 5 finished with value: 0.8055147326373241 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 4, 'max_features': 0.46, 'bootstrap': True, 'class_weight': 'balanced', 'n_jobs': 12}. Best is trial 1 with value: 0.8119482879778085.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 20:59:14,372]\u001b[0m Trial 6 finished with value: 0.8073369742404249 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.32, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 1 with value: 0.8119482879778085.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 20:59:33,716]\u001b[0m Trial 7 finished with value: 0.8091413639356215 and parameters: {'n_estimators': 350, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.44, 'bootstrap': True, 'class_weight': 'balanced', 'n_jobs': 12}. Best is trial 1 with value: 0.8119482879778085.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 20:59:44,333]\u001b[0m Trial 8 finished with value: 0.8080076566988972 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 7, 'min_samples_leaf': 4, 'max_features': 0.28, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 1 with value: 0.8119482879778085.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:00:01,522]\u001b[0m Trial 9 finished with value: 0.8093473585208082 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 3, 'max_features': 0.5, 'bootstrap': True, 'class_weight': 'balanced', 'n_jobs': 12}. Best is trial 1 with value: 0.8119482879778085.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:00:10,544]\u001b[0m Trial 10 finished with value: 0.8120644772640416 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.2, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 10 with value: 0.8120644772640416.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:00:19,766]\u001b[0m Trial 11 finished with value: 0.8120644772640416 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.2, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 10 with value: 0.8120644772640416.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:00:28,834]\u001b[0m Trial 12 finished with value: 0.8120644772640416 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.2, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 10 with value: 0.8120644772640416.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:00:36,617]\u001b[0m Trial 13 finished with value: 0.8102648830664922 and parameters: {'n_estimators': 250, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.2, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 10 with value: 0.8120644772640416.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:00:47,353]\u001b[0m Trial 14 finished with value: 0.8085555878491564 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.24000000000000002, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 10 with value: 0.8120644772640416.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:00:57,876]\u001b[0m Trial 15 finished with value: 0.8085555878491564 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.24000000000000002, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 10 with value: 0.8120644772640416.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:01:07,023]\u001b[0m Trial 16 finished with value: 0.8100841812761279 and parameters: {'n_estimators': 250, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.26, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 10 with value: 0.8120644772640416.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:01:16,269]\u001b[0m Trial 17 finished with value: 0.8111662307039647 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 3, 'max_features': 0.2, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 10 with value: 0.8120644772640416.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:01:26,848]\u001b[0m Trial 18 finished with value: 0.8085555878491564 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.24000000000000002, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 10 with value: 0.8120644772640416.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:01:40,258]\u001b[0m Trial 19 finished with value: 0.8088302513154758 and parameters: {'n_estimators': 250, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.4, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 10 with value: 0.8120644772640416.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:01:54,177]\u001b[0m Trial 20 finished with value: 0.8055627679659187 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 7, 'min_samples_leaf': 3, 'max_features': 0.4, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 10 with value: 0.8120644772640416.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:02:03,287]\u001b[0m Trial 21 finished with value: 0.8120644772640416 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.2, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 10 with value: 0.8120644772640416.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:02:13,116]\u001b[0m Trial 22 finished with value: 0.8091688224462807 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.22, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 10 with value: 0.8120644772640416.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:02:24,661]\u001b[0m Trial 23 finished with value: 0.8102491860898724 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.28, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 10 with value: 0.8120644772640416.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:02:34,578]\u001b[0m Trial 24 finished with value: 0.8091688224462807 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.22, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 10 with value: 0.8120644772640416.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:02:46,080]\u001b[0m Trial 25 finished with value: 0.8129984670125407 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.26, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 25 with value: 0.8129984670125407.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:02:55,519]\u001b[0m Trial 26 finished with value: 0.8100841812761279 and parameters: {'n_estimators': 250, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.26, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 25 with value: 0.8129984670125407.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:03:09,188]\u001b[0m Trial 27 finished with value: 0.8090453553966228 and parameters: {'n_estimators': 350, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.28, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 25 with value: 0.8129984670125407.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:03:19,207]\u001b[0m Trial 28 finished with value: 0.8091688224462807 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.22, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 25 with value: 0.8129984670125407.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:03:30,942]\u001b[0m Trial 29 finished with value: 0.8094228932645882 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 4, 'max_features': 0.26, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 25 with value: 0.8129984670125407.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:03:44,578]\u001b[0m Trial 30 finished with value: 0.8086971810218253 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.32, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 25 with value: 0.8129984670125407.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:03:54,010]\u001b[0m Trial 31 finished with value: 0.8120644772640416 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.2, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 25 with value: 0.8129984670125407.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:04:04,072]\u001b[0m Trial 32 finished with value: 0.8091688224462807 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.22, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 25 with value: 0.8129984670125407.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:04:14,332]\u001b[0m Trial 33 finished with value: 0.8085555878491564 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.24000000000000002, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 25 with value: 0.8129984670125407.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:04:23,485]\u001b[0m Trial 34 finished with value: 0.8120644772640416 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.2, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 25 with value: 0.8129984670125407.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:04:33,562]\u001b[0m Trial 35 finished with value: 0.8091688224462807 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.22, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 25 with value: 0.8129984670125407.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:04:45,809]\u001b[0m Trial 36 finished with value: 0.8116453986867223 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 3, 'max_features': 0.30000000000000004, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 25 with value: 0.8129984670125407.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:05:02,081]\u001b[0m Trial 37 finished with value: 0.8072335692866186 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 4, 'max_features': 0.38, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 25 with value: 0.8129984670125407.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:05:14,674]\u001b[0m Trial 38 finished with value: 0.8115669977252511 and parameters: {'n_estimators': 350, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.26, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 25 with value: 0.8129984670125407.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 21:05:25,483]\u001b[0m Trial 39 finished with value: 0.8095896344591775 and parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 3, 'max_features': 0.24000000000000002, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}. Best is trial 25 with value: 0.8129984670125407.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-14 21:05:25,485 - Hyper-Parameters - INFO - Best score value: 0.8129984670125407\n"
     ]
    }
   ],
   "source": [
    "target_feature_name = \"Activity\"\n",
    "X = data.drop([target_feature_name], axis=1)\n",
    "Y = data[target_feature_name]\n",
    "samples = make_holdout_sample_sklearn(\n",
    "    X, Y,\n",
    "    holdout_sample_size=0.2,\n",
    "    seed=ML_SEED,\n",
    "    shuffle=True,\n",
    "    stratify=Y\n",
    ")\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "\n",
    "    n_estimators     = trial.suggest_int('n_estimators', 250, 350, 50)\n",
    "    criterion        = trial.suggest_categorical('criterion', [\"entropy\", \"log_loss\"])\n",
    "    max_depth        = trial.suggest_int('max_depth', 7, 8, 1)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 3, 4, 1)\n",
    "    max_features     = trial.suggest_float('max_features', 0.2, 0.5, step=0.02)\n",
    "    bootstrap        = trial.suggest_categorical('bootstrap', [True])\n",
    "    class_weight     = trial.suggest_categorical('class_weight', [\"balanced\", None])\n",
    "    n_jobs           = trial.suggest_categorical('n_jobs', [ML_JOBS])\n",
    "\n",
    "    model = ensemble.RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        bootstrap=bootstrap,\n",
    "        class_weight=class_weight,\n",
    "        n_jobs=n_jobs,\n",
    "        random_state=ML_SEED\n",
    "    )\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"error\")\n",
    "        try:\n",
    "            score = cross_val_score(\n",
    "                model, samples['X_train'], samples['Y_train'], cv=5, scoring=\"f1\", n_jobs=-1).mean()\n",
    "            # LOG.info(f\"TRIAL {trial.number}. Parameters: {trial.params}; Score: {score}\")\n",
    "            return score\n",
    "        except Warning or exceptions.NotFittedError:\n",
    "            # LOG.info(f\"NOT FITTED; Model: {model}.\\n----------\")\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "study = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=40)\n",
    "LOG.info(f\"Best score value: {study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-14 21:07:08,457 - Hyper-Parameters - INFO - Best parameters: {'n_estimators': 300, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_leaf': 4, 'max_features': 0.26, 'bootstrap': True, 'class_weight': None, 'n_jobs': 12}\n",
      "2022-07-14 21:07:11,090 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, train dataset: 0.8838768668088998\n",
      "2022-07-14 21:07:11,091 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, train dataset: 0.8766626360338573\n",
      "2022-07-14 21:07:11,093 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, train dataset: 0.8912108174554395\n",
      "2022-07-14 21:07:11,093 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, train dataset: 0.873\n",
      "2022-07-14 21:07:11,094 - Hyper-Parameters - INFO - -----\n",
      "2022-07-14 21:07:11,149 - Hyper-Parameters - INFO - \u001b[31mF1-score\u001b[0m, test dataset: 0.7914183551847437\n",
      "2022-07-14 21:07:11,151 - Hyper-Parameters - INFO - \u001b[35mPrecision\u001b[0m, test dataset: 0.7685185185185185\n",
      "2022-07-14 21:07:11,152 - Hyper-Parameters - INFO - \u001b[34mRecall\u001b[0m, test dataset: 0.8157248157248157\n",
      "2022-07-14 21:07:11,153 - Hyper-Parameters - INFO - \u001b[32mAccuracy\u001b[0m, test dataset: 0.7669773635153129\n"
     ]
    }
   ],
   "source": [
    "best_parameters = dict(study.best_params)\n",
    "LOG.info(f\"Best parameters: {best_parameters}\")\n",
    "\n",
    "best_model = ensemble.RandomForestClassifier(\n",
    "    **best_parameters,\n",
    "    random_state=ML_SEED,\n",
    ")\n",
    "best_model.fit(samples['X_train'], samples['Y_train'])\n",
    "log_f1_scores(samples, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "f1_score",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39
         ],
         "y": [
          0.8096700278993263,
          0.8119482879778085,
          0.8081147048141112,
          0.8091243587863252,
          0.8070361089858761,
          0.8055147326373241,
          0.8073369742404249,
          0.8091413639356215,
          0.8080076566988972,
          0.8093473585208082,
          0.8120644772640416,
          0.8120644772640416,
          0.8120644772640416,
          0.8102648830664922,
          0.8085555878491564,
          0.8085555878491564,
          0.8100841812761279,
          0.8111662307039647,
          0.8085555878491564,
          0.8088302513154758,
          0.8055627679659187,
          0.8120644772640416,
          0.8091688224462807,
          0.8102491860898724,
          0.8091688224462807,
          0.8129984670125407,
          0.8100841812761279,
          0.8090453553966228,
          0.8091688224462807,
          0.8094228932645882,
          0.8086971810218253,
          0.8120644772640416,
          0.8091688224462807,
          0.8085555878491564,
          0.8120644772640416,
          0.8091688224462807,
          0.8116453986867223,
          0.8072335692866186,
          0.8115669977252511,
          0.8095896344591775
         ]
        },
        {
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39
         ],
         "y": [
          0.8096700278993263,
          0.8119482879778085,
          0.8119482879778085,
          0.8119482879778085,
          0.8119482879778085,
          0.8119482879778085,
          0.8119482879778085,
          0.8119482879778085,
          0.8119482879778085,
          0.8119482879778085,
          0.8120644772640416,
          0.8120644772640416,
          0.8120644772640416,
          0.8120644772640416,
          0.8120644772640416,
          0.8120644772640416,
          0.8120644772640416,
          0.8120644772640416,
          0.8120644772640416,
          0.8120644772640416,
          0.8120644772640416,
          0.8120644772640416,
          0.8120644772640416,
          0.8120644772640416,
          0.8120644772640416,
          0.8129984670125407,
          0.8129984670125407,
          0.8129984670125407,
          0.8129984670125407,
          0.8129984670125407,
          0.8129984670125407,
          0.8129984670125407,
          0.8129984670125407,
          0.8129984670125407,
          0.8129984670125407,
          0.8129984670125407,
          0.8129984670125407,
          0.8129984670125407,
          0.8129984670125407,
          0.8129984670125407
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "#Trials"
         }
        },
        "yaxis": {
         "title": {
          "text": "f1_score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(study, target_name=\"f1_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "510017f941ecd040108aa6155b7d7920a30c358be25c6738528295864459697b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('data-science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
