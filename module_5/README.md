# Data Science Project 5: Machine Learning Essentials - Logistic Regression <br />Data Science Проект 2: Компьютер Говорит "Нет". Основы машинного обучения. Логистическая регрессия

## Основные цели и задачи проекта
Научиться работать с моделью логистической регрессии на основе примера кредитного скоринга.
Предобработка и разведывательный анализ данных (EDA), Feature Engineering,
выбор и анализ метрик, построение затравочных моделей с различным выбором признакового пространства, устранение дисбалланса выборки по классам целевой переменной (веса классов, oversampling), варьирование гиперпараметров (`GridSearchCV`), обучение логистической регрессии на оптимальных гиперпараметрах. Анализ confusion matrix, метрик ROC-AUC, f1_score, precision & recall, accuracy. работа с ROA-AUC curve и PR curve.

## Краткая информация о входных данных
- client_id - идентификатор клиента
- education - уровень образования
- sex - пол заемщика
- age - возраст заемщика
- car - флаг наличия автомобиля
- car_type - флаг автомобиля иномарки
- decline_app_cnt - количество отказанных прошлых заявок
- good_work - флаг наличия “хорошей” работы
- bki_request_cnt - количество запросов в БКИ
- home_address - категоризатор домашнего адреса
- work_address - категоризатор рабочего адреса
- income - доход заемщика
- foreign_passport - наличие загранпаспорта
- sna - связь заемщика с клиентами банка
- first_time - давность наличия информации о заемщике
- score_bki - скоринговый балл по данным из БКИ
- region_rating - рейтинг региона
- app_date - дата подачи заявки
- default - флаг дефолта по кредиту

Сами данные из Kaggle находятся в директории [00-data/kaggle](00-data/kaggle),
включая файл [00-data/kaggle/submission.csv](00-data/kaggle/submission.csv).
Оригинал входных данных можно найти здесь: [https://www.kaggle.com/c/sf-dst-scoring/data](https://www.kaggle.com/c/sf-dst-scoring/data).

## Файл Jupyter Notebook с результатами
Файл Jupyter Notebook [02-Kaggle-Solution/Dmitry_Vlasov-Project_5-Solution-Credit-Scoring.ipynb](02-Kaggle-Solution/Dmitry_Vlasov-Project_5-Solution-Credit-Scoring.ipynb) может "не открываться"
с первого раза на сайте GitHub. Скорее всего надо будет нажать на появившуюся гиперссылку <span style="color:blue">**Reload**</span>.<br />

Выходные данные модели находятся в директории [00-data/kaggle](00-data/kaggle),
в файле [00-data/kaggle/submission.csv](00-data/kaggle/submission.csv).

## Ссылка на Jupyter Notebook в Kaggle
[https://www.kaggle.com/dmitryvvlasov/dmitry-vlasov-project-5-solution-credit-scoring/notebook](https://www.kaggle.com/dmitryvvlasov/dmitry-vlasov-project-5-solution-credit-scoring/notebook)
## Этапы работы над проектом
- сделан первичный анализ переменных;
- преобразованы переменные в понятное числовое представление, включая создание бинарных переменных, ординальных переменных, и dummy переменных для номинативных признаков;
- проведён разведывательный анализ данных:
    - анализ дисбалланса классов целевой бинарной переменной кредитного скоринга (1 - дефолт по кредиту, 0 - возврат кредита);
    - анализ распределений переменных;
    - анализ отношений ординальных и номинативных переменных по отношению к целевой переменной классификатора кредитного скоринга (1 - дефолт по кредиту, 0 - возврат кредита) и анализ относительных частот дефолтов по кредитам в разных значениях категорий;
    - поиск выбросов в числовых переменных, анализ возможности их устранения в случае к частичной сводимости их распределения к нормалному путём лорифмирования, либо принятие решения оставить так называемые выбросы, в силу существенно иной природы распределения переменной, когда её многие или все её значения попадают в "выбросы" и при этом существенно влияют на качество обучения модели;
    - анализ линейных корреляций между различными признаками и выводы об их удалениях или преобразованях/объединениях;
    - анализ значимости числовых и категориальных переменных (ординальных и номинативных);
    - на основе собранной информации сформированы рекоммендации по формированию итогового датасета для модели логистической регресии: датасеты с ординалиными переменными (ординаные как числовые) либо только с dummy переменными.
- на основе разведывательного анализа данных сделан feature enginnering:
    - некоторые коррелирующие принаки заменены на суммарные или удалены;
    - удаление малозначимых признаков сделано на этапе ручной валидации моделей;
    - сформированы наборы датасетов с числовыми, бинарными, ординалиными (ординаные как числовые) и dummy переменными, либо только с числовыми, бинарными и dummy переменными (ординальные как dummies);
- построено три затравочных (ручных) модели логистической регрессии:
    - Модель 1 - на базовых настройках без удаления признаков (ординальные как числовые);
    - Модель 2 - на базовых настройках с удалением малозначимых признаков (ординальные как числовые);
    - Модель 3 - на базовых настройках с частичным удалением малозначимых признаков и с интерпертацией ординальных переменных как чисто номинальных с созданием dummy переменных;
    - за основу взята Модель 3, чтобы не учитывать возможно неверные шкалы ординальных переменных;
- сделано два варьирования гиперпараметров для Модели 3:
    - с баллансом классов на основе их весов;
    - с увеличением объёма тренировочной выборки для минорного класса дефолтов по кредитам с помощью oversampling алгоритма SVMSMOTE;
    - сделан вывод, что oversampling даёт более симметричную матрицу ошибок (confusion matrix), хотя без oversampling модель с оптимальными гиперпараметрами и даёт чаще отказ по выдаче кредитов, но при этом делает это чаще ложно, что влияет на увеличение недополученной прибыли (TN);
    - выбрана Модель 3 с oversampling на основе алгоритма SVMSMOTE с дальнейшим варьированием гиперпараметров LogisticRegression с помощью GridSearchCV.

## Выводы

После обучение на тренировочной выборке с применением `SVMSMOTE` **oversamplig**<br />
результаты оптимизации гиперпараметров следующие.

*По сравнению с базовой моделью 3 без подбора гиперпараметров.*<br />
Метрика `accuracy` уменьшилась с `0.87` до `0.82`.
Хотя  метрика `precision` и уменьшилась c `0.54` до `0.33`, но при этом<br />
значительно учучшилась метрика полноты `recall` с `0.027` до `0.35` и<br/>
метрика F1-score - также с `0.051` до ~`0.34`.

*По сравнению с моделью 3 c подбором гиперпараметров без oversampling.*<br />
Метрика `accuracy` увеличилась с `0.67` до `0.82`.
Метрика `precision` увеличилась с `0.24` до `0.33`.
Метрика `recall` упала c `0.67` до `0.34`.<br/>
Метрика F1-score осталась примерно такой же - ~`0.34`.

Модель примерно в равной степени неверно предсказывает<br />
как ложные дефолты, так и ложные возвраты кредитов.
Это приводит к тому, что банк примерно сохраняет столько условных денег,
отказывая по кредитам, сколько и теряет их при выдаче невозвратных кредитов.
*Но*, по сравнению с моделью без oversampling, при проверке модели на валидационной выборке значительно увеличилось число<br /> верно предсказанных выданных и возвращённых кредитов (TN),
что принесёт банку больше денег от большего числа верно распознанных платёжеспособных клиентов.

## Возможные направления по улучшению модели

Необходим дальнейший анализ влияния различных значений ординальных и номинативных переменных.

В случае с ординальными переменными может быть стоит варьировать расстояния между отдельными значениями ординальных переменных, тем самым меняя их шкалы. Это позволило бы уменьшить размерность задачи и не использовать большое количество dummy переменных.

В случае с номинативными переменными нужно больше информации о том, что означает каждая категория
адреса работы и домашнего адреса, что позволило бы также подобрать в будущем иные веса для этих признаков, преобразовав их в один или два новых признака, хранящих рейтинги домашнего и рабочего адресов. Это также позволило бы избавиться от признаков адресов частично или полностью и тем самым убрать лишние корреляции.

Необходимо проверить чем можно заменить признаки `sna` и `first_time`. Какой один признак может заменить их оба, поскольку между `sna` и `first_time` есть высокая корреляция, но удаление одного из этих признаков немного ухудшает результаты обучения. Возможно здесь поможет перемножение этих признаков или создание иных полиномиальных признаков, отражающих давность вовлечённости клиента в сообщество клиентов банка.

Необходимо изучить другие возможности, другие алгоритмы по устранению несбалансированности выборки для кредитного скоринга и по варьированию их гиперпараметров.
Но это потребует значительных затрат дополнительного машинного времени.

Нужно провести более широкое варьирование гиперпараметров для модели логистической регрессии совместно с варьированием гиперпараметров для алгоритмов Oversampling.
Это требует отдельного исследования с большими вычислительными затратами.

## Использованное ПО
Code OSS (VS Code) с поддержкой Python и Jupyter Notebook